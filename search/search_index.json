{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Python CQRS <p>Event-Driven Architecture Framework for Distributed Systems</p> \ud83d\udc19 Star if cool \u2b50 \u2728 \u2728 \ud83d\udce6 PyPI \ud83d\udcca Downloads <p>Breaking Changes in v5.0.0</p> <p>Starting with version 5.0.0, Pydantic support will become optional. The default implementations of <code>Request</code>, <code>Response</code>, <code>DomainEvent</code>, and <code>NotificationEvent</code> will be migrated to dataclasses-based implementations.</p> <p>See the planned release discussion on GitHub for the full list of breaking changes and migration details.</p>"},{"location":"#core-features","title":"Core Features","text":"<ul> <li> <p> Bootstrap</p> <p>Quick project setup and configuration with automatic DI container setup.</p> <p> Read More</p> </li> <li> <p> Request Handlers</p> <p>Handle commands and queries with full type safety and async support.</p> <p> Read More</p> </li> <li> <p> Saga Pattern</p> <p>Orchestrated Saga for distributed transactions with automatic compensation.</p> <p> Read More</p> </li> <li> <p> Event Handling</p> <p>Process domain events with parallel processing and runtime execution.</p> <p> Read More</p> </li> <li> <p> Transaction Outbox</p> <p>Guaranteed event delivery with at-least-once semantics.</p> <p> Read More</p> </li> <li> <p> Chain of Responsibility</p> <p>Sequential request processing with flexible handler chaining.</p> <p> Read More</p> </li> <li> <p> Streaming</p> <p>Incremental processing with real-time progress updates via SSE.</p> <p> Read More</p> </li> <li> <p> Integrations</p> <p>FastAPI and FastStream integrations out of the box.</p> <p> Read More</p> </li> <li> <p> Mermaid Diagrams</p> <p>Visualize architecture patterns and flows with interactive Mermaid diagrams.</p> <p> Read More</p> </li> </ul>"},{"location":"#what-is-it","title":"What is it?","text":"<p>Python CQRS is a framework for implementing the CQRS (Command Query Responsibility Segregation) pattern in Python applications. It helps separate read and write operations, improving scalability, performance, and code maintainability.</p> <p>Key Highlights:</p> <ul> <li> Performance \u2014 Separation of commands and queries, parallel event processing</li> <li> Reliability \u2014 Transaction Outbox for guaranteed event delivery, Saga with compensation support and eventual consistency</li> <li> Flexible Types \u2014 Easy integration with any type: Pydantic, dataclasses, msgspec, attrs, TypedDict and more</li> <li> Ready Integrations \u2014 FastAPI and FastStream out of the box</li> <li> Simple Setup \u2014 Bootstrap for quick configuration</li> <li> Proven Patterns \u2014 CQRS, Saga, Outbox and more to keep services decoupled and maintainable</li> </ul>"},{"location":"#project-status","title":"Project status","text":"Group Badges Python version &amp; PyPI Downloads Quality &amp; CI Documentation &amp; community"},{"location":"#installation","title":"Installation","text":"<p>Install Python CQRS using pip or uv:</p> <p>Using pip:</p> <pre><code>pip install python-cqrs\n</code></pre> <p>Using uv:</p> <pre><code>uv pip install python-cqrs\n</code></pre> <p>Requirements</p> <p>Python 3.10+</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\n\n# Define command, response and handler\nclass CreateUserCommand(cqrs.Request):\n    email: str\n    name: str\n\nclass CreateUserResponse(cqrs.Response):\n    user_id: str\n\nclass CreateUserHandler(cqrs.RequestHandler[CreateUserCommand, CreateUserResponse]):\n    async def handle(self, request: CreateUserCommand) -&gt; CreateUserResponse:\n        # Your business logic here\n        user_id = f\"user_{request.email}\"\n        return CreateUserResponse(user_id=user_id)\n\n# Bootstrap and use\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=lambda m: m.bind(CreateUserCommand, CreateUserHandler),\n)\n\nresult = await mediator.send(CreateUserCommand(email=\"user@example.com\", name=\"John\"))\n</code></pre> <p>See Bootstrap for detailed setup instructions.</p>"},{"location":"di/","title":"Dependency Injection","text":"<p>Dependency Injection (DI) is a design pattern that allows injecting dependencies into application components, simplifying their management and improving code testability.</p>"},{"location":"di/#overview","title":"Overview","text":"<p>The <code>python-cqrs</code> package supports multiple DI container libraries:</p> <ul> <li><code>di</code> \u2014 Lightweight, modern dependency injection library (default)</li> <li><code>dependency-injector</code> \u2014 Feature-rich DI library with configuration management and FastAPI integration</li> </ul> <p>Both libraries allow you to bind implementations to interfaces and automatically resolve dependencies in your handlers.</p> <p>Prerequisites</p> <p>This section assumes you've already configured Bootstrap. The DI container is passed to bootstrap functions to resolve handlers and their dependencies.</p> <p>Next Steps</p> <p>After understanding DI, proceed to Request Handlers to learn how handlers use dependency injection.</p>"},{"location":"di/#supported-libraries","title":"Supported Libraries","text":"Feature <code>di</code> <code>dependency-injector</code> Default \u2705 Yes (default) \u274c No Type-based resolution \u2705 Yes \u2705 Yes Scoped dependencies \u2705 Yes \u2705 Yes Configuration management \u274c No \u2705 Yes (YAML, dict, Pydantic) Resource management \u274c No \u2705 Yes FastAPI integration \u2705 Yes \u2705 Yes (direct wiring) Nested containers \u274c No \u2705 Yes Learning curve \ud83d\udfe2 Easy \ud83d\udfe1 Moderate Best for Small to medium apps Large, complex apps"},{"location":"di/#di-library","title":"<code>di</code> Library","text":"<p>The <code>di</code> library is the default DI container for <code>python-cqrs</code>. It provides:</p> Feature Description Type-based resolution Automatic dependency resolution by type Scoped dependencies Support for singleton, request, and scoped lifetimes Simple API Easy to use and configure Type safety Full type checking support <p>When to use <code>di</code></p> <p>Use <code>di</code> for most applications. It's lightweight, simple, and provides everything you need for dependency injection.</p>"},{"location":"di/#dependency-injector-library","title":"<code>dependency-injector</code> Library","text":"<p>The <code>dependency-injector</code> library offers advanced features:</p> Feature Description Configuration management Built-in support for YAML, dict, and Pydantic settings Resource management Automatic initialization and cleanup of resources Container wiring Direct injection into FastAPI endpoints Nested containers Better organization for large applications <p>When to use <code>dependency-injector</code></p> <p>Use <code>dependency-injector</code> when you need advanced features like configuration management, resource lifecycle, or nested containers for large applications.</p>"},{"location":"di/#key-concepts","title":"Key Concepts","text":""},{"location":"di/#binding-implementations","title":"Binding Implementations","text":"<p>Dependencies are bound by type, allowing the container to automatically resolve implementations:</p> <pre><code>container.bind(\n    di.bind_by_type(\n        Dependent(ImplementationClass, scope=\"request\"),\n        InterfaceProtocol\n    )\n)\n</code></pre>"},{"location":"di/#dependency-scopes","title":"Dependency Scopes","text":"<p>The <code>di</code> library supports different scopes:</p> Scope Lifetime Use Case <code>\"singleton\"</code> One instance per container (shared across all requests) Stateless services, configuration <code>\"request\"</code> One instance per request (new instance for each handler) Stateful services, database connections <code>\"scoped\"</code> One instance per scope (custom scope management) Request-scoped resources Scope Examples <pre><code># Singleton - shared across all requests\ncontainer.bind(\n    di.bind_by_type(\n        Dependent(ConfigService, scope=\"singleton\"),\n        ConfigServiceProtocol\n    )\n)\n\n# Request - new instance per request\ncontainer.bind(\n    di.bind_by_type(\n        Dependent(DatabaseConnection, scope=\"request\"),\n        DatabaseProtocol\n    )\n)\n</code></pre>"},{"location":"di/#automatic-resolution","title":"Automatic Resolution","text":"<p>Handlers receive dependencies automatically through constructor injection:</p> <pre><code>class MyHandler(RequestHandler[MyCommand, None]):\n    def __init__(self, service: ServiceProtocol) -&gt; None:\n        self._service = service\n</code></pre> <p>The container automatically resolves <code>ServiceProtocol</code> and injects it into the handler.</p>"},{"location":"di/#integration-with-bootstrap","title":"Integration with Bootstrap","text":"<p>DI containers are integrated with the bootstrap process:</p> <pre><code>mediator = bootstrap.bootstrap(\n    di_container=container,\n    commands_mapper=commands_mapper,\n    queries_mapper=queries_mapper,\n    domain_events_mapper=domain_events_mapper,\n)\n</code></pre> <p>The container is used to resolve all handlers and their dependencies automatically.</p>"},{"location":"di/#benefits","title":"Benefits","text":"<p>Using dependency injection with <code>python-cqrs</code> provides:</p> Benefit Description Simplified management Container handles creation and lifecycle Improved testability Easy to mock dependencies for unit testing Flexibility Swap implementations without changing core code Separation of concerns Dependencies explicitly declared Configuration management Centralized dependency configuration"},{"location":"di/#best-practices","title":"Best Practices","text":"Practice Description Example Use interfaces Always bind implementations to interfaces, not concrete classes <code>ServiceProtocol</code> \u2192 <code>ServiceImplementation</code> Choose scopes wisely Use singleton for stateless services, request for stateful ones Config: singleton, DB: request Keep constructors simple Avoid complex logic in constructors Move logic to methods Use factory functions For complex object creation, use factory functions <code>create_database_connection()</code> Test with mocks Always test handlers with mocked dependencies Mock <code>ServiceProtocol</code> in tests <p>Common Mistakes</p> <ul> <li>\u274c Binding concrete classes instead of interfaces</li> <li>\u274c Using singleton for stateful services</li> <li>\u274c Complex logic in constructors</li> <li>\u274c Not testing with mocks</li> </ul> <p>Testing Tips</p> <p>Always test handlers with mocked dependencies. This ensures your handlers are testable and don't depend on external services.</p>"},{"location":"event_producing/","title":"Event Producing","text":""},{"location":"event_producing/#overview","title":"Overview","text":"<p>Event producing allows you to publish events to message brokers (Kafka, RabbitMQ) for asynchronous processing. The <code>python-cqrs</code> package provides message broker abstractions that support both JSON and Protobuf serialization.</p> <p>Key Features:</p> <ul> <li>Multiple Brokers \u2014 Support for Kafka and RabbitMQ</li> <li>Serialization Formats \u2014 JSON support (Protobuf support available, see Protobuf Integration)</li> <li>Type Safety \u2014 Full Pydantic v2 support for event payloads</li> <li>Error Handling \u2014 Built-in retry and error handling</li> </ul> <p>Prerequisites</p> <p>Understanding of Event Handling and Bootstrap is required. Events are automatically published when command handlers emit them.</p> <p>Related Topics</p> <ul> <li>FastStream Integration \u2014 For consuming events from message brokers</li> <li>Protobuf Integration \u2014 For Protobuf serialization</li> <li>Transaction Outbox \u2014 For reliable event delivery</li> </ul>"},{"location":"event_producing/#basic-event-producing","title":"Basic Event Producing","text":"<p>Events are produced through the <code>EventEmitter</code> which is configured in the bootstrap process:</p> <pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import devnull\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(CreateUserCommand, CreateUserCommandHandler)\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(UserCreatedEvent, UserCreatedEventHandler)\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=devnull.DevnullMessageBroker(),  # For testing\n)\n</code></pre> <p>When a command handler emits events, they are automatically published to the configured message broker.</p>"},{"location":"event_producing/#kafka-event-producing","title":"Kafka Event Producing","text":""},{"location":"event_producing/#basic-kafka-producer-setup","title":"Basic Kafka Producer Setup","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import kafka\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\n\n# Create Kafka producer adapter\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    client_id=\"my-app\",\n)\n\n# Create message broker\nkafka_broker = kafka.KafkaMessageBroker(\n    producer=kafka_producer,\n    aiokafka_log_level=\"ERROR\",\n)\n\n# Bootstrap with Kafka broker\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=kafka_broker,\n)\n</code></pre>"},{"location":"event_producing/#kafka-producer-with-ssltls","title":"Kafka Producer with SSL/TLS","text":"<pre><code>import ssl\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\n\n# Create SSL context\nssl_context = ssl.create_default_context()\n\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"kafka.example.com:9093\"],\n    security_protocol=\"SASL_SSL\",\n    sasl_mechanism=\"SCRAM-SHA-256\",\n    sasl_plain_username=\"username\",\n    sasl_plain_password=\"password\",\n    ssl_context=ssl_context,\n)\n\nkafka_broker = kafka.KafkaMessageBroker(producer=kafka_producer)\n</code></pre>"},{"location":"event_producing/#kafka-producer-configuration","title":"Kafka Producer Configuration","text":"<pre><code>kafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    client_id=\"my-app\",\n    acks=\"all\",  # Wait for all replicas\n    enable_idempotence=True,  # Exactly-once semantics\n    max_in_flight_requests_per_connection=5,\n    retry_count=3,\n    retry_delay=1,\n)\n\nkafka_broker = kafka.KafkaMessageBroker(\n    producer=kafka_producer,\n    aiokafka_log_level=\"ERROR\",\n)\n</code></pre>"},{"location":"event_producing/#rabbitmq-event-producing","title":"RabbitMQ Event Producing","text":""},{"location":"event_producing/#basic-rabbitmq-producer-setup","title":"Basic RabbitMQ Producer Setup","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import amqp\nfrom cqrs.adapters.amqp import AMQPPublisherAdapter\n\n# Create AMQP publisher\namqp_publisher = AMQPPublisherAdapter(\n    dsn=\"amqp://user:password@localhost:5672/\",\n)\n\n# Create message broker\namqp_broker = amqp.AMQPMessageBroker(\n    publisher=amqp_publisher,\n    exchange_name=\"events\",\n    pika_log_level=\"ERROR\",\n)\n\n# Bootstrap with RabbitMQ broker\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=amqp_broker,\n)\n</code></pre>"},{"location":"event_producing/#rabbitmq-with-connection-pooling","title":"RabbitMQ with Connection Pooling","text":"<pre><code>from cqrs.adapters.amqp import amqp_publisher_factory, amqp_connection_pool_factory\nimport aio_pika\n\n# Create connection pool\nconnection_pool = amqp_connection_pool_factory(\n    url=\"amqp://user:password@localhost:5672/\",\n    pool_size=10,\n)\n\n# Create publisher with pool\namqp_publisher = amqp_publisher_factory(\n    connection_pool=connection_pool,\n)\n\namqp_broker = amqp.AMQPMessageBroker(\n    publisher=amqp_publisher,\n    exchange_name=\"events\",\n)\n</code></pre> <p>For Protobuf event producing, see the Protobuf Integration documentation.</p>"},{"location":"event_producing/#complete-examples","title":"Complete Examples","text":""},{"location":"event_producing/#kafka-json-example","title":"Kafka JSON Example","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import kafka\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\n\n# Create Kafka producer\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    client_id=\"my-app\",\n    acks=\"all\",\n    enable_idempotence=True,\n)\n\n# Create message broker\nkafka_broker = kafka.KafkaMessageBroker(\n    producer=kafka_producer,\n    aiokafka_log_level=\"ERROR\",\n)\n\n# Bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=kafka_broker,\n)\n</code></pre>"},{"location":"event_producing/#rabbitmq-json-example","title":"RabbitMQ JSON Example","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import amqp\nfrom cqrs.adapters.amqp import AMQPPublisherAdapter\n\n# Create AMQP publisher\namqp_publisher = AMQPPublisherAdapter(\n    dsn=\"amqp://guest:guest@localhost:5672/\",\n)\n\n# Create message broker\namqp_broker = amqp.AMQPMessageBroker(\n    publisher=amqp_publisher,\n    exchange_name=\"events\",\n    pika_log_level=\"ERROR\",\n)\n\n# Bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=amqp_broker,\n)\n</code></pre>"},{"location":"event_producing/#best-practices","title":"Best Practices","text":""},{"location":"event_producing/#1-use-appropriate-serialization","title":"1. Use Appropriate Serialization","text":"<p>Choose serialization format based on your needs:</p> <ul> <li>JSON \u2014 Human-readable, easy to debug, larger message size</li> <li>Protobuf \u2014 See Protobuf Integration for Protobuf serialization</li> </ul>"},{"location":"event_producing/#2-configure-producer-settings","title":"2. Configure Producer Settings","text":"<p>For Kafka, configure producer for reliability:</p> <pre><code>kafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    acks=\"all\",  # Wait for all replicas\n    enable_idempotence=True,  # Exactly-once semantics\n    retry_count=3,\n    retry_delay=1,\n)\n</code></pre>"},{"location":"event_producing/#3-use-connection-pooling","title":"3. Use Connection Pooling","text":"<p>For RabbitMQ, use connection pooling for better performance:</p> <pre><code>connection_pool = amqp_connection_pool_factory(\n    url=\"amqp://user:password@localhost:5672/\",\n    pool_size=10,\n)\n</code></pre>"},{"location":"event_producing/#4-error-handling","title":"4. Error Handling","text":"<p>Handle producer errors appropriately:</p> <pre><code>try:\n    await broker.send_message(message)\nexcept Exception as e:\n    logger.error(f\"Failed to publish event: {e}\")\n    # Implement retry logic or dead letter queue\n</code></pre>"},{"location":"event_producing/#5-protobuf-serialization","title":"5. Protobuf Serialization","text":"<p>For Protobuf serialization, see the Protobuf Integration documentation.</p>"},{"location":"event_producing/#6-logging","title":"6. Logging","text":"<p>Suppress verbose broker logging:</p> <pre><code>logging.getLogger(\"aiokafka\").setLevel(logging.ERROR)  # Kafka\nlogging.getLogger(\"aio_pika\").setLevel(logging.ERROR)  # RabbitMQ\n</code></pre>"},{"location":"event_producing/#7-security","title":"7. Security","text":"<p>Use SSL/TLS for production:</p> <pre><code>ssl_context = ssl.create_default_context()\n\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"kafka.example.com:9093\"],\n    security_protocol=\"SASL_SSL\",\n    sasl_mechanism=\"SCRAM-SHA-256\",\n    ssl_context=ssl_context,\n)\n</code></pre>"},{"location":"fastapi/","title":"FastAPI Integration","text":""},{"location":"fastapi/#overview","title":"Overview","text":"<p>FastAPI integration with <code>python-cqrs</code> allows you to build RESTful APIs where FastAPI handles HTTP layer (routing, validation, serialization) while CQRS handles business logic through command/query handlers.</p> Benefit Description Separation of Concerns HTTP layer vs business logic Type Safety Full Pydantic v2 support Testability Easy to test handlers independently Scalability Commands and queries can scale independently <p>Prerequisites</p> <p>Understanding of Bootstrap, Request Handlers, and Stream Handling is recommended.</p> <p>Quick Start</p> <p>This integration shows how to use mediators created via Bootstrap in FastAPI endpoints. See Stream Handling for SSE examples.</p>"},{"location":"fastapi/#setup","title":"Setup","text":"<p>First, install the required dependencies:</p> <pre><code>pip install fastapi uvicorn python-cqrs di\n</code></pre>"},{"location":"fastapi/#mediator-dependency-injection","title":"Mediator Dependency Injection","text":"<p>The recommended way to inject mediators into FastAPI endpoints is using <code>Depends()</code> with factory functions. This ensures proper dependency management and allows for easy testing.</p>"},{"location":"fastapi/#basic-mediator-factory","title":"Basic Mediator Factory","text":"<pre><code>import di\nimport fastapi\nimport cqrs\nfrom cqrs.requests import bootstrap\n\ndef mediator_factory() -&gt; cqrs.RequestMediator:\n    \"\"\"Factory function for RequestMediator dependency injection.\"\"\"\n    container = di.Container()\n\n    # Your mappers (commands_mapper, queries_mapper, events_mapper)\n    # should be defined elsewhere in your application\n\n    return bootstrap.bootstrap(\n        di_container=container,\n        commands_mapper=commands_mapper,\n        queries_mapper=queries_mapper,\n        domain_events_mapper=events_mapper,\n    )\n\n# Use in endpoint\n@app.post(\"/users\")\nasync def create_user(\n    command: CreateUserCommand,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n):\n    return await mediator.send(command)\n</code></pre>"},{"location":"fastapi/#mediator-factory-comparison","title":"Mediator Factory Comparison","text":"Factory Type Performance Use Case Basic Factory Creates new mediator per request Development, testing Singleton Factory Reuses mediator across requests Production (recommended) Per-Request Factory Creates mediator per request with DI Advanced scenarios <p>Production Recommendation</p> <p>Use singleton mediator factory for better performance. The mediator is thread-safe and can be safely reused.</p>"},{"location":"fastapi/#singleton-mediator-recommended-for-production","title":"Singleton Mediator (Recommended for Production)","text":"<p>For better performance, you can create a singleton mediator that's reused across requests:</p> <pre><code>import functools\n\n@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.RequestMediator:\n    \"\"\"Singleton mediator factory - created once and reused.\"\"\"\n    container = di.Container()\n    return bootstrap.bootstrap(\n        di_container=container,\n        commands_mapper=commands_mapper,\n        queries_mapper=queries_mapper,\n        domain_events_mapper=events_mapper,\n    )\n</code></pre>"},{"location":"fastapi/#streaming-mediator-factory","title":"Streaming Mediator Factory","text":"<p>For streaming endpoints, create a separate factory:</p> <pre><code>@functools.lru_cache(maxsize=1)\ndef streaming_mediator_factory() -&gt; cqrs.StreamingRequestMediator:\n    \"\"\"Factory for StreamingRequestMediator.\"\"\"\n    container = di.Container()\n    return bootstrap.bootstrap_streaming(\n        di_container=container,\n        commands_mapper=commands_mapper,\n        domain_events_mapper=events_mapper,\n        max_concurrent_event_handlers=5,\n        concurrent_event_handle_enable=True,\n    )\n</code></pre>"},{"location":"fastapi/#event-emitter-factory","title":"Event Emitter Factory","text":"<p>For background task processing:</p> <pre><code>from cqrs.requests import bootstrap\nfrom cqrs.events import EventEmitter\n\n@functools.lru_cache(maxsize=1)\ndef event_emitter_factory() -&gt; EventEmitter:\n    \"\"\"Factory for EventEmitter used in background tasks.\"\"\"\n    container = di.Container()\n    return bootstrap.setup_event_emitter(\n        container=container,\n        domain_events_mapper=events_mapper,\n    )\n</code></pre>"},{"location":"fastapi/#using-multiple-mediators","title":"Using Multiple Mediators","text":"<p>You can inject multiple mediators into a single endpoint:</p> <pre><code>@app.post(\"/process\")\nasync def process_request(\n    command: ProcessCommand,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n    streaming_mediator: cqrs.StreamingRequestMediator = fastapi.Depends(\n        streaming_mediator_factory\n    ),\n):\n    # Use appropriate mediator based on logic\n    if command.use_streaming:\n        async for result in streaming_mediator.stream(command):\n            yield result\n    else:\n        return await mediator.send(command)\n</code></pre>"},{"location":"fastapi/#command-handling-post-put-delete","title":"Command Handling (POST, PUT, DELETE)","text":"<p>Commands modify state and typically don't return data (or return minimal data). Use POST for creation, PUT for updates, and DELETE for deletion.</p>"},{"location":"fastapi/#post-request-create-command","title":"POST Request (Create Command)","text":"<pre><code>import fastapi\nimport cqrs\n\n@app.post(\"/users\", status_code=201)\nasync def create_user(\n    command: CreateUserCommand,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserCreatedResponse:\n    \"\"\"Create a new user.\"\"\"\n    return await mediator.send(command)\n</code></pre>"},{"location":"fastapi/#put-request-update-command","title":"PUT Request (Update Command)","text":"<pre><code>@app.put(\"/users/{user_id}\")\nasync def update_user(\n    user_id: str,\n    command: UpdateUserCommand,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserUpdatedResponse:\n    \"\"\"Update an existing user.\"\"\"\n    command.user_id = user_id  # Set from path parameter\n    return await mediator.send(command)\n</code></pre>"},{"location":"fastapi/#delete-request-delete-command","title":"DELETE Request (Delete Command)","text":"<pre><code>@app.delete(\"/users/{user_id}\", status_code=200)\nasync def delete_user(\n    user_id: str,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserDeletedResponse:\n    \"\"\"Delete a user.\"\"\"\n    command = DeleteUserCommand(user_id=user_id)\n    return await mediator.send(command)\n</code></pre>"},{"location":"fastapi/#command-with-path-and-body-parameters","title":"Command with Path and Body Parameters","text":"<pre><code>@app.put(\"/users/{user_id}/profile\")\nasync def update_user_profile(\n    user_id: str,\n    profile_data: ProfileUpdateRequest,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; ProfileResponse:\n    \"\"\"Update user profile with path and body parameters.\"\"\"\n    command = UpdateProfileCommand(\n        user_id=user_id,\n        **profile_data.model_dump()\n    )\n    return await mediator.send(command)\n</code></pre>"},{"location":"fastapi/#command-with-query-parameters","title":"Command with Query Parameters","text":"<pre><code>@app.post(\"/users/{user_id}/notify\")\nasync def notify_user(\n    user_id: str,\n    notification_type: str = fastapi.Query(...),\n    priority: str = fastapi.Query(\"normal\"),\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; NotificationResponse:\n    \"\"\"Send notification to user with query parameters.\"\"\"\n    command = NotifyUserCommand(\n        user_id=user_id,\n        notification_type=notification_type,\n        priority=priority\n    )\n    return await mediator.send(command)\n</code></pre>"},{"location":"fastapi/#query-handling-get","title":"Query Handling (GET)","text":"<p>Queries read data without modifying state. Use GET requests for queries.</p>"},{"location":"fastapi/#basic-get-request","title":"Basic GET Request","text":"<pre><code>@app.get(\"/users/{user_id}\")\nasync def get_user(\n    user_id: str,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserResponse:\n    \"\"\"Get user by ID.\"\"\"\n    query = GetUserQuery(user_id=user_id)\n    return await mediator.send(query)\n</code></pre>"},{"location":"fastapi/#get-with-query-parameters","title":"GET with Query Parameters","text":"<pre><code>@app.get(\"/users\")\nasync def list_users(\n    page: int = fastapi.Query(1, ge=1),\n    page_size: int = fastapi.Query(10, ge=1, le=100),\n    search: str | None = fastapi.Query(None),\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; ListUsersResponse:\n    \"\"\"List users with pagination and search.\"\"\"\n    query = ListUsersQuery(\n        page=page,\n        page_size=page_size,\n        search=search\n    )\n    return await mediator.send(query)\n</code></pre>"},{"location":"fastapi/#get-with-multiple-path-parameters","title":"GET with Multiple Path Parameters","text":"<pre><code>@app.get(\"/users/{user_id}/orders/{order_id}\")\nasync def get_user_order(\n    user_id: str,\n    order_id: str,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; OrderResponse:\n    \"\"\"Get specific order for a user.\"\"\"\n    query = GetUserOrderQuery(user_id=user_id, order_id=order_id)\n    return await mediator.send(query)\n</code></pre>"},{"location":"fastapi/#get-with-optional-parameters","title":"GET with Optional Parameters","text":"<pre><code>@app.get(\"/users/{user_id}/analytics\")\nasync def get_user_analytics(\n    user_id: str,\n    start_date: str | None = fastapi.Query(None),\n    end_date: str | None = fastapi.Query(None),\n    include_details: bool = fastapi.Query(False),\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; AnalyticsResponse:\n    \"\"\"Get user analytics with optional date range.\"\"\"\n    query = GetUserAnalyticsQuery(\n        user_id=user_id,\n        start_date=start_date,\n        end_date=end_date,\n        include_details=include_details\n    )\n    return await mediator.send(query)\n</code></pre>"},{"location":"fastapi/#event-handling-with-background-tasks","title":"Event Handling with Background Tasks","text":"<p>Sometimes you need to process events asynchronously using FastAPI's <code>BackgroundTasks</code>. This is useful when you want to:</p> <ul> <li>Process events after returning HTTP response</li> <li>Handle events from external systems</li> <li>Decouple event processing from request handling</li> </ul>"},{"location":"fastapi/#post-endpoint-with-background-task","title":"POST Endpoint with Background Task","text":"<pre><code>from fastapi import BackgroundTasks\n\n@app.post(\"/events/process\", status_code=202)\nasync def process_event(\n    event: UserCreatedEvent,\n    background_tasks: BackgroundTasks,\n    emitter: EventEmitter = fastapi.Depends(event_emitter_factory),\n) -&gt; dict:\n    \"\"\"Process event asynchronously using background tasks.\"\"\"\n    background_tasks.add_task(emitter.emit, event)\n\n    return {\n        \"status\": \"accepted\",\n        \"event_id\": event.event_id,\n        \"message\": \"Event will be processed in background\"\n    }\n</code></pre>"},{"location":"fastapi/#put-endpoint-with-background-task","title":"PUT Endpoint with Background Task","text":"<pre><code>@app.put(\"/events/{event_id}/process\", status_code=202)\nasync def process_event_by_id(\n    event_id: str,\n    event_data: dict,\n    background_tasks: BackgroundTasks,\n    emitter: EventEmitter = fastapi.Depends(event_emitter_factory),\n) -&gt; dict:\n    \"\"\"Process event by ID asynchronously.\"\"\"\n    # Create event from event_data\n    event = UserCreatedEvent(\n        user_id=event_data.get(\"user_id\", event_id),\n        email=event_data.get(\"email\", \"\")\n    )\n\n    background_tasks.add_task(emitter.emit, event)\n\n    return {\n        \"status\": \"accepted\",\n        \"event_id\": event_id,\n        \"message\": \"Event processing started\"\n    }\n</code></pre>"},{"location":"fastapi/#processing-multiple-events","title":"Processing Multiple Events","text":"<pre><code>@app.post(\"/events/batch\", status_code=202)\nasync def process_events_batch(\n    events: list[UserCreatedEvent],\n    background_tasks: BackgroundTasks,\n    emitter: EventEmitter = fastapi.Depends(event_emitter_factory),\n) -&gt; dict:\n    \"\"\"Process multiple events in background.\"\"\"\n    for event in events:\n        background_tasks.add_task(emitter.emit, event)\n\n    return {\n        \"status\": \"accepted\",\n        \"events_count\": len(events),\n        \"message\": f\"{len(events)} events will be processed in background\"\n    }\n</code></pre>"},{"location":"fastapi/#event-processing-with-error-handling","title":"Event Processing with Error Handling","text":"<pre><code>async def emit_event_safe(emitter: EventEmitter, event: cqrs.Event):\n    \"\"\"Safely emit event with error handling.\"\"\"\n    try:\n        await emitter.emit(event)\n    except Exception as e:\n        # Log error, send to error queue, etc.\n        print(f\"Error processing event {event.event_id}: {e}\")\n\n@app.post(\"/events\", status_code=202)\nasync def process_event_safe(\n    event: UserCreatedEvent,\n    background_tasks: BackgroundTasks,\n    emitter: EventEmitter = fastapi.Depends(event_emitter_factory),\n) -&gt; dict:\n    \"\"\"Process event with error handling.\"\"\"\n    background_tasks.add_task(emit_event_safe, emitter, event)\n\n    return {\n        \"status\": \"accepted\",\n        \"event_id\": event.event_id\n    }\n</code></pre>"},{"location":"fastapi/#server-sent-events-sse-with-streaming","title":"Server-Sent Events (SSE) with Streaming","text":"<p>Server-Sent Events (SSE) allow you to stream data to clients in real-time. This is perfect for:</p> <ul> <li>Long-running operations with progress updates</li> <li>Batch processing with real-time feedback</li> <li>File processing with incremental results</li> </ul>"},{"location":"fastapi/#basic-sse-endpoint","title":"Basic SSE Endpoint","text":"<pre><code>import json\n\n@app.post(\"/process-files\")\nasync def process_files_stream(\n    command: ProcessFilesCommand,\n    mediator: cqrs.StreamingRequestMediator = fastapi.Depends(\n        streaming_mediator_factory\n    ),\n) -&gt; fastapi.responses.StreamingResponse:\n    \"\"\"Process files and stream results via SSE.\"\"\"\n\n    async def generate_sse():\n        \"\"\"Generate SSE events from streaming mediator.\"\"\"\n        try:\n            # Send initial event\n            yield f\"data: {json.dumps({'type': 'start', 'message': f'Processing {len(command.file_ids)} files...'})}\\n\\n\"\n\n            processed_count = 0\n\n            # Stream results from mediator\n            async for result in mediator.stream(command):\n                if result is None:\n                    continue\n\n                processed_count += 1\n\n                # Format result as SSE event\n                sse_data = {\n                    \"type\": \"progress\",\n                    \"data\": {\n                        \"file_id\": result.file_id,\n                        \"status\": result.status,\n                        \"progress\": {\n                            \"current\": processed_count,\n                            \"total\": len(command.file_ids),\n                            \"percentage\": int(\n                                (processed_count / len(command.file_ids)) * 100\n                            ),\n                        },\n                    },\n                }\n\n                yield f\"data: {json.dumps(sse_data)}\\n\\n\"\n\n            # Send completion event\n            completion_data = {\n                \"type\": \"complete\",\n                \"message\": f\"Successfully processed {processed_count} files\",\n                \"total_processed\": processed_count,\n            }\n            yield f\"data: {json.dumps(completion_data)}\\n\\n\"\n\n        except Exception as e:\n            error_data = {\n                \"type\": \"error\",\n                \"message\": str(e),\n            }\n            yield f\"data: {json.dumps(error_data)}\\n\\n\"\n\n    return fastapi.responses.StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"X-Accel-Buffering\": \"no\",  # Disable buffering in nginx\n        },\n    )\n</code></pre>"},{"location":"fastapi/#sse-with-query-parameters","title":"SSE with Query Parameters","text":"<pre><code>@app.post(\"/process\")\nasync def process_with_options(\n    command: ProcessCommand,\n    include_details: bool = fastapi.Query(False),\n    mediator: cqrs.StreamingRequestMediator = fastapi.Depends(\n        streaming_mediator_factory\n    ),\n) -&gt; fastapi.responses.StreamingResponse:\n    \"\"\"Process with streaming and query parameters.\"\"\"\n\n    async def generate_sse():\n        yield f\"data: {json.dumps({'type': 'start'})}\\n\\n\"\n\n        async for result in mediator.stream(command):\n            if result is None:\n                continue\n\n            sse_data = {\n                \"type\": \"progress\",\n                \"data\": result.model_dump(include=include_details),\n            }\n            yield f\"data: {json.dumps(sse_data)}\\n\\n\"\n\n        yield f\"data: {json.dumps({'type': 'complete'})}\\n\\n\"\n\n    return fastapi.responses.StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n    )\n</code></pre>"},{"location":"fastapi/#sse-with-path-parameters","title":"SSE with Path Parameters","text":"<pre><code>@app.post(\"/users/{user_id}/process\")\nasync def process_user_files(\n    user_id: str,\n    command: ProcessFilesCommand,\n    mediator: cqrs.StreamingRequestMediator = fastapi.Depends(\n        streaming_mediator_factory\n    ),\n) -&gt; fastapi.responses.StreamingResponse:\n    \"\"\"Process files for a specific user.\"\"\"\n\n    # Add user_id to command\n    command.user_id = user_id\n\n    async def generate_sse():\n        yield f\"data: {json.dumps({'type': 'start', 'user_id': user_id})}\\n\\n\"\n\n        async for result in mediator.stream(command):\n            if result is None:\n                continue\n            yield f\"data: {json.dumps(result.model_dump())}\\n\\n\"\n\n        yield f\"data: {json.dumps({'type': 'complete'})}\\n\\n\"\n\n    return fastapi.responses.StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n    )\n</code></pre>"},{"location":"fastapi/#complete-example","title":"Complete Example","text":"<p>Here's a complete FastAPI application demonstrating all integration patterns:</p> <pre><code>import functools\nimport json\nfrom fastapi import BackgroundTasks\n\nimport di\nimport fastapi\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.events import EventEmitter\nfrom cqrs.message_brokers import devnull\n\napp = fastapi.FastAPI(title=\"CQRS FastAPI Integration Example\")\n\n# ============================================================================\n# Mediator Factories\n# ============================================================================\n\n@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.RequestMediator:\n    \"\"\"Factory for RequestMediator - singleton pattern.\"\"\"\n    container = di.Container()\n    return bootstrap.bootstrap(\n        di_container=container,\n        commands_mapper=commands_mapper,\n        queries_mapper=queries_mapper,\n        domain_events_mapper=events_mapper,\n        message_broker=devnull.DevnullMessageBroker(),\n    )\n\n@functools.lru_cache(maxsize=1)\ndef streaming_mediator_factory() -&gt; cqrs.StreamingRequestMediator:\n    \"\"\"Factory for StreamingRequestMediator - singleton pattern.\"\"\"\n    container = di.Container()\n    return bootstrap.bootstrap_streaming(\n        di_container=container,\n        commands_mapper=commands_mapper,\n        domain_events_mapper=events_mapper,\n        max_concurrent_event_handlers=5,\n        concurrent_event_handle_enable=True,\n    )\n\n@functools.lru_cache(maxsize=1)\ndef event_emitter_factory() -&gt; EventEmitter:\n    \"\"\"Factory for EventEmitter - singleton pattern.\"\"\"\n    container = di.Container()\n    return bootstrap.setup_event_emitter(\n        container=container,\n        domain_events_mapper=events_mapper,\n    )\n\n# ============================================================================\n# Command Endpoints\n# ============================================================================\n\n@app.post(\"/users\", status_code=201)\nasync def create_user(\n    command: CreateUserCommand,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserCreatedResponse:\n    \"\"\"Create a new user.\"\"\"\n    return await mediator.send(command)\n\n@app.put(\"/users/{user_id}\")\nasync def update_user(\n    user_id: str,\n    command: UpdateUserCommand,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserUpdatedResponse:\n    \"\"\"Update an existing user.\"\"\"\n    command.user_id = user_id\n    return await mediator.send(command)\n\n@app.delete(\"/users/{user_id}\", status_code=200)\nasync def delete_user(\n    user_id: str,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserDeletedResponse:\n    \"\"\"Delete a user.\"\"\"\n    command = DeleteUserCommand(user_id=user_id)\n    return await mediator.send(command)\n\n# ============================================================================\n# Query Endpoints\n# ============================================================================\n\n@app.get(\"/users/{user_id}\")\nasync def get_user(\n    user_id: str,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserResponse:\n    \"\"\"Get user by ID.\"\"\"\n    query = GetUserQuery(user_id=user_id)\n    return await mediator.send(query)\n\n@app.get(\"/users\")\nasync def list_users(\n    page: int = fastapi.Query(1, ge=1),\n    page_size: int = fastapi.Query(10, ge=1, le=100),\n    search: str | None = fastapi.Query(None),\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; ListUsersResponse:\n    \"\"\"List users with pagination.\"\"\"\n    query = ListUsersQuery(page=page, page_size=page_size, search=search)\n    return await mediator.send(query)\n\n# ============================================================================\n# Event Processing Endpoints\n# ============================================================================\n\n@app.post(\"/events\", status_code=202)\nasync def process_event(\n    event: UserCreatedEvent,\n    background_tasks: BackgroundTasks,\n    emitter: EventEmitter = fastapi.Depends(event_emitter_factory),\n) -&gt; dict:\n    \"\"\"Process event asynchronously.\"\"\"\n    background_tasks.add_task(emitter.emit, event)\n    return {\n        \"status\": \"accepted\",\n        \"event_id\": event.event_id,\n        \"message\": \"Event will be processed in background\"\n    }\n\n@app.put(\"/events/{event_id}/process\", status_code=202)\nasync def process_event_by_id(\n    event_id: str,\n    event_data: dict,\n    background_tasks: BackgroundTasks,\n    emitter: EventEmitter = fastapi.Depends(event_emitter_factory),\n) -&gt; dict:\n    \"\"\"Process event by ID asynchronously.\"\"\"\n    event = UserCreatedEvent(\n        user_id=event_data.get(\"user_id\", event_id),\n        email=event_data.get(\"email\", \"\")\n    )\n    background_tasks.add_task(emitter.emit, event)\n    return {\n        \"status\": \"accepted\",\n        \"event_id\": event_id\n    }\n\n# ============================================================================\n# Streaming Endpoints\n# ============================================================================\n\n@app.post(\"/process-files\")\nasync def process_files_stream(\n    command: ProcessFilesCommand,\n    mediator: cqrs.StreamingRequestMediator = fastapi.Depends(\n        streaming_mediator_factory\n    ),\n) -&gt; fastapi.responses.StreamingResponse:\n    \"\"\"Process files and stream results via SSE.\"\"\"\n\n    async def generate_sse():\n        yield f\"data: {json.dumps({'type': 'start', 'message': f'Processing {len(command.file_ids)} files...'})}\\n\\n\"\n\n        processed_count = 0\n        async for result in mediator.stream(command):\n            if result is None:\n                continue\n\n            processed_count += 1\n            sse_data = {\n                \"type\": \"progress\",\n                \"data\": result.model_dump(),\n                \"progress\": {\n                    \"current\": processed_count,\n                    \"total\": len(command.file_ids),\n                    \"percentage\": int((processed_count / len(command.file_ids)) * 100),\n                },\n            }\n            yield f\"data: {json.dumps(sse_data)}\\n\\n\"\n\n        yield f\"data: {json.dumps({'type': 'complete', 'total_processed': processed_count})}\\n\\n\"\n\n    return fastapi.responses.StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n        },\n    )\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"fastapi/#best-practices","title":"Best Practices","text":""},{"location":"fastapi/#1-use-singleton-factories","title":"1. Use Singleton Factories","text":"<p>Use <code>@functools.lru_cache</code> to create singleton mediators for better performance:</p> <pre><code>@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.RequestMediator:\n    return bootstrap.bootstrap(...)\n</code></pre>"},{"location":"fastapi/#2-separate-factories","title":"2. Separate Factories","text":"<p>Create separate factories for different mediator types:</p> <pre><code>def mediator_factory() -&gt; cqrs.RequestMediator:\n    # For commands and queries\n    pass\n\ndef streaming_mediator_factory() -&gt; cqrs.StreamingRequestMediator:\n    # For streaming requests\n    pass\n\ndef event_emitter_factory() -&gt; EventEmitter:\n    # For background event processing\n    pass\n</code></pre>"},{"location":"fastapi/#3-error-handling","title":"3. Error Handling","text":"<p>Handle errors appropriately in endpoints:</p> <pre><code>from fastapi import HTTPException\n\n@app.post(\"/users\")\nasync def create_user(\n    command: CreateUserCommand,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n) -&gt; UserCreatedResponse:\n    try:\n        return await mediator.send(command)\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n</code></pre>"},{"location":"fastapi/#4-response-models","title":"4. Response Models","text":"<p>Always define response models for type safety:</p> <pre><code>@app.post(\"/users\", response_model=UserCreatedResponse, status_code=201)\nasync def create_user(...) -&gt; UserCreatedResponse:\n    ...\n</code></pre>"},{"location":"fastapi/#5-background-tasks","title":"5. Background Tasks","text":"<p>Use background tasks for long-running event processing:</p> <pre><code>@app.post(\"/events\")\nasync def process_event(\n    event: UserCreatedEvent,\n    background_tasks: BackgroundTasks,\n    emitter: EventEmitter = fastapi.Depends(event_emitter_factory),\n) -&gt; dict:\n    background_tasks.add_task(emitter.emit, event)\n    return {\"status\": \"accepted\"}\n</code></pre>"},{"location":"fastapi/#6-sse-headers","title":"6. SSE Headers","text":"<p>Always set proper headers for SSE:</p> <pre><code>return fastapi.responses.StreamingResponse(\n    generate_sse(),\n    media_type=\"text/event-stream\",\n    headers={\n        \"Cache-Control\": \"no-cache\",\n        \"Connection\": \"keep-alive\",\n        \"X-Accel-Buffering\": \"no\",  # For nginx\n    },\n)\n</code></pre>"},{"location":"fastapi/#7-path-parameters","title":"7. Path Parameters","text":"<p>Extract path parameters and set them in commands/queries:</p> <pre><code>@app.put(\"/users/{user_id}\")\nasync def update_user(\n    user_id: str,\n    command: UpdateUserCommand,\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n):\n    command.user_id = user_id  # Set from path\n    return await mediator.send(command)\n</code></pre>"},{"location":"fastapi/#8-query-parameters","title":"8. Query Parameters","text":"<p>Use FastAPI Query for validation and defaults:</p> <pre><code>@app.get(\"/users\")\nasync def list_users(\n    page: int = fastapi.Query(1, ge=1),\n    page_size: int = fastapi.Query(10, ge=1, le=100),\n    mediator: cqrs.RequestMediator = fastapi.Depends(mediator_factory),\n):\n    query = ListUsersQuery(page=page, page_size=page_size)\n    return await mediator.send(query)\n</code></pre>"},{"location":"faststream/","title":"FastStream Integration","text":""},{"location":"faststream/#overview","title":"Overview","text":"<p>FastStream is a powerful framework for building event-driven applications with message brokers. The <code>python-cqrs</code> package integrates seamlessly with FastStream to process events from Kafka and RabbitMQ using CQRS event handlers.</p> <p>Key Features:</p> <ul> <li>Kafka Support \u2014 Process events from Apache Kafka topics using <code>aiokafka</code></li> <li>RabbitMQ Support \u2014 Process events from RabbitMQ queues using <code>aiopika</code></li> <li>Type Safety \u2014 Full Pydantic v2 support for event payloads</li> <li>Dependency Injection \u2014 Use FastStream's <code>Depends()</code> for mediator injection</li> <li>Error Handling \u2014 Built-in deserialization error handling</li> <li>Auto-commit Control \u2014 Fine-grained control over message acknowledgment</li> </ul> <p>Prerequisites</p> <p>Understanding of Event Handling and Bootstrap is required. This integration shows how to consume events from message brokers.</p> <p>Related Topics</p> <ul> <li>Event Producing \u2014 For publishing events to message brokers</li> <li>Protobuf Integration \u2014 For Protobuf serialization/deserialization</li> <li>Transaction Outbox \u2014 For reliable event delivery</li> </ul>"},{"location":"faststream/#setup","title":"Setup","text":"<p>Install the required dependencies:</p> <pre><code># For Kafka\npip install faststream[kafka] python-cqrs di orjson\n\n# For RabbitMQ\npip install faststream[rabbit] python-cqrs di orjson\n\n# Or install both\npip install faststream[kafka,rabbit] python-cqrs di orjson\n</code></pre>"},{"location":"faststream/#kafka-integration-aiokafka","title":"Kafka Integration (aiokafka)","text":"<p>FastStream provides excellent support for Apache Kafka through <code>aiokafka</code>. This section shows how to consume events from Kafka topics and process them using CQRS event handlers.</p>"},{"location":"faststream/#basic-kafka-consumer-setup","title":"Basic Kafka Consumer Setup","text":"<pre><code>import di\nimport faststream\nimport cqrs\nfrom faststream import kafka\nfrom cqrs.events import bootstrap\nfrom cqrs import deserializers\n\n# Create Kafka broker\nbroker = kafka.KafkaBroker(bootstrap_servers=[\"localhost:9092\"])\napp = faststream.FastStream(broker)\n\n# Event Mediator Factory\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    container = di.Container()\n\n    def events_mapper(mapper: cqrs.EventMap) -&gt; None:\n        # Your event mappings here\n        mapper.bind(\n            cqrs.NotificationEvent[UserCreatedPayload],\n            UserCreatedEventHandler\n        )\n\n    return bootstrap.bootstrap(\n        di_container=container,\n        events_mapper=events_mapper,\n    )\n\n# Kafka subscriber\n@broker.subscriber(\n    \"user_events\",\n    group_id=\"my-service\",\n    auto_commit=False,\n    auto_offset_reset=\"earliest\",\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload],\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    await mediator.send(body)\n    await msg.ack()\n</code></pre>"},{"location":"faststream/#kafka-with-json-deserialization","title":"Kafka with JSON Deserialization","text":"<pre><code>from cqrs import deserializers\n\n@broker.subscriber(\n    \"user_events\",\n    group_id=\"my-service\",\n    auto_commit=False,\n    value_deserializer=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload]\n    | deserializers.DeserializeJsonError\n    | None,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    # Handle deserialization errors\n    if isinstance(body, deserializers.DeserializeJsonError):\n        print(f\"Deserialization error: {body}\")\n        await msg.nack()\n        return\n\n    if body is not None:\n        await mediator.send(body)\n        await msg.ack()\n</code></pre>"},{"location":"faststream/#kafka-with-custom-decoder","title":"Kafka with Custom Decoder","text":"<pre><code>from faststream import types\n\nasync def empty_message_decoder(\n    msg: kafka.KafkaMessage,\n    original_decoder: typing.Callable[\n        [kafka.KafkaMessage],\n        typing.Awaitable[types.DecodedMessage],\n    ],\n) -&gt; types.DecodedMessage | None:\n    \"\"\"Skip empty messages.\"\"\"\n    if not msg.body:\n        return None\n    return await original_decoder(msg)\n\n@broker.subscriber(\n    \"user_events\",\n    group_id=\"my-service\",\n    decoder=empty_message_decoder,\n    value_deserializer=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload] | None,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    if body is not None:\n        await mediator.send(body)\n    await msg.ack()\n</code></pre>"},{"location":"faststream/#kafka-consumer-configuration","title":"Kafka Consumer Configuration","text":"<pre><code>@broker.subscriber(\n    \"user_events\",\n    group_id=\"my-service\",\n    auto_commit=False,  # Manual commit control\n    auto_offset_reset=\"earliest\",  # Start from beginning\n    enable_auto_commit=False,\n    max_poll_records=100,  # Batch size\n    value_deserializer=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload],\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    try:\n        await mediator.send(body)\n        await msg.ack()  # Acknowledge after successful processing\n    except Exception as e:\n        print(f\"Error processing event: {e}\")\n        await msg.nack()  # Negative acknowledgment on error\n</code></pre>"},{"location":"faststream/#multiple-kafka-topics","title":"Multiple Kafka Topics","text":"<pre><code>@broker.subscriber(\n    \"user_events\",\n    group_id=\"my-service\",\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload],\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    await mediator.send(body)\n    await msg.ack()\n\n@broker.subscriber(\n    \"order_events\",\n    group_id=\"my-service\",\n)\nasync def handle_order_event(\n    body: cqrs.NotificationEvent[OrderCreatedPayload],\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    await mediator.send(body)\n    await msg.ack()\n</code></pre>"},{"location":"faststream/#rabbitmq-integration-aiopika","title":"RabbitMQ Integration (aiopika)","text":"<p>FastStream also supports RabbitMQ through <code>aiopika</code>. This section shows how to consume events from RabbitMQ queues.</p>"},{"location":"faststream/#basic-rabbitmq-consumer-setup","title":"Basic RabbitMQ Consumer Setup","text":"<pre><code>import di\nimport faststream\nimport cqrs\nfrom faststream import rabbitmq\nfrom cqrs.events import bootstrap\nfrom cqrs import deserializers\n\n# Create RabbitMQ broker\nbroker = rabbitmq.RabbitBroker(\"amqp://guest:guest@localhost:5672/\")\napp = faststream.FastStream(broker)\n\n# Event Mediator Factory\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    container = di.Container()\n\n    def events_mapper(mapper: cqrs.EventMap) -&gt; None:\n        mapper.bind(\n            cqrs.NotificationEvent[UserCreatedPayload],\n            UserCreatedEventHandler\n        )\n\n    return bootstrap.bootstrap(\n        di_container=container,\n        events_mapper=events_mapper,\n    )\n\n# RabbitMQ subscriber\n@broker.subscriber(\"user_events\")\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload],\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    await mediator.send(body)\n</code></pre>"},{"location":"faststream/#rabbitmq-with-json-deserialization","title":"RabbitMQ with JSON Deserialization","text":"<pre><code>@broker.subscriber(\n    \"user_events\",\n    parser=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload]\n    | deserializers.DeserializeJsonError,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    if isinstance(body, deserializers.DeserializeJsonError):\n        print(f\"Deserialization error: {body}\")\n        return\n\n    await mediator.send(body)\n</code></pre>"},{"location":"faststream/#rabbitmq-queue-configuration","title":"RabbitMQ Queue Configuration","text":"<pre><code>@broker.subscriber(\n    \"user_events\",\n    queue=\"user_events_queue\",\n    exchange=\"events\",\n    routing_key=\"user.created\",\n    durable=True,  # Make queue durable\n    auto_delete=False,\n    parser=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload],\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    await mediator.send(body)\n</code></pre>"},{"location":"faststream/#rabbitmq-with-manual-acknowledgment","title":"RabbitMQ with Manual Acknowledgment","text":"<pre><code>@broker.subscriber(\n    \"user_events\",\n    ack=True,  # Enable manual acknowledgment\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload],\n    message: rabbitmq.RabbitMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    try:\n        await mediator.send(body)\n        await message.ack()  # Acknowledge after successful processing\n    except Exception as e:\n        print(f\"Error processing event: {e}\")\n        await message.nack()  # Negative acknowledgment on error\n</code></pre>"},{"location":"faststream/#rabbitmq-multiple-queues","title":"RabbitMQ Multiple Queues","text":"<pre><code>@broker.subscriber(\"user_events\")\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload],\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    await mediator.send(body)\n\n@broker.subscriber(\"order_events\")\nasync def handle_order_event(\n    body: cqrs.NotificationEvent[OrderCreatedPayload],\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    await mediator.send(body)\n</code></pre> <p>For Protobuf event handling, see the Protobuf Integration documentation.</p>"},{"location":"faststream/#event-mediator-factory","title":"Event Mediator Factory","text":"<p>The event mediator factory is crucial for dependency injection in FastStream subscribers. Here are different patterns:</p>"},{"location":"faststream/#singleton-mediator-recommended","title":"Singleton Mediator (Recommended)","text":"<pre><code>import functools\nimport di\nimport cqrs\nfrom cqrs.events import bootstrap\n\n@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    \"\"\"Singleton mediator - created once and reused.\"\"\"\n    container = di.Container()\n\n    def events_mapper(mapper: cqrs.EventMap) -&gt; None:\n        mapper.bind(\n            cqrs.NotificationEvent[UserCreatedPayload],\n            UserCreatedEventHandler\n        )\n\n    return bootstrap.bootstrap(\n        di_container=container,\n        events_mapper=events_mapper,\n    )\n</code></pre>"},{"location":"faststream/#per-request-mediator","title":"Per-Request Mediator","text":"<pre><code>def mediator_factory() -&gt; cqrs.EventMediator:\n    \"\"\"Create new mediator for each request.\"\"\"\n    container = di.Container()\n\n    def events_mapper(mapper: cqrs.EventMap) -&gt; None:\n        mapper.bind(\n            cqrs.NotificationEvent[UserCreatedPayload],\n            UserCreatedEventHandler\n        )\n\n    return bootstrap.bootstrap(\n        di_container=container,\n        events_mapper=events_mapper,\n    )\n</code></pre>"},{"location":"faststream/#mediator-with-custom-middlewares","title":"Mediator with Custom Middlewares","text":"<pre><code>import functools\nfrom cqrs.middlewares import base\n\nclass EventLoggingMiddleware(base.Middleware):\n    async def __call__(self, request: cqrs.Request, handle):\n        print(f\"Processing event: {type(request).__name__}\")\n        result = await handle(request)\n        print(f\"Event processed: {type(request).__name__}\")\n        return result\n\n@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    container = di.Container()\n\n    def events_mapper(mapper: cqrs.EventMap) -&gt; None:\n        mapper.bind(\n            cqrs.NotificationEvent[UserCreatedPayload],\n            UserCreatedEventHandler\n        )\n\n    return bootstrap.bootstrap(\n        di_container=container,\n        events_mapper=events_mapper,\n        middlewares=[EventLoggingMiddleware()],\n    )\n</code></pre>"},{"location":"faststream/#event-deserialization","title":"Event Deserialization","text":"<p>FastStream requires proper deserialization of messages from brokers. The <code>python-cqrs</code> package provides <code>JsonDeserializer</code> for this purpose.</p>"},{"location":"faststream/#basic-deserialization","title":"Basic Deserialization","text":"<pre><code>from cqrs import deserializers\n\n@broker.subscriber(\n    \"user_events\",\n    value_deserializer=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload]\n    | deserializers.DeserializeJsonError\n    | None,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    if isinstance(body, deserializers.DeserializeJsonError):\n        # Handle deserialization error\n        print(f\"Failed to deserialize: {body}\")\n        await msg.nack()\n        return\n\n    if body is not None:\n        await mediator.send(body)\n        await msg.ack()\n</code></pre>"},{"location":"faststream/#error-handling","title":"Error Handling","text":"<pre><code>@broker.subscriber(\n    \"user_events\",\n    value_deserializer=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload]\n    | deserializers.DeserializeJsonError\n    | None,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    # Check for deserialization errors\n    if isinstance(body, deserializers.DeserializeJsonError):\n        # Log error and send to DLQ (Dead Letter Queue)\n        print(f\"Deserialization error: {body.error}\")\n        await msg.nack()  # Don't acknowledge, message will be retried\n        return\n\n    # Check for None (empty message)\n    if body is None:\n        await msg.ack()  # Acknowledge empty messages\n        return\n\n    # Process valid event\n    try:\n        await mediator.send(body)\n        await msg.ack()\n    except Exception as e:\n        print(f\"Error processing event: {e}\")\n        await msg.nack()  # Retry on processing error\n</code></pre>"},{"location":"faststream/#complete-examples","title":"Complete Examples","text":""},{"location":"faststream/#kafka-complete-example","title":"Kafka Complete Example","text":"<pre><code>import asyncio\nimport functools\nimport logging\nimport typing\n\nimport di\nimport faststream\nimport orjson\nimport pydantic\nfrom faststream import kafka, types\n\nimport cqrs\nfrom cqrs import deserializers\nfrom cqrs.events import bootstrap\n\nlogging.basicConfig(level=logging.INFO)\nlogging.getLogger(\"aiokafka\").setLevel(logging.ERROR)\n\n# Create Kafka broker\nbroker = kafka.KafkaBroker(bootstrap_servers=[\"localhost:9092\"])\napp = faststream.FastStream(broker)\n\n# Event payload\nclass UserCreatedPayload(pydantic.BaseModel):\n    user_id: str\n    email: str\n    name: str\n\n# Event handler (defined elsewhere)\nclass UserCreatedEventHandler(\n    cqrs.EventHandler[cqrs.NotificationEvent[UserCreatedPayload]]\n):\n    async def handle(\n        self, event: cqrs.NotificationEvent[UserCreatedPayload]\n    ) -&gt; None:\n        print(f\"User {event.payload.user_id} created: {event.payload.email}\")\n\n# Event mapper\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(\n        cqrs.NotificationEvent[UserCreatedPayload],\n        UserCreatedEventHandler\n    )\n\n# Mediator factory\n@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    return bootstrap.bootstrap(\n        di_container=di.Container(),\n        events_mapper=events_mapper,\n    )\n\n# Custom decoder\nasync def empty_message_decoder(\n    msg: kafka.KafkaMessage,\n    original_decoder: typing.Callable[\n        [kafka.KafkaMessage],\n        typing.Awaitable[types.DecodedMessage],\n    ],\n) -&gt; types.DecodedMessage | None:\n    if not msg.body:\n        return None\n    return await original_decoder(msg)\n\n# Kafka subscriber\n@broker.subscriber(\n    \"user_events\",\n    group_id=\"user-service\",\n    auto_commit=False,\n    auto_offset_reset=\"earliest\",\n    value_deserializer=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n    decoder=empty_message_decoder,\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload]\n    | deserializers.DeserializeJsonError\n    | None,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    if isinstance(body, deserializers.DeserializeJsonError):\n        print(f\"Deserialization error: {body}\")\n        await msg.nack()\n        return\n\n    if body is not None:\n        await mediator.send(body)\n        await msg.ack()\n\nif __name__ == \"__main__\":\n    asyncio.run(app.run())\n</code></pre>"},{"location":"faststream/#rabbitmq-complete-example","title":"RabbitMQ Complete Example","text":"<pre><code>import functools\nimport logging\n\nimport di\nimport faststream\nimport pydantic\nfrom faststream import rabbitmq\n\nimport cqrs\nfrom cqrs import deserializers\nfrom cqrs.events import bootstrap\n\nlogging.basicConfig(level=logging.INFO)\n\n# Create RabbitMQ broker\nbroker = rabbitmq.RabbitBroker(\"amqp://guest:guest@localhost:5672/\")\napp = faststream.FastStream(broker)\n\n# Event payload\nclass UserCreatedPayload(pydantic.BaseModel):\n    user_id: str\n    email: str\n    name: str\n\n# Event handler (defined elsewhere)\nclass UserCreatedEventHandler(\n    cqrs.EventHandler[cqrs.NotificationEvent[UserCreatedPayload]]\n):\n    async def handle(\n        self, event: cqrs.NotificationEvent[UserCreatedPayload]\n    ) -&gt; None:\n        print(f\"User {event.payload.user_id} created: {event.payload.email}\")\n\n# Event mapper\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(\n        cqrs.NotificationEvent[UserCreatedPayload],\n        UserCreatedEventHandler\n    )\n\n# Mediator factory\n@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    return bootstrap.bootstrap(\n        di_container=di.Container(),\n        events_mapper=events_mapper,\n    )\n\n# RabbitMQ subscriber\n@broker.subscriber(\n    \"user_events\",\n    queue=\"user_events_queue\",\n    exchange=\"events\",\n    routing_key=\"user.created\",\n    durable=True,\n    parser=deserializers.JsonDeserializer(\n        model=cqrs.NotificationEvent[UserCreatedPayload],\n    ),\n)\nasync def handle_user_event(\n    body: cqrs.NotificationEvent[UserCreatedPayload]\n    | deserializers.DeserializeJsonError,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    if isinstance(body, deserializers.DeserializeJsonError):\n        print(f\"Deserialization error: {body}\")\n        return\n\n    await mediator.send(body)\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(app.run())\n</code></pre>"},{"location":"faststream/#best-practices","title":"Best Practices","text":""},{"location":"faststream/#1-use-singleton-mediator-factory","title":"1. Use Singleton Mediator Factory","text":"<p>Always use <code>@functools.lru_cache</code> for mediator factory to avoid recreating mediators:</p> <pre><code>@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    return bootstrap.bootstrap(...)\n</code></pre>"},{"location":"faststream/#2-handle-deserialization-errors","title":"2. Handle Deserialization Errors","text":"<p>Always check for <code>DeserializeJsonError</code> before processing:</p> <pre><code>if isinstance(body, deserializers.DeserializeJsonError):\n    # Handle error\n    await msg.nack()\n    return\n</code></pre>"},{"location":"faststream/#3-manual-acknowledgment","title":"3. Manual Acknowledgment","text":"<p>Use manual acknowledgment for better control:</p> <pre><code>@broker.subscriber(\n    \"events\",\n    auto_commit=False,  # Kafka\n    ack=True,  # RabbitMQ\n)\nasync def handle_event(...):\n    try:\n        await mediator.send(body)\n        await msg.ack()  # Acknowledge success\n    except Exception as e:\n        await msg.nack()  # Retry on error\n</code></pre>"},{"location":"faststream/#4-error-handling","title":"4. Error Handling","text":"<p>Wrap event processing in try-except:</p> <pre><code>async def handle_event(...):\n    try:\n        await mediator.send(body)\n        await msg.ack()\n    except Exception as e:\n        print(f\"Error: {e}\")\n        await msg.nack()  # Retry\n</code></pre>"},{"location":"faststream/#5-logging-configuration","title":"5. Logging Configuration","text":"<p>Suppress verbose broker logging:</p> <pre><code>logging.getLogger(\"aiokafka\").setLevel(logging.ERROR)  # Kafka\nlogging.getLogger(\"aio_pika\").setLevel(logging.ERROR)  # RabbitMQ\n</code></pre>"},{"location":"faststream/#6-empty-message-handling","title":"6. Empty Message Handling","text":"<p>Handle empty messages gracefully:</p> <pre><code>async def empty_message_decoder(...):\n    if not msg.body:\n        return None\n    return await original_decoder(msg)\n</code></pre>"},{"location":"faststream/#7-multiple-event-types","title":"7. Multiple Event Types","text":"<p>Use separate subscribers for different event types:</p> <pre><code>@broker.subscriber(\"user_events\")\nasync def handle_user_event(...):\n    ...\n\n@broker.subscriber(\"order_events\")\nasync def handle_order_event(...):\n    ...\n</code></pre>"},{"location":"protobuf/","title":"Protobuf Integration","text":""},{"location":"protobuf/#overview","title":"Overview","text":"<p>Protobuf (Protocol Buffers) provides efficient binary serialization for events, offering significant advantages over JSON:</p> <ul> <li>Performance \u2014 Faster serialization/deserialization</li> <li>Size \u2014 Compact binary format reduces message size by 30-50%</li> <li>Schema Evolution \u2014 Backward and forward compatibility</li> <li>Type Safety \u2014 Strong typing with generated code</li> <li>Schema Registry \u2014 Centralized schema management</li> </ul> <p>The <code>python-cqrs</code> package supports Protobuf serialization/deserialization for both Kafka and RabbitMQ through FastStream integration.</p> <p>Prerequisites</p> <p>Understanding of Event Producing and FastStream Integration is recommended. Protobuf is an advanced feature for high-performance scenarios.</p> <p>When to Use</p> <p>Use Protobuf when you need better performance, smaller message sizes, or schema evolution. For most use cases, JSON serialization (default) is sufficient.</p>"},{"location":"protobuf/#setup","title":"Setup","text":"<p>Install the required dependencies:</p> <pre><code>pip install python-cqrs faststream[kafka] protobuf confluent-kafka[protobuf]\n</code></pre> <p>For RabbitMQ:</p> <pre><code>pip install python-cqrs faststream[rabbit] protobuf\n</code></pre>"},{"location":"protobuf/#protobuf-event-definition","title":"Protobuf Event Definition","text":"<p>Events that support Protobuf must implement the <code>proto()</code> method that converts the event to Protobuf format.</p>"},{"location":"protobuf/#basic-event-definition","title":"Basic Event Definition","text":"<pre><code>import pydantic\nimport cqrs\nfrom your_proto_module import UserCreatedProtobuf  # Generated Protobuf class\n\nclass UserCreatedPayload(pydantic.BaseModel, frozen=True):\n    user_id: str\n    email: str\n    name: str\n\nclass UserCreatedEvent(cqrs.NotificationEvent[UserCreatedPayload], frozen=True):\n    def proto(self) -&gt; UserCreatedProtobuf:\n        \"\"\"Convert event to Protobuf format.\"\"\"\n        return UserCreatedProtobuf(\n            event_id=str(self.event_id),\n            event_timestamp=str(self.event_timestamp),\n            event_name=self.event_name,\n            payload=UserCreatedProtobuf.Payload(\n                user_id=self.payload.user_id,\n                email=self.payload.email,\n                name=self.payload.name,\n            ),\n        )\n</code></pre>"},{"location":"protobuf/#event-with-nested-payloads","title":"Event with Nested Payloads","text":"<pre><code>class AddressPayload(pydantic.BaseModel, frozen=True):\n    street: str\n    city: str\n    zip_code: str\n\nclass UserCreatedPayload(pydantic.BaseModel, frozen=True):\n    user_id: str\n    email: str\n    name: str\n    address: AddressPayload\n\nclass UserCreatedEvent(cqrs.NotificationEvent[UserCreatedPayload], frozen=True):\n    def proto(self) -&gt; UserCreatedProtobuf:\n        return UserCreatedProtobuf(\n            event_id=str(self.event_id),\n            event_timestamp=str(self.event_timestamp),\n            event_name=self.event_name,\n            payload=UserCreatedProtobuf.Payload(\n                user_id=self.payload.user_id,\n                email=self.payload.email,\n                name=self.payload.name,\n                address=UserCreatedProtobuf.Payload.Address(\n                    street=self.payload.address.street,\n                    city=self.payload.address.city,\n                    zip_code=self.payload.address.zip_code,\n                ),\n            ),\n        )\n</code></pre>"},{"location":"protobuf/#event-producing-with-protobuf","title":"Event Producing with Protobuf","text":""},{"location":"protobuf/#kafka-producer-with-protobuf-serialization","title":"Kafka Producer with Protobuf Serialization","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import kafka\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\nfrom cqrs.serializers import protobuf\n\n# Create Kafka producer with Protobuf serializer\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    client_id=\"my-app\",\n    security_protocol=\"PLAINTEXT\",  # Or \"SASL_SSL\" for production\n    sasl_mechanism=\"PLAIN\",\n    value_serializer=protobuf.protobuf_value_serializer,\n)\n\n# Create message broker\nkafka_broker = kafka.KafkaMessageBroker(\n    producer=kafka_producer,\n    aiokafka_log_level=\"ERROR\",\n)\n\n# Bootstrap with Protobuf-enabled broker\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=kafka_broker,\n)\n</code></pre>"},{"location":"protobuf/#protobuf-producer-with-ssl","title":"Protobuf Producer with SSL","text":"<pre><code>import ssl\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\nfrom cqrs.serializers import protobuf\n\n# Create SSL context\nssl_context = ssl.create_default_context()\n\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"kafka.example.com:9093\"],\n    security_protocol=\"SASL_SSL\",\n    sasl_mechanism=\"SCRAM-SHA-256\",\n    sasl_plain_username=\"username\",\n    sasl_plain_password=\"password\",\n    ssl_context=ssl_context,\n    value_serializer=protobuf.protobuf_value_serializer,\n)\n\nkafka_broker = kafka.KafkaMessageBroker(producer=kafka_producer)\n</code></pre>"},{"location":"protobuf/#direct-event-publishing","title":"Direct Event Publishing","text":"<pre><code>import asyncio\nimport os\nimport cqrs\nfrom cqrs.message_brokers import kafka, protocol as broker_protocol\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\nfrom cqrs.serializers import protobuf\n\n# Set schema registry URL\nos.environ[\"KAFKA_SCHEMA_REGISTRY_URL\"] = \"http://localhost:8085\"\n\nasync def produce_protobuf_event():\n    # Create event\n    event = UserCreatedEvent(\n        event_name=\"user_created\",\n        topic=\"user_events_proto\",\n        payload=UserCreatedPayload(\n            user_id=\"123\",\n            email=\"user@example.com\",\n            name=\"John Doe\"\n        ),\n    )\n\n    # Create Kafka producer with Protobuf serializer\n    kafka_producer = KafkaProducerAdapter(\n        bootstrap_servers=[\"localhost:9092\"],\n        value_serializer=protobuf.protobuf_value_serializer,\n    )\n\n    # Create message broker\n    broker = kafka.KafkaMessageBroker(producer=kafka_producer)\n\n    # Publish event\n    await broker.send_message(\n        message=broker_protocol.Message(\n            message_name=event.event_name,\n            message_id=event.event_id,\n            topic=event.topic,\n            payload=event.model_dump(mode=\"json\"),\n        ),\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(produce_protobuf_event())\n</code></pre>"},{"location":"protobuf/#event-consuming-with-protobuf","title":"Event Consuming with Protobuf","text":""},{"location":"protobuf/#kafka-consumer-with-protobuf-deserialization","title":"Kafka Consumer with Protobuf Deserialization","text":"<pre><code>import di\nimport faststream\nimport cqrs\nfrom faststream import kafka\nfrom cqrs.events import bootstrap\nfrom cqrs.deserializers import protobuf\nfrom your_proto_module import UserCreatedProtobuf\n\nbroker = kafka.KafkaBroker(bootstrap_servers=[\"localhost:9092\"])\napp = faststream.FastStream(broker)\n\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    container = di.Container()\n\n    def events_mapper(mapper: cqrs.EventMap) -&gt; None:\n        mapper.bind(UserCreatedEvent, UserCreatedEventHandler)\n\n    return bootstrap.bootstrap(\n        di_container=container,\n        events_mapper=events_mapper,\n    )\n\n@broker.subscriber(\n    \"user_events_proto\",\n    group_id=\"protobuf-consumers\",\n    auto_commit=False,\n    auto_offset_reset=\"earliest\",\n    value_deserializer=protobuf.ProtobufValueDeserializer(\n        model=UserCreatedEvent,\n        protobuf_model=UserCreatedProtobuf,\n    ),\n)\nasync def handle_user_event(\n    body: UserCreatedEvent | protobuf.DeserializeProtobufError,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    # Handle deserialization errors\n    if isinstance(body, protobuf.DeserializeProtobufError):\n        print(f\"Protobuf deserialization error: {body.error_message}\")\n        await msg.nack()\n        return\n\n    # Process valid event\n    await mediator.send(body)\n    await msg.ack()\n</code></pre>"},{"location":"protobuf/#protobuf-error-handling","title":"Protobuf Error Handling","text":"<pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\n@broker.subscriber(\n    \"user_events_proto\",\n    value_deserializer=protobuf.ProtobufValueDeserializer(\n        model=UserCreatedEvent,\n        protobuf_model=UserCreatedProtobuf,\n    ),\n)\nasync def handle_user_event(\n    body: UserCreatedEvent | protobuf.DeserializeProtobufError | None,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    # Check for deserialization errors\n    if isinstance(body, protobuf.DeserializeProtobufError):\n        logger.error(\n            f\"Failed to deserialize Protobuf message: {body.error_message}\",\n            extra={\n                \"error_type\": body.error_type.__name__,\n                \"message_data\": body.message_data.hex()[:100],  # First 100 bytes\n            }\n        )\n        await msg.nack()  # Retry or send to DLQ\n        return\n\n    # Check for None (empty message)\n    if body is None:\n        await msg.ack()\n        return\n\n    # Process valid event\n    try:\n        await mediator.send(body)\n        await msg.ack()\n    except Exception as e:\n        logger.error(f\"Error processing event: {e}\")\n        await msg.nack()\n</code></pre>"},{"location":"protobuf/#custom-decoder-for-protobuf","title":"Custom Decoder for Protobuf","text":"<pre><code>import typing\nfrom faststream import types\n\nasync def protobuf_message_decoder(\n    msg: kafka.KafkaMessage,\n    original_decoder: typing.Callable[\n        [kafka.KafkaMessage],\n        typing.Awaitable[types.DecodedMessage],\n    ],\n) -&gt; types.DecodedMessage | None:\n    \"\"\"Skip empty messages and handle Protobuf decoding.\"\"\"\n    if not msg.body:\n        return None\n\n    # Additional validation can be added here\n    if len(msg.body) &lt; 10:  # Minimum Protobuf message size\n        return None\n\n    return await original_decoder(msg)\n\n@broker.subscriber(\n    \"user_events_proto\",\n    decoder=protobuf_message_decoder,\n    value_deserializer=protobuf.ProtobufValueDeserializer(\n        model=UserCreatedEvent,\n        protobuf_model=UserCreatedProtobuf,\n    ),\n)\nasync def handle_user_event(\n    body: UserCreatedEvent | protobuf.DeserializeProtobufError | None,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    if isinstance(body, protobuf.DeserializeProtobufError):\n        await msg.nack()\n        return\n\n    if body is not None:\n        await mediator.send(body)\n        await msg.ack()\n</code></pre>"},{"location":"protobuf/#schema-registry","title":"Schema Registry","text":"<p>Protobuf serialization uses Confluent Schema Registry for schema management. The Schema Registry ensures schema compatibility and versioning.</p>"},{"location":"protobuf/#schema-registry-configuration","title":"Schema Registry Configuration","text":"<pre><code>import os\nfrom cqrs.serializers import protobuf\n\n# Set schema registry URL (defaults to http://localhost:8085)\nos.environ[\"KAFKA_SCHEMA_REGISTRY_URL\"] = \"http://schema-registry:8085\"\n\n# The protobuf_value_serializer automatically uses Schema Registry\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    value_serializer=protobuf.protobuf_value_serializer,\n)\n</code></pre>"},{"location":"protobuf/#schema-registry-with-authentication","title":"Schema Registry with Authentication","text":"<pre><code>import os\nfrom confluent_kafka import schema_registry\n\n# Configure Schema Registry with authentication\nschema_registry_client = schema_registry.SchemaRegistryClient({\n    \"url\": \"https://schema-registry.example.com\",\n    \"basic.auth.user.info\": \"username:password\",\n})\n\n# Custom serializer with authenticated client\ndef custom_protobuf_serializer(event: cqrs.NotificationEvent):\n    protobuf_event = event.proto()\n    protobuf_serializer = protobuf.ProtobufSerializer(\n        protobuf_event.__class__,\n        schema_registry_client,\n        {\"use.deprecated.format\": False},\n    )\n    # ... serialization logic\n</code></pre>"},{"location":"protobuf/#complete-examples","title":"Complete Examples","text":""},{"location":"protobuf/#complete-producer-example","title":"Complete Producer Example","text":"<pre><code>import asyncio\nimport os\nimport ssl\n\nimport pydantic\nimport cqrs\nfrom cqrs.message_brokers import kafka, protocol as broker_protocol\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\nfrom cqrs.serializers import protobuf\nfrom your_proto_module import UserCreatedProtobuf\n\n# Set schema registry URL\nos.environ[\"KAFKA_SCHEMA_REGISTRY_URL\"] = \"http://localhost:8085\"\n\n# Event payload\nclass UserCreatedPayload(pydantic.BaseModel, frozen=True):\n    user_id: str\n    email: str\n    name: str\n\n# Event with Protobuf support\nclass UserCreatedEvent(cqrs.NotificationEvent[UserCreatedPayload], frozen=True):\n    def proto(self) -&gt; UserCreatedProtobuf:\n        return UserCreatedProtobuf(\n            event_id=str(self.event_id),\n            event_timestamp=str(self.event_timestamp),\n            event_name=self.event_name,\n            payload=UserCreatedProtobuf.Payload(\n                user_id=self.payload.user_id,\n                email=self.payload.email,\n                name=self.payload.name,\n            ),\n        )\n\nasync def produce_protobuf_event():\n    # Create event\n    event = UserCreatedEvent(\n        event_name=\"user_created\",\n        topic=\"user_events_proto\",\n        payload=UserCreatedPayload(\n            user_id=\"123\",\n            email=\"user@example.com\",\n            name=\"John Doe\"\n        ),\n    )\n\n    # Create Kafka producer with Protobuf serializer\n    kafka_producer = KafkaProducerAdapter(\n        bootstrap_servers=[\"localhost:9092\"],\n        value_serializer=protobuf.protobuf_value_serializer,\n    )\n\n    # Create message broker\n    broker = kafka.KafkaMessageBroker(producer=kafka_producer)\n\n    # Publish event\n    await broker.send_message(\n        message=broker_protocol.Message(\n            message_name=event.event_name,\n            message_id=event.event_id,\n            topic=event.topic,\n            payload=event.model_dump(mode=\"json\"),\n        ),\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(produce_protobuf_event())\n</code></pre>"},{"location":"protobuf/#complete-consumer-example","title":"Complete Consumer Example","text":"<pre><code>import asyncio\nimport functools\nimport logging\n\nimport di\nimport faststream\nimport pydantic\nfrom faststream import kafka\n\nimport cqrs\nfrom cqrs.deserializers import protobuf\nfrom cqrs.events import bootstrap\nfrom your_proto_module import UserCreatedProtobuf\n\nlogging.basicConfig(level=logging.INFO)\nlogging.getLogger(\"aiokafka\").setLevel(logging.ERROR)\n\nbroker = kafka.KafkaBroker(bootstrap_servers=[\"localhost:9092\"])\napp = faststream.FastStream(broker)\n\n# Event payload\nclass UserCreatedPayload(pydantic.BaseModel, frozen=True):\n    user_id: str\n    email: str\n    name: str\n\n# Event with Protobuf support\nclass UserCreatedEvent(cqrs.NotificationEvent[UserCreatedPayload], frozen=True):\n    def proto(self) -&gt; UserCreatedProtobuf:\n        return UserCreatedProtobuf(\n            event_id=str(self.event_id),\n            event_timestamp=str(self.event_timestamp),\n            event_name=self.event_name,\n            payload=UserCreatedProtobuf.Payload(\n                user_id=self.payload.user_id,\n                email=self.payload.email,\n                name=self.payload.name,\n            ),\n        )\n\n# Event handler (defined elsewhere)\nclass UserCreatedEventHandler(cqrs.EventHandler[UserCreatedEvent]):\n    async def handle(self, event: UserCreatedEvent) -&gt; None:\n        print(f\"User {event.payload.user_id} created: {event.payload.email}\")\n\n# Event mapper\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(UserCreatedEvent, UserCreatedEventHandler)\n\n# Mediator factory\n@functools.lru_cache(maxsize=1)\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    return bootstrap.bootstrap(\n        di_container=di.Container(),\n        events_mapper=events_mapper,\n    )\n\n# Kafka subscriber with Protobuf\n@broker.subscriber(\n    \"user_events_proto\",\n    group_id=\"protobuf-service\",\n    auto_commit=False,\n    auto_offset_reset=\"earliest\",\n    value_deserializer=protobuf.ProtobufValueDeserializer(\n        model=UserCreatedEvent,\n        protobuf_model=UserCreatedProtobuf,\n    ),\n)\nasync def handle_user_event(\n    body: UserCreatedEvent | protobuf.DeserializeProtobufError | None,\n    msg: kafka.KafkaMessage,\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    if isinstance(body, protobuf.DeserializeProtobufError):\n        print(f\"Deserialization error: {body.error_message}\")\n        await msg.nack()\n        return\n\n    if body is not None:\n        await mediator.send(body)\n        await msg.ack()\n\nif __name__ == \"__main__\":\n    asyncio.run(app.run())\n</code></pre>"},{"location":"protobuf/#best-practices","title":"Best Practices","text":""},{"location":"protobuf/#1-always-use-schema-registry","title":"1. Always Use Schema Registry","text":"<p>Schema Registry ensures schema compatibility and versioning:</p> <pre><code>os.environ[\"KAFKA_SCHEMA_REGISTRY_URL\"] = \"http://schema-registry:8085\"\n</code></pre>"},{"location":"protobuf/#2-handle-deserialization-errors","title":"2. Handle Deserialization Errors","text":"<p>Always check for <code>DeserializeProtobufError</code>:</p> <pre><code>if isinstance(body, protobuf.DeserializeProtobufError):\n    logger.error(f\"Deserialization error: {body.error_message}\")\n    await msg.nack()\n    return\n</code></pre>"},{"location":"protobuf/#3-use-frozen-models","title":"3. Use Frozen Models","text":"<p>Use <code>frozen=True</code> for event payloads to ensure immutability:</p> <pre><code>class UserCreatedPayload(pydantic.BaseModel, frozen=True):\n    user_id: str\n    email: str\n</code></pre>"},{"location":"protobuf/#4-implement-proto-method-correctly","title":"4. Implement proto() Method Correctly","text":"<p>Ensure the <code>proto()</code> method correctly maps all fields:</p> <pre><code>def proto(self) -&gt; UserCreatedProtobuf:\n    return UserCreatedProtobuf(\n        event_id=str(self.event_id),\n        event_timestamp=str(self.event_timestamp),\n        event_name=self.event_name,\n        payload=UserCreatedProtobuf.Payload(\n            # Map all payload fields\n        ),\n    )\n</code></pre>"},{"location":"protobuf/#5-schema-evolution","title":"5. Schema Evolution","text":"<p>Protobuf supports schema evolution. When adding new fields:</p> <ul> <li>Use optional fields for backward compatibility</li> <li>Don't remove fields, mark them as deprecated</li> <li>Test schema compatibility before deployment</li> </ul>"},{"location":"protobuf/#6-error-logging","title":"6. Error Logging","text":"<p>Log deserialization errors with context:</p> <pre><code>if isinstance(body, protobuf.DeserializeProtobufError):\n    logger.error(\n        f\"Failed to deserialize Protobuf message: {body.error_message}\",\n        extra={\n            \"error_type\": body.error_type.__name__,\n            \"topic\": msg.topic,\n            \"partition\": msg.partition,\n        }\n    )\n</code></pre>"},{"location":"protobuf/#7-performance-considerations","title":"7. Performance Considerations","text":"<ul> <li>Protobuf is faster than JSON for large payloads</li> <li>Use Protobuf for high-throughput scenarios</li> <li>Consider compression for very large messages</li> <li>Monitor schema registry performance</li> </ul>"},{"location":"protobuf/#8-testing","title":"8. Testing","text":"<p>Test Protobuf serialization/deserialization:</p> <pre><code># Test event to Protobuf conversion\nevent = UserCreatedEvent(...)\nproto_event = event.proto()\nassert proto_event.event_id == str(event.event_id)\n\n# Test Protobuf to event conversion\ndeserialized = UserCreatedEvent.model_validate(proto_event)\nassert deserialized.event_id == event.event_id\n</code></pre>"},{"location":"bootstrap/","title":"Bootstrap","text":""},{"location":"bootstrap/#overview","title":"Overview","text":"<ul> <li> <p> Request Mediator</p> <p>Standard mediator for commands and queries with automatic handler resolution.</p> <p> Read More</p> </li> <li> <p> Streaming Request Mediator</p> <p>For incremental processing and Server-Sent Events (SSE) support.</p> <p> Read More</p> </li> <li> <p> Event Mediator</p> <p>For processing events from message brokers like Kafka and RabbitMQ.</p> <p> Read More</p> </li> <li> <p> Saga Mediator</p> <p>Orchestrated sagas with step streaming, storage, and recovery.</p> <p> Read More</p> </li> <li> <p> Message Brokers</p> <p>Configure Kafka, RabbitMQ, and custom brokers for event publishing.</p> <p> Read More</p> </li> <li> <p> Middlewares</p> <p>Request interception and modification with custom middleware support.</p> <p> Read More</p> </li> <li> <p> DI Containers</p> <p>Dependency injection configuration and container setup.</p> <p> Read More</p> </li> <li> <p> Advanced Configuration</p> <p>Combining all options and manual setup for complex scenarios.</p> <p> Read More</p> </li> </ul> <p>The <code>bootstrap</code> utilities simplify the initial configuration of your CQRS application. They automatically set up:</p> <ul> <li>Dependency Injection Container \u2014 Resolves handlers and their dependencies (see Dependency Injection)</li> <li>Request Mapping \u2014 Maps commands and queries to their handlers (see Request Handlers)</li> <li>Event Mapping \u2014 Maps domain events to their handlers (see Event Handling)</li> <li>Saga Mapping \u2014 Maps saga context types to saga classes (see Saga Pattern)</li> <li>Message Broker \u2014 Configures event publishing (see Event Producing)</li> <li>Middlewares \u2014 Adds logging and custom middlewares</li> <li>Event Processing \u2014 Configures parallel event processing</li> </ul> <p>Getting Started</p> <p>If you're new to <code>python-cqrs</code>, start here! Bootstrap is the foundation for all other features. After configuring bootstrap, proceed to Request Handlers to learn how to create command and query handlers.</p> <p>Navigation</p> <p>Use the navigation menu on the left to explore different mediator types and configuration options. Each section covers a specific aspect of bootstrap configuration.</p>"},{"location":"bootstrap/#mediator-types","title":"Mediator Types","text":"<p>The <code>python-cqrs</code> package provides four types of mediators:</p> Mediator Type Use Case Bootstrap Function <code>RequestMediator</code> Standard commands and queries <code>cqrs.requests.bootstrap.bootstrap()</code> <code>StreamingRequestMediator</code> Streaming requests with incremental results <code>cqrs.requests.bootstrap.bootstrap_streaming()</code> <code>EventMediator</code> Processing events from message brokers <code>cqrs.events.bootstrap.bootstrap()</code> <code>SagaMediator</code> Orchestrated sagas with step streaming and recovery <code>cqrs.saga.bootstrap.bootstrap()</code> <p>Mediator Comparison</p> <p>Each mediator type has its own bootstrap function and configuration options. Choose based on your use case:</p> <ul> <li>RequestMediator: Most common, handles standard CQRS operations</li> <li>StreamingRequestMediator: For real-time progress updates (SSE, WebSockets)</li> <li>EventMediator: For consuming events from Kafka/RabbitMQ</li> <li>SagaMediator: For distributed transactions with steps and compensation</li> </ul> When to use each mediator? <ul> <li>RequestMediator: Use for standard HTTP API endpoints (GET, POST, PUT, DELETE)</li> <li>StreamingRequestMediator: Use when you need to stream results back to clients (file processing, batch operations)</li> <li>EventMediator: Use in FastStream consumers to process events from message brokers</li> <li>SagaMediator: Use when coordinating multiple steps across services with automatic compensation on failure</li> </ul>"},{"location":"bootstrap/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Request Mediator \u2014 Standard mediator for commands and queries</li> <li>Streaming Request Mediator \u2014 For incremental processing and SSE</li> <li>Event Mediator \u2014 For processing events from message brokers</li> <li>Saga Mediator \u2014 Orchestrated sagas with storage and recovery</li> <li>Message Brokers \u2014 Kafka, RabbitMQ, and custom brokers</li> <li>Middlewares \u2014 Request interception and modification</li> <li>DI Containers \u2014 Dependency injection configuration</li> <li>Advanced Configuration \u2014 Combining all options and manual setup</li> </ul>"},{"location":"bootstrap/advanced/","title":"Advanced","text":"<ul> <li> <p> Back to Bootstrap Overview</p> <p>Return to the Bootstrap overview page with all configuration options.</p> <p> Back to Overview</p> </li> <li> <p> Commands / Requests Handling</p> <p>Core concepts for commands, queries, and request handlers.</p> <p> Read More</p> </li> </ul>"},{"location":"bootstrap/advanced/#combining-all-options","title":"Combining All Options","text":"<p>Here's a complete example combining all configuration options:</p> <pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import kafka\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\nfrom cqrs.middlewares import base\n\n# DI Container setup\ncontainer = di.Container()\n# ... bind dependencies ...\n\n# Mappers\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(CreateUserCommand, CreateUserCommandHandler)\n\ndef queries_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(GetUserQuery, GetUserQueryHandler)\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(UserCreatedEvent, UserCreatedEventHandler)\n\n# Custom middleware\nclass CustomMiddleware(base.Middleware):\n    async def __call__(self, request: cqrs.Request, handle):\n        # Custom logic\n        return await handle(request)\n\n# Message broker\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n)\nkafka_broker = kafka.KafkaMessageBroker(producer=kafka_producer)\n\n# Startup callbacks\ndef init_database():\n    print(\"Database initialized\")\n\ndef init_cache():\n    print(\"Cache initialized\")\n\n# Complete bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=container,\n    commands_mapper=commands_mapper,\n    queries_mapper=queries_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=kafka_broker,\n    middlewares=[CustomMiddleware()],\n    on_startup=[init_database, init_cache],\n    max_concurrent_event_handlers=5,\n    concurrent_event_handle_enable=True,\n)\n</code></pre>"},{"location":"bootstrap/advanced/#manual-setup-advanced","title":"Manual Setup (Advanced)","text":"<p>For advanced use cases, you can manually set up mediators and emitters:</p> <pre><code>from cqrs.requests import bootstrap\nfrom cqrs.events import EventEmitter\n\n# Manually create event emitter\nevent_emitter = bootstrap.setup_event_emitter(\n    container=container,\n    domain_events_mapper=events_mapper,\n    message_broker=kafka_broker,\n)\n\n# Manually create mediator\nmediator = bootstrap.setup_mediator(\n    event_emitter=event_emitter,\n    container=container,\n    middlewares=[CustomMiddleware()],\n    commands_mapper=commands_mapper,\n    queries_mapper=queries_mapper,\n    max_concurrent_event_handlers=5,\n    concurrent_event_handle_enable=True,\n)\n</code></pre>"},{"location":"bootstrap/di_containers/","title":"Di Containers","text":"<ul> <li> <p> Back to Bootstrap Overview</p> <p>Return to the Bootstrap overview page with all configuration options.</p> <p> Back to Overview</p> </li> <li> <p> Dependency Injection</p> <p>Container setup, scopes, and resolving handlers and dependencies.</p> <p> Read More</p> </li> </ul>"},{"location":"bootstrap/di_containers/#overview","title":"Overview","text":"<p>The bootstrap functions support multiple DI container implementations.</p> Container Library Default Best For di.Container <code>di</code> \u2705 Yes Most applications CQRSContainer <code>dependency-injector</code> \u274c No Large, complex applications <p>Container Choice</p> <p>Use <code>di.Container</code> for most applications. Use <code>dependency-injector</code> only if you need advanced features like configuration management or nested containers.</p>"},{"location":"bootstrap/di_containers/#dicontainer","title":"di.Container","text":"<p>The <code>di</code> library is the default and recommended DI container:</p> <pre><code>import abc\nimport di\nfrom di import dependent\n\nclass ServiceProtocol(abc.ABC):\n    @abc.abstractmethod\n    async def do_work(self) -&gt; None:\n        pass\n\nclass ServiceImpl(ServiceProtocol):\n    async def do_work(self) -&gt; None:\n        print(\"Working...\")\n\n# Setup DI container\ncontainer = di.Container()\ncontainer.bind(\n    di.bind_by_type(\n        dependent.Dependent(ServiceImpl, scope=\"request\"),\n        ServiceProtocol,\n    )\n)\n\nmediator = bootstrap.bootstrap(\n    di_container=container,\n    commands_mapper=commands_mapper,\n)\n</code></pre>"},{"location":"bootstrap/di_containers/#cqrscontainer-dependency-injector","title":"CQRSContainer (dependency-injector)","text":"<p>The <code>CQRSContainer</code> adapter allows using <code>dependency-injector</code> library:</p> <pre><code>from dependency_injector import containers, providers\nfrom cqrs.container import DependencyInjectorCQRSContainer\n\nclass ApplicationContainer(containers.DeclarativeContainer):\n    # Define your services\n    service = providers.Factory(ServiceImpl)\n\n# Create CQRS container adapter\ncqrs_container = DependencyInjectorCQRSContainer(ApplicationContainer())\n\nmediator = bootstrap.bootstrap(\n    di_container=cqrs_container,\n    commands_mapper=commands_mapper,\n)\n</code></pre>"},{"location":"bootstrap/event_mediator/","title":"Event Mediator","text":"<ul> <li> <p> Back to Bootstrap Overview</p> <p>Return to the Bootstrap overview page with all configuration options.</p> <p> Back to Overview</p> </li> <li> <p> Events Handling</p> <p>Event types, flow, parallel processing, and handlers.</p> <p> Read More</p> </li> </ul>"},{"location":"bootstrap/event_mediator/#overview","title":"Overview","text":"<p>The <code>EventMediator</code> processes events received from message brokers (like Kafka, RabbitMQ). It's used in event consumers to handle incoming events.</p>"},{"location":"bootstrap/event_mediator/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from cqrs.events import bootstrap\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(\n        cqrs.NotificationEvent[UserCreatedPayload],\n        UserCreatedEventHandler\n    )\n\nevent_mediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    events_mapper=events_mapper,\n)\n</code></pre>"},{"location":"bootstrap/event_mediator/#with-custom-middlewares","title":"With Custom Middlewares","text":"<pre><code>from cqrs.middlewares import base\n\nclass EventLoggingMiddleware(base.Middleware):\n    async def __call__(self, request: cqrs.Request, handle):\n        print(f\"Processing event: {type(request).__name__}\")\n        result = await handle(request)\n        print(f\"Event processed: {type(request).__name__}\")\n        return result\n\nevent_mediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    events_mapper=events_mapper,\n    middlewares=[EventLoggingMiddleware()],\n)\n</code></pre>"},{"location":"bootstrap/event_mediator/#with-on-startup-callbacks","title":"With On Startup Callbacks","text":"<pre><code>def setup_event_store():\n    # Initialize event store connections\n    print(\"Event store initialized\")\n\nevent_mediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    events_mapper=events_mapper,\n    on_startup=[setup_event_store],\n)\n</code></pre>"},{"location":"bootstrap/event_mediator/#complete-example-with-faststream","title":"Complete Example with FastStream","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.events import bootstrap\nfrom faststream import kafka\nimport faststream\n\nclass UserCreatedPayload(cqrs.Response):\n    user_id: str\n    email: str\n\nclass UserCreatedEventHandler(\n    cqrs.EventHandler[cqrs.NotificationEvent[UserCreatedPayload]]\n):\n    async def handle(\n        self, event: cqrs.NotificationEvent[UserCreatedPayload]\n    ) -&gt; None:\n        print(f\"User {event.payload.user_id} created\")\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(\n        cqrs.NotificationEvent[UserCreatedPayload],\n        UserCreatedEventHandler\n    )\n\ndef mediator_factory() -&gt; cqrs.EventMediator:\n    return bootstrap.bootstrap(\n        di_container=di.Container(),\n        events_mapper=events_mapper,\n    )\n\nbroker = kafka.KafkaBroker(bootstrap_servers=[\"localhost:9092\"])\napp = faststream.FastStream(broker)\n\n@broker.subscriber(\"user_events\")\nasync def handle_user_event(\n    event: cqrs.NotificationEvent[UserCreatedPayload],\n    mediator: cqrs.EventMediator = faststream.Depends(mediator_factory),\n):\n    await mediator.send(event)\n</code></pre>"},{"location":"bootstrap/message_brokers/","title":"Message Brokers","text":"<ul> <li> <p> Back to Bootstrap Overview</p> <p>Return to the Bootstrap overview page with all configuration options.</p> <p> Back to Overview</p> </li> <li> <p> Event Producing</p> <p>Publishing events to Kafka, RabbitMQ, and custom brokers.</p> <p> Read More</p> </li> </ul>"},{"location":"bootstrap/message_brokers/#overview","title":"Overview","text":"<p>Message brokers are used to publish <code>NotificationEvent</code> and <code>ECSTEvent</code> events to external systems. The <code>python-cqrs</code> package supports multiple message broker implementations.</p> Broker Type Use Case Production Ready DevnullMessageBroker Testing, development \u274c No KafkaMessageBroker High-throughput, distributed systems \u2705 Yes AMQPMessageBroker RabbitMQ, traditional message queues \u2705 Yes Choosing a Message Broker <ul> <li>DevnullMessageBroker: Use for testing and development when you don't need actual message publishing</li> <li>KafkaMessageBroker: Use for high-throughput, distributed systems with strong ordering guarantees</li> <li>AMQPMessageBroker: Use for traditional message queue patterns, RabbitMQ integration</li> </ul>"},{"location":"bootstrap/message_brokers/#devnullmessagebroker","title":"DevnullMessageBroker","text":"<p>The <code>DevnullMessageBroker</code> is a no-op broker used for testing. It doesn't actually send messages anywhere but logs warnings.</p> <p>Development Only</p> <p>Never use <code>DevnullMessageBroker</code> in production. It's designed for testing and development only.</p> <pre><code>from cqrs.message_brokers import devnull\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    message_broker=devnull.DevnullMessageBroker(),\n)\n</code></pre>"},{"location":"bootstrap/message_brokers/#kafkamessagebroker","title":"KafkaMessageBroker","text":"<p>The <code>KafkaMessageBroker</code> publishes events to Apache Kafka topics.</p> <pre><code>from cqrs.message_brokers import kafka\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\n\n# Create Kafka producer adapter\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    client_id=\"my-app\",\n    acks=\"all\",  # Wait for all replicas\n    enable_idempotence=True,\n)\n\n# Create message broker\nkafka_broker = kafka.KafkaMessageBroker(\n    producer=kafka_producer,\n    aiokafka_log_level=\"ERROR\",  # Suppress verbose logging\n)\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=kafka_broker,\n)\n</code></pre>"},{"location":"bootstrap/message_brokers/#amqpmessagebroker","title":"AMQPMessageBroker","text":"<p>The <code>AMQPMessageBroker</code> publishes events to RabbitMQ or other AMQP-compatible brokers.</p> <pre><code>from cqrs.message_brokers import amqp\nfrom cqrs.adapters.amqp import AMQPPublisherAdapter\nimport aio_pika\n\n# Create AMQP publisher\namqp_publisher = AMQPPublisherAdapter(\n    dsn=\"amqp://user:password@localhost/\",\n)\n\n# Create message broker\namqp_broker = amqp.AMQPMessageBroker(\n    publisher=amqp_publisher,\n    exchange_name=\"events\",\n    pika_log_level=\"ERROR\",\n)\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=amqp_broker,\n)\n</code></pre>"},{"location":"bootstrap/message_brokers/#custom-message-broker","title":"Custom Message Broker","text":"<p>You can create custom message brokers by implementing the <code>MessageBroker</code> protocol:</p> <pre><code>from cqrs.message_brokers import protocol\n\nclass CustomMessageBroker(protocol.MessageBroker):\n    async def send_message(self, message: protocol.Message) -&gt; None:\n        # Custom implementation\n        print(f\"Sending {message.message_name} to {message.topic}\")\n        # Send to your custom broker\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    message_broker=CustomMessageBroker(),\n)\n</code></pre>"},{"location":"bootstrap/middlewares/","title":"Middlewares","text":"<ul> <li> <p> Back to Bootstrap Overview</p> <p>Return to the Bootstrap overview page with all configuration options.</p> <p> Back to Overview</p> </li> <li> <p> Commands / Requests Handling</p> <p>Request pipeline and handler execution where middlewares apply.</p> <p> Read More</p> </li> </ul>"},{"location":"bootstrap/middlewares/#overview","title":"Overview","text":"<p>Middlewares allow you to intercept and modify request processing. The <code>python-cqrs</code> package includes a built-in <code>LoggingMiddleware</code> and allows you to create custom middlewares.</p>"},{"location":"bootstrap/middlewares/#loggingmiddleware","title":"LoggingMiddleware","text":"<p>The <code>LoggingMiddleware</code> is automatically added to all mediators. It logs request and response details.</p> <pre><code># LoggingMiddleware is added automatically\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    # LoggingMiddleware is added automatically\n)\n</code></pre>"},{"location":"bootstrap/middlewares/#custom-middleware","title":"Custom Middleware","text":"<p>Create custom middlewares by implementing the <code>Middleware</code> protocol:</p> <pre><code>from cqrs.middlewares import base\nimport time\n\nclass TimingMiddleware(base.Middleware):\n    async def __call__(self, request: cqrs.Request, handle):\n        start_time = time.time()\n        result = await handle(request)\n        elapsed = time.time() - start_time\n        print(f\"Request {type(request).__name__} took {elapsed:.2f}s\")\n        return result\n\nclass ValidationMiddleware(base.Middleware):\n    async def __call__(self, request: cqrs.Request, handle):\n        # Validate request\n        if hasattr(request, 'validate'):\n            request.validate()\n        result = await handle(request)\n        return result\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    middlewares=[TimingMiddleware(), ValidationMiddleware()],\n)\n</code></pre>"},{"location":"bootstrap/middlewares/#middleware-order","title":"Middleware Order","text":"<p>Middlewares are executed in the order they are added, with the last middleware wrapping the handler first:</p> Order Middleware Execution 1 <code>TimingMiddleware</code> Executes first (outermost) 2 <code>ValidationMiddleware</code> Executes second 3 Handler Executes last (innermost) <pre><code># Execution order: TimingMiddleware -&gt; ValidationMiddleware -&gt; Handler\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    middlewares=[\n        TimingMiddleware(),      # Executes first (outermost)\n        ValidationMiddleware(),  # Executes second\n    ],\n)\n</code></pre> <p>Middleware Execution</p> <p>Middlewares wrap handlers in reverse order. The first middleware in the list is the outermost wrapper, executing before all others.</p>"},{"location":"bootstrap/request_mediator/","title":"Request Mediator","text":"<ul> <li> <p> Back to Bootstrap Overview</p> <p>Return to the Bootstrap overview page with all configuration options.</p> <p> Back to Overview</p> </li> <li> <p> Commands / Requests Handling</p> <p>Commands, queries, handlers, and request/response mapping.</p> <p> Read More</p> </li> </ul>"},{"location":"bootstrap/request_mediator/#overview","title":"Overview","text":"<p>The <code>RequestMediator</code> is the standard mediator for handling commands and queries. It processes requests synchronously and emits events after handler execution.</p>"},{"location":"bootstrap/request_mediator/#basic-configuration","title":"Basic Configuration","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(CreateUserCommand, CreateUserCommandHandler)\n\ndef queries_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(GetUserQuery, GetUserQueryHandler)\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(\n        cqrs.DomainEvent[UserCreatedPayload],\n        UserCreatedEventHandler\n    )\n\n# Basic bootstrap with di.Container\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    queries_mapper=queries_mapper,\n    domain_events_mapper=events_mapper,\n)\n</code></pre>"},{"location":"bootstrap/request_mediator/#with-message-broker","title":"With Message Broker","text":"<pre><code>from cqrs.message_brokers import devnull, kafka\n\n# Using DevnullMessageBroker (for testing)\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=devnull.DevnullMessageBroker(),\n)\n\n# Using KafkaMessageBroker\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\n\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    client_id=\"my-app\",\n)\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=kafka.KafkaMessageBroker(\n        producer=kafka_producer,\n        aiokafka_log_level=\"ERROR\",\n    ),\n)\n</code></pre>"},{"location":"bootstrap/request_mediator/#with-parallel-event-processing","title":"With Parallel Event Processing","text":"<pre><code># Enable parallel event processing\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    max_concurrent_event_handlers=5,  # Process up to 5 events concurrently\n    concurrent_event_handle_enable=True,  # Enable parallel processing\n)\n</code></pre>"},{"location":"bootstrap/request_mediator/#with-custom-middlewares","title":"With Custom Middlewares","text":"<pre><code>from cqrs.middlewares import base\n\nclass CustomMiddleware(base.Middleware):\n    async def __call__(self, request: cqrs.Request, handle):\n        print(f\"Before handling {type(request).__name__}\")\n        result = await handle(request)\n        print(f\"After handling {type(request).__name__}\")\n        return result\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    middlewares=[CustomMiddleware()],\n)\n</code></pre>"},{"location":"bootstrap/request_mediator/#with-on-startup-callbacks","title":"With On Startup Callbacks","text":"<pre><code>def initialize_database():\n    # Initialize database connections, create tables, etc.\n    print(\"Database initialized\")\n\ndef setup_cache():\n    # Setup cache connections\n    print(\"Cache initialized\")\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    on_startup=[initialize_database, setup_cache],\n)\n</code></pre>"},{"location":"bootstrap/request_mediator/#complete-example","title":"Complete Example","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import devnull\nfrom cqrs.middlewares import base\n\nclass CreateUserCommand(cqrs.Request):\n    user_id: str\n    email: str\n\nclass UserCreatedEvent(cqrs.DomainEvent):\n    user_id: str\n    email: str\n\nclass CreateUserCommandHandler(cqrs.RequestHandler[CreateUserCommand, None]):\n    def __init__(self):\n        self._events = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events\n\n    async def handle(self, request: CreateUserCommand) -&gt; None:\n        # Business logic\n        self._events.append(\n            UserCreatedEvent(user_id=request.user_id, email=request.email)\n        )\n\nclass UserCreatedEventHandler(cqrs.EventHandler[UserCreatedEvent]):\n    async def handle(self, event: UserCreatedEvent) -&gt; None:\n        print(f\"User {event.user_id} created with email {event.email}\")\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(CreateUserCommand, CreateUserCommandHandler)\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(UserCreatedEvent, UserCreatedEventHandler)\n\n# Complete configuration\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=devnull.DevnullMessageBroker(),\n    max_concurrent_event_handlers=3,\n    concurrent_event_handle_enable=True,\n    on_startup=[lambda: print(\"Application started\")],\n)\n\n# Use the mediator\nresult = await mediator.send(CreateUserCommand(user_id=\"1\", email=\"user@example.com\"))\n</code></pre>"},{"location":"bootstrap/saga_mediator/","title":"Saga Mediator","text":"<ul> <li> <p> Back to Bootstrap Overview</p> <p>Return to the Bootstrap overview page with all configuration options.</p> <p> Back to Overview</p> </li> <li> <p> Saga Pattern</p> <p>Flow, storage, recovery, and compensation.</p> <p> Read More</p> </li> </ul>"},{"location":"bootstrap/saga_mediator/#overview","title":"Overview","text":"<p>The <code>SagaMediator</code> runs orchestrated sagas: it resolves the saga by context type, creates a transaction, and streams step results. It is bootstrapped via <code>cqrs.saga.bootstrap.bootstrap()</code> with a saga map, DI container, optional saga storage, and optional event mapping for domain events emitted by steps.</p>"},{"location":"bootstrap/saga_mediator/#basic-configuration","title":"Basic Configuration","text":"<pre><code>import di\nimport cqrs\nfrom cqrs.saga import bootstrap\nfrom cqrs.saga.storage.memory import MemorySagaStorage\n\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\nstorage = MemorySagaStorage()\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n</code></pre>"},{"location":"bootstrap/saga_mediator/#with-domain-events","title":"With Domain Events","text":"<p>Steps can emit domain events; the mediator uses an event emitter and event map (same as request bootstrap). Register handlers via <code>domain_events_mapper</code>:</p> <pre><code>def events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(InventoryReservedEvent, InventoryReservedEventHandler)\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    sagas_mapper=saga_mapper,\n    domain_events_mapper=events_mapper,\n    saga_storage=storage,\n)\n</code></pre>"},{"location":"bootstrap/saga_mediator/#with-message-broker","title":"With Message Broker","text":"<p>By default the event emitter uses <code>DevnullMessageBroker</code>. To publish events to Kafka or RabbitMQ, pass <code>message_broker</code>:</p> <pre><code>from cqrs.message_brokers import kafka\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\n\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n    client_id=\"my-app\",\n)\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    sagas_mapper=saga_mapper,\n    domain_events_mapper=events_mapper,\n    saga_storage=storage,\n    message_broker=kafka.KafkaMessageBroker(\n        producer=kafka_producer,\n        aiokafka_log_level=\"ERROR\",\n    ),\n)\n</code></pre>"},{"location":"bootstrap/saga_mediator/#with-middlewares-and-on-startup","title":"With Middlewares and On Startup","text":"<pre><code>from cqrs.middlewares import base\n\nclass SagaLoggingMiddleware(base.Middleware):\n    async def __call__(self, request: cqrs.Request, handle):\n        print(f\"Before saga step: {type(request).__name__}\")\n        result = await handle(request)\n        print(f\"After saga step: {type(request).__name__}\")\n        return result\n\ndef init_storage():\n    # e.g. create tables for SqlAlchemySagaStorage\n    pass\n\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n    middlewares=[SagaLoggingMiddleware()],\n    on_startup=[init_storage],\n)\n</code></pre>"},{"location":"bootstrap/saga_mediator/#executing-a-saga","title":"Executing a Saga","text":"<p>Use <code>mediator.stream(context, saga_id=...)</code> to run the saga. It returns an async iterator; consume it with <code>async for</code>:</p> <pre><code>import uuid\n\ncontext = OrderContext(order_id=\"123\", items=[\"item_1\"], total_amount=100.0)\nsaga_id = uuid.uuid4()\n\nasync for step_result in mediator.stream(context, saga_id=saga_id):\n    print(f\"Step completed: {step_result.step_type.__name__}\")\n</code></pre> <p>For recovery, use the same <code>saga_id</code> and call <code>recover_saga()</code> (see Saga Recovery).</p>"},{"location":"bootstrap/saga_mediator/#complete-example","title":"Complete Example","text":"<pre><code>import dataclasses\nimport uuid\nimport di\nimport cqrs\nfrom cqrs.saga import bootstrap\nfrom cqrs.saga.saga import Saga\nfrom cqrs.saga.step import SagaStepHandler, SagaStepResult\nfrom cqrs.saga.storage.memory import MemorySagaStorage\nfrom cqrs.saga.models import SagaContext\nfrom cqrs.response import Response\n\n@dataclasses.dataclass\nclass OrderContext(SagaContext):\n    order_id: str\n    items: list[str]\n    total_amount: float\n    inventory_reservation_id: str | None = None\n    payment_id: str | None = None\n\nclass ReserveInventoryStep(SagaStepHandler[OrderContext, Response]):\n    def __init__(self, inventory_service):\n        self._inventory_service = inventory_service\n\n    async def act(self, context: OrderContext) -&gt; SagaStepResult:\n        reservation_id = await self._inventory_service.reserve_items(\n            context.order_id, context.items\n        )\n        context.inventory_reservation_id = reservation_id\n        return self._generate_step_result(Response())\n\n    async def compensate(self, context: OrderContext) -&gt; None:\n        if context.inventory_reservation_id:\n            await self._inventory_service.release_items(\n                context.inventory_reservation_id\n            )\n\nclass OrderSaga(Saga[OrderContext]):\n    steps = [ReserveInventoryStep]\n\n# Register services in container\ndi_container = di.Container()\n# di_container.bind(...)\n\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\nstorage = MemorySagaStorage()\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n\ncontext = OrderContext(order_id=\"123\", items=[\"item_1\"], total_amount=100.0)\nsaga_id = uuid.uuid4()\n\nasync for step_result in mediator.stream(context, saga_id=saga_id):\n    print(f\"Step: {step_result.step_type.__name__}\")\n</code></pre>"},{"location":"bootstrap/saga_mediator/#bootstrap-parameters","title":"Bootstrap Parameters","text":"Parameter Description <code>di_container</code> DI container (<code>di.Container</code> or CQRS <code>Container</code>) for resolving saga step handlers <code>sagas_mapper</code> Callable that receives <code>cqrs.SagaMap</code> and registers context type \u2192 saga class (e.g. <code>mapper.bind(OrderContext, OrderSaga)</code>) <code>saga_storage</code> Optional <code>ISagaStorage</code> implementation. If <code>None</code>, defaults to in-memory behaviour when storage is needed. For production, use e.g. <code>SqlAlchemySagaStorage</code> and register it in the container <code>domain_events_mapper</code> Optional callable to register event handlers (for events emitted by steps) <code>message_broker</code> Optional message broker for event publishing; defaults to <code>DevnullMessageBroker</code> <code>middlewares</code> Optional list of middlewares for request processing <code>on_startup</code> Optional list of callables invoked once when bootstrap runs <code>max_concurrent_event_handlers</code> Max concurrent event handlers (default: 1) <code>concurrent_event_handle_enable</code> Whether to process events in parallel (default: True)"},{"location":"bootstrap/streaming_mediator/","title":"Streaming Mediator","text":"<ul> <li> <p> Back to Bootstrap Overview</p> <p>Return to the Bootstrap overview page with all configuration options.</p> <p> Back to Overview</p> </li> <li> <p> Stream Handling</p> <p>Incremental processing, SSE, and streaming configuration.</p> <p> Read More</p> </li> </ul>"},{"location":"bootstrap/streaming_mediator/#overview","title":"Overview","text":"<p>The <code>StreamingRequestMediator</code> processes requests incrementally, yielding results as they become available. Perfect for batch processing, file uploads, and real-time progress updates.</p>"},{"location":"bootstrap/streaming_mediator/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from cqrs.requests import bootstrap\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(ProcessFilesCommand, ProcessFilesCommandHandler)\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(FileProcessedEvent, FileProcessedEventHandler)\n\nmediator = bootstrap.bootstrap_streaming(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n)\n</code></pre>"},{"location":"bootstrap/streaming_mediator/#with-parallel-event-processing","title":"With Parallel Event Processing","text":"<pre><code># Streaming mediator defaults to parallel event processing\nmediator = bootstrap.bootstrap_streaming(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    max_concurrent_event_handlers=10,  # Default: 10\n    concurrent_event_handle_enable=True,  # Default: True for streaming\n)\n</code></pre>"},{"location":"bootstrap/streaming_mediator/#with-message-broker","title":"With Message Broker","text":"<pre><code>from cqrs.message_brokers import kafka\nfrom cqrs.adapters.kafka import KafkaProducerAdapter\n\nkafka_producer = KafkaProducerAdapter(\n    bootstrap_servers=[\"localhost:9092\"],\n)\n\nmediator = bootstrap.bootstrap_streaming(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=kafka.KafkaMessageBroker(producer=kafka_producer),\n)\n</code></pre>"},{"location":"bootstrap/streaming_mediator/#complete-example","title":"Complete Example","text":"<pre><code>import typing\nimport asyncio\nimport di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.requests.request_handler import StreamingRequestHandler\nfrom cqrs.message_brokers import devnull\n\nclass ProcessFilesCommand(cqrs.Request):\n    file_ids: list[str]\n\nclass FileProcessedResult(cqrs.Response):\n    file_id: str\n    status: str\n\nclass FileProcessedEvent(cqrs.DomainEvent):\n    file_id: str\n    status: str\n\nclass ProcessFilesCommandHandler(\n    StreamingRequestHandler[ProcessFilesCommand, FileProcessedResult]\n):\n    def __init__(self):\n        self._events = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events.copy()\n\n    def clear_events(self) -&gt; None:\n        self._events.clear()\n\n    async def handle(\n        self, request: ProcessFilesCommand\n    ) -&gt; typing.AsyncIterator[FileProcessedResult]:\n        for file_id in request.file_ids:\n            # Simulate processing\n            await asyncio.sleep(0.1)\n            result = FileProcessedResult(file_id=file_id, status=\"completed\")\n            self._events.append(\n                FileProcessedEvent(file_id=file_id, status=\"completed\")\n            )\n            yield result\n\nclass FileProcessedEventHandler(cqrs.EventHandler[FileProcessedEvent]):\n    async def handle(self, event: FileProcessedEvent) -&gt; None:\n        print(f\"File {event.file_id} processed\")\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(ProcessFilesCommand, ProcessFilesCommandHandler)\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(FileProcessedEvent, FileProcessedEventHandler)\n\nmediator = bootstrap.bootstrap_streaming(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=events_mapper,\n    message_broker=devnull.DevnullMessageBroker(),\n    max_concurrent_event_handlers=5,\n    concurrent_event_handle_enable=True,\n)\n\n# Stream results\nasync for result in mediator.stream(\n    ProcessFilesCommand(file_ids=[\"1\", \"2\", \"3\"])\n):\n    if result:\n        print(f\"Processed: {result.file_id} - {result.status}\")\n</code></pre>"},{"location":"chain_of_responsibility/","title":"Chain of Responsibility","text":"<p>The Chain of Responsibility pattern allows multiple handlers to process a request in sequence until one successfully handles it. This pattern is particularly useful when you have multiple processing strategies or need to implement fallback mechanisms.</p>"},{"location":"chain_of_responsibility/#overview","title":"Overview","text":"<ul> <li> <p> Examples</p> <p>Registering handlers and complete examples of Chain of Responsibility pattern.</p> <p> Read More</p> </li> <li> <p> Advanced Topics</p> <p>Manual chain building, handler methods, and integration patterns.</p> <p> Read More</p> </li> <li> <p> Mermaid Diagrams</p> <p>Generate Sequence and Class diagrams for documentation.</p> <p> Read More</p> </li> <li> <p> Fallback</p> <p>Combine CoR with Request Handler Fallback when the chain raises.</p> <p> Read More</p> </li> </ul> <p><code>CORRequestHandler</code> implements the Chain of Responsibility pattern, allowing multiple handlers to process a request sequentially. Each handler decides whether to process the request or pass it to the next handler in the chain. The chain stops when a handler successfully processes the request or when all handlers have been exhausted.</p>"},{"location":"chain_of_responsibility/#key-benefits","title":"Key Benefits","text":"<ul> <li>Flexible processing \u2014 Multiple strategies can be tried in order</li> <li>Fallback mechanisms \u2014 Default handlers can handle unsupported cases</li> <li>Separation of concerns \u2014 Each handler focuses on a specific case</li> <li>Easy to extend \u2014 Add new handlers without modifying existing ones</li> </ul> <p>Prerequisites</p> <p>Understanding of Request Handlers and Bootstrap is recommended.</p> <p>When to Use</p> <p>Use Chain of Responsibility when you have multiple processing strategies or need fallback mechanisms. For standard request handling, use regular Request Handlers.</p>"},{"location":"chain_of_responsibility/#pattern-description","title":"Pattern Description","text":"<p>The Chain of Responsibility pattern consists of:</p> <ol> <li>Handler Interface \u2014 <code>CORRequestHandler</code> defines the interface for handlers in the chain</li> <li>Concrete Handlers \u2014 Multiple handlers that can process requests</li> <li>Chain Building \u2014 Handlers are linked together in a specific order</li> <li>Request Passing \u2014 Each handler can either process the request or pass it to the next handler</li> </ol>"},{"location":"chain_of_responsibility/#how-it-works","title":"How It Works","text":"<pre><code>Request \u2192 Handler 1 \u2192 Handler 2 \u2192 Handler 3 \u2192 Default Handler\n           \u2193           \u2193           \u2193              \u2193\n        Process?    Process?    Process?      Always Process\n           \u2193           \u2193           \u2193              \u2193\n        Yes/No       Yes/No       Yes/No         Yes\n           \u2193           \u2193           \u2193              \u2193\n        Return      Return      Return         Return\n</code></pre> <p>Each handler in the chain:</p> <ol> <li>Receives the request</li> <li>Decides if it can handle it</li> <li>If yes: processes and returns result</li> <li>If no: passes to next handler using <code>await self.next(request)</code></li> </ol>"},{"location":"chain_of_responsibility/#basic-example","title":"Basic Example","text":"<p>Here's a simple example demonstrating the Chain of Responsibility pattern:</p> <pre><code>import typing\nimport cqrs\nfrom cqrs.requests.cor_request_handler import CORRequestHandler\n\nclass ProcessPaymentCommand(cqrs.Request):\n    amount: float\n    payment_method: str\n    user_id: str\n\nclass PaymentResult(cqrs.Response):\n    success: bool\n    transaction_id: str | None = None\n    message: str = \"\"\n\nclass PaymentProcessedEvent(cqrs.Event):\n    transaction_id: str\n    amount: float\n    user_id: str\n\nclass CreditCardHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    def __init__(self):\n        self._events: list[cqrs.Event] = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events\n\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        if request.payment_method == \"credit_card\":\n            transaction_id = f\"cc_{request.user_id}_{int(request.amount * 100)}\"\n\n            self._events.append(\n                PaymentProcessedEvent(\n                    transaction_id=transaction_id,\n                    amount=request.amount,\n                    user_id=request.user_id,\n                )\n            )\n\n            return PaymentResult(\n                success=True,\n                transaction_id=transaction_id,\n                message=\"Payment processed via credit card\",\n            )\n\n        # Pass to next handler if can't handle\n        return await self.next(request)\n\nclass PayPalHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    def __init__(self):\n        self._events: list[cqrs.Event] = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events\n\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        if request.payment_method == \"paypal\":\n            transaction_id = f\"pp_{request.user_id}_{int(request.amount * 100)}\"\n\n            self._events.append(\n                PaymentProcessedEvent(\n                    transaction_id=transaction_id,\n                    amount=request.amount,\n                    user_id=request.user_id,\n                )\n            )\n\n            return PaymentResult(\n                success=True,\n                transaction_id=transaction_id,\n                message=\"Payment processed via PayPal\",\n            )\n\n        # Pass to next handler if can't handle\n        return await self.next(request)\n\nclass DefaultPaymentHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return []\n\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        # Default handler always handles the request\n        return PaymentResult(\n            success=False,\n            message=f\"Unsupported payment method: {request.payment_method}\",\n        )\n</code></pre>"},{"location":"chain_of_responsibility/advanced/","title":"Advanced Topics","text":"<ul> <li> <p> Back to Chain of Responsibility Overview</p> <p>Return to the Chain of Responsibility overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"chain_of_responsibility/advanced/#overview","title":"Overview","text":"<p>You can also build chains manually using the <code>build_chain()</code> function:</p> <pre><code>from cqrs.requests.cor_request_handler import build_chain\n\n# Create handler instances\nhandler1 = CreditCardHandler()\nhandler2 = PayPalHandler()\nhandler3 = DefaultPaymentHandler()\n\n# Build chain manually\nchain = build_chain([handler1, handler2, handler3])\n\n# Use the chain\nresult = await chain.handle(\n    ProcessPaymentCommand(\n        amount=100.0,\n        payment_method=\"credit_card\",\n        user_id=\"user1\",\n    )\n)\n</code></pre>"},{"location":"chain_of_responsibility/advanced/#set_nexthandler","title":"<code>set_next(handler)</code>","text":"<p>Sets the next handler in the chain. Returns the next handler to allow chaining:</p> <pre><code>handler1.set_next(handler2).set_next(handler3)\n</code></pre>"},{"location":"chain_of_responsibility/advanced/#nextrequest","title":"<code>next(request)</code>","text":"<p>Passes the request to the next handler in the chain:</p> <pre><code>async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n    if can_handle(request):\n        return process(request)\n\n    # Pass to next handler\n    return await self.next(request)\n</code></pre>"},{"location":"chain_of_responsibility/advanced/#events-property","title":"<code>events</code> Property","text":"<p>Returns the list of events generated by the handler. Must be implemented:</p> <pre><code>@property\ndef events(self) -&gt; list[cqrs.Event]:\n    return self._events.copy()\n</code></pre> <p>Chain of Responsibility is ideal for:</p> <ul> <li>Payment processing \u2014 Try different payment methods in order</li> <li>Authentication \u2014 Try multiple authentication strategies</li> <li>Validation \u2014 Multiple validation rules with fallback</li> <li>Error handling \u2014 Try different recovery strategies</li> <li>Feature flags \u2014 Try different implementations based on availability</li> <li> <p>Rate limiting \u2014 Multiple rate limiters with fallback</p> </li> <li> <p>Order matters \u2014 Place handlers in order of preference or priority</p> </li> <li>Always have a default \u2014 Include a default handler at the end of the chain</li> <li>Clear decision logic \u2014 Make it obvious when a handler can process a request</li> <li>Return early \u2014 Return immediately after processing, don't continue the chain</li> <li>Use <code>next()</code> correctly \u2014 Only call <code>next()</code> when you can't handle the request</li> <li>Handle events \u2014 Collect events from handlers that process requests</li> </ul> Feature Regular Handler COR Handler Processing Single handler Multiple handlers in sequence Decision Always processes Decides whether to process Fallback Not available Built-in via chain Use Case Simple operations Multiple strategies Registration Single handler List of handlers <p>Chain of Responsibility works well with:</p> <ul> <li>Dependency Injection \u2014 Handlers can be injected with dependencies</li> <li>Event Handling \u2014 Handlers can emit events when processing requests</li> <li>Middleware \u2014 Middleware can be applied to the entire chain</li> <li>Regular Handlers \u2014 COR handlers can be used alongside regular handlers</li> </ul> <p>The Chain of Responsibility pattern provides a flexible way to handle requests with multiple processing strategies. By linking handlers together, you can:</p> <ul> <li>Try multiple strategies in order</li> <li>Implement fallback mechanisms</li> <li>Separate concerns across handlers</li> <li>Easily extend functionality by adding new handlers</li> </ul>"},{"location":"chain_of_responsibility/examples/","title":"Examples","text":"<ul> <li> <p> Back to Chain of Responsibility Overview</p> <p>Return to the Chain of Responsibility overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"chain_of_responsibility/examples/#overview","title":"Overview","text":"<p>To register a chain of handlers, bind the request type to a list of handler classes:</p> <pre><code>import cqrs\nfrom cqrs.requests import bootstrap\n\ndef payment_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    \"\"\"Register the chain of payment handlers.\"\"\"\n    mapper.bind(\n        ProcessPaymentCommand,\n        [\n            CreditCardHandler,      # First in chain\n            PayPalHandler,          # Second in chain\n            DefaultPaymentHandler,  # Last in chain (fallback)\n        ],\n    )\n\n# Bootstrap mediator\nmediator = bootstrap.bootstrap(\n    di_container=container,\n    commands_mapper=payment_mapper,\n)\n\n# Use the mediator\nresult = await mediator.send(\n    ProcessPaymentCommand(\n        amount=100.0,\n        payment_method=\"credit_card\",\n        user_id=\"user1\",\n    )\n)\n</code></pre> <p>The framework automatically:</p> <ol> <li>Resolves all handlers from the DI container</li> <li>Builds the chain using <code>build_chain()</code></li> <li>Links handlers in the order specified</li> <li>Uses the first handler as the entry point</li> </ol> <p>Here's a complete example demonstrating payment processing with multiple handlers:</p> <pre><code>import asyncio\nimport typing\nimport di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.requests.cor_request_handler import CORRequestHandler\n\n# Domain models\nclass ProcessPaymentCommand(cqrs.Request):\n    amount: float\n    payment_method: str\n    user_id: str\n\nclass PaymentResult(cqrs.Response):\n    success: bool\n    transaction_id: str | None = None\n    message: str = \"\"\n\nclass PaymentProcessedEvent(cqrs.Event):\n    transaction_id: str\n    amount: float\n    user_id: str\n\n# Chain handlers\nclass CreditCardHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    def __init__(self):\n        self._events: list[cqrs.Event] = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events\n\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        if request.payment_method == \"credit_card\":\n            transaction_id = f\"cc_{request.user_id}_{int(request.amount * 100)}\"\n\n            self._events.append(\n                PaymentProcessedEvent(\n                    transaction_id=transaction_id,\n                    amount=request.amount,\n                    user_id=request.user_id,\n                )\n            )\n\n            return PaymentResult(\n                success=True,\n                transaction_id=transaction_id,\n                message=\"Payment processed via credit card\",\n            )\n\n        return await self.next(request)\n\nclass PayPalHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    def __init__(self):\n        self._events: list[cqrs.Event] = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events\n\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        if request.payment_method == \"paypal\":\n            transaction_id = f\"pp_{request.user_id}_{int(request.amount * 100)}\"\n\n            self._events.append(\n                PaymentProcessedEvent(\n                    transaction_id=transaction_id,\n                    amount=request.amount,\n                    user_id=request.user_id,\n                )\n            )\n\n            return PaymentResult(\n                success=True,\n                transaction_id=transaction_id,\n                message=\"Payment processed via PayPal\",\n            )\n\n        return await self.next(request)\n\nclass BankTransferHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    def __init__(self):\n        self._events: list[cqrs.Event] = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events\n\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        if request.payment_method == \"bank_transfer\":\n            transaction_id = f\"bt_{request.user_id}_{int(request.amount * 100)}\"\n\n            self._events.append(\n                PaymentProcessedEvent(\n                    transaction_id=transaction_id,\n                    amount=request.amount,\n                    user_id=request.user_id,\n                )\n            )\n\n            return PaymentResult(\n                success=True,\n                transaction_id=transaction_id,\n                message=\"Payment processed via bank transfer\",\n            )\n\n        return await self.next(request)\n\nclass DefaultPaymentHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return []\n\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        return PaymentResult(\n            success=False,\n            message=f\"Unsupported payment method: {request.payment_method}\",\n        )\n\n# Mapper\ndef payment_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(\n        ProcessPaymentCommand,\n        [\n            CreditCardHandler,\n            PayPalHandler,\n            BankTransferHandler,\n            DefaultPaymentHandler,\n        ],\n    )\n\n# Usage\nasync def main():\n    mediator = bootstrap.bootstrap(\n        di_container=di.Container(),\n        commands_mapper=payment_mapper,\n    )\n\n    # Test different payment methods\n    result1 = await mediator.send(\n        ProcessPaymentCommand(\n            amount=100.0,\n            payment_method=\"credit_card\",\n            user_id=\"user1\",\n        )\n    )\n    print(f\"Credit card: {result1.message}\")\n\n    result2 = await mediator.send(\n        ProcessPaymentCommand(\n            amount=50.0,\n            payment_method=\"paypal\",\n            user_id=\"user2\",\n        )\n    )\n    print(f\"PayPal: {result2.message}\")\n\n    result3 = await mediator.send(\n        ProcessPaymentCommand(\n            amount=75.0,\n            payment_method=\"crypto\",  # Unsupported\n            user_id=\"user3\",\n        )\n    )\n    print(f\"Unsupported: {result3.message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"chain_of_responsibility/fallback/","title":"Chain of Responsibility Fallback","text":"<ul> <li> <p> Back to Chain of Responsibility Overview</p> <p>Return to the Chain of Responsibility overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"chain_of_responsibility/fallback/#overview","title":"Overview","text":"<p>You can combine Chain of Responsibility with Request Handler Fallback: the primary handler is a <code>RequestHandler</code> that delegates to a COR chain; when the chain raises (e.g. downstream failure), the fallback handler is invoked. This is useful when a request is first tried through a chain (e.g. cache \u2192 DB \u2192 external API) and you want a default/cached response if the whole chain fails.</p> Concept Description Primary A <code>RequestHandler</code> that runs the COR chain (e.g. injects chain entry via DI) Fallback A <code>RequestHandler</code> used when the chain raises Flow <code>mediator.send(request)</code> dispatches to primary; primary calls the chain; on exception, fallback runs <p>When to Use</p> <p>Use COR + Fallback when you have a chain of strategies (CoR) and a clear fallback path if the entire chain fails (e.g. connection errors to the last handler).</p>"},{"location":"chain_of_responsibility/fallback/#registration","title":"Registration","text":"<p>Bind the request type to <code>RequestHandlerFallback</code> with a wrapper handler as primary (the one that runs the chain) and a simple handler as fallback:</p> <pre><code>import cqrs\nfrom cqrs.requests.cor_request_handler import CORRequestHandler, build_chain\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(\n        FetchDataCommand,\n        cqrs.RequestHandlerFallback(\n            primary=CORChainWrapperHandler,   # RequestHandler that delegates to chain\n            fallback=FallbackFetchDataHandler,\n            failure_exceptions=(ConnectionError, TimeoutError),\n        ),\n    )\n</code></pre> <p>Build the chain and inject the chain entry (first handler) so the wrapper receives it:</p> <pre><code>source_a = SourceAHandler()\nsource_b = SourceBHandler()\ndefault = DefaultChainHandler()\nbuild_chain([source_a, source_b, default])\n\ndi_container.bind(\n    di.bind_by_type(\n        dependent.Dependent(lambda: source_a, scope=\"request\"),\n        SourceAHandler,\n    ),\n)\n\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    commands_mapper=commands_mapper,\n)\n</code></pre>"},{"location":"chain_of_responsibility/fallback/#wrapper-handler","title":"Wrapper Handler","text":"<p>The primary handler is a normal <code>RequestHandler</code> that holds the chain entry and delegates:</p> <pre><code>class CORChainWrapperHandler(\n    cqrs.RequestHandler[FetchDataCommand, FetchDataResult],\n):\n    \"\"\"Primary handler: runs the COR chain; chain entry injected via DI.\"\"\"\n\n    def __init__(self, chain_entry: SourceAHandler) -&gt; None:\n        self._chain_entry = chain_entry\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return []\n\n    async def handle(self, request: FetchDataCommand) -&gt; FetchDataResult:\n        result = await self._chain_entry.handle(request)\n        if result is None:\n            raise ValueError(\"COR chain did not handle the request\")\n        return result\n</code></pre> <p>When any handler in the chain raises (e.g. <code>ConnectionError</code>), the dispatcher catches it and invokes the fallback handler. Use <code>failure_exceptions</code> to restrict fallback to specific exception types.</p>"},{"location":"chain_of_responsibility/fallback/#fallback-handler","title":"Fallback Handler","text":"<p>The fallback is a simple <code>RequestHandler</code> that returns a default or cached response:</p> <pre><code>class FallbackFetchDataHandler(\n    cqrs.RequestHandler[FetchDataCommand, FetchDataResult],\n):\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return []\n\n    async def handle(self, request: FetchDataCommand) -&gt; FetchDataResult:\n        return FetchDataResult(\n            data=\"cached_or_default\",\n            source=\"fallback\",\n        )\n</code></pre>"},{"location":"chain_of_responsibility/fallback/#circuit-breaker-configuration","title":"Circuit Breaker configuration","text":"<p>CoR + Fallback uses <code>RequestHandlerFallback</code>, so Circuit Breaker is configured the same way as for Request Handler Fallback.</p> <ul> <li>Adapter: <code>AioBreakerAdapter</code> from <code>cqrs.adapters.circuit_breaker</code>.</li> <li>Parameters: <code>fail_max</code> (default <code>5</code>), <code>timeout_duration</code> (seconds, default <code>60</code>), <code>exclude</code> (exceptions that do not open the circuit), optional <code>storage_factory</code> for distributed state.</li> <li>One instance per domain \u2014 e.g. one adapter for request fallbacks (including COR wrapper); the adapter creates an isolated circuit per handler type.</li> </ul> <p>Example:</p> <pre><code>from cqrs.adapters.circuit_breaker import AioBreakerAdapter\n\nrequest_cb = AioBreakerAdapter(fail_max=5, timeout_duration=60)\nmapper.bind(\n    FetchDataCommand,\n    cqrs.RequestHandlerFallback(\n        primary=CORChainWrapperHandler,\n        fallback=FallbackFetchDataHandler,\n        failure_exceptions=(ConnectionError, TimeoutError),\n        circuit_breaker=request_cb,\n    ),\n)\n</code></pre> <p>Full configuration (exclude, storage_factory, failure_exceptions) is described in Request Handler Fallback \u2014 Circuit Breaker configuration and Saga Fallback \u2014 Circuit Breaker.</p>"},{"location":"chain_of_responsibility/fallback/#related","title":"Related","text":"<ul> <li>Request Handler Fallback \u2014 Fallback for command/query handlers</li> <li>Chain of Responsibility Examples \u2014 Registering and building COR chains</li> <li>Saga Fallback Pattern \u2014 Fallback for saga steps</li> </ul>"},{"location":"event_handler/","title":"Event Handling","text":""},{"location":"event_handler/#overview","title":"Overview","text":"<ul> <li> <p> Event Flow</p> <p>Understanding how events flow through the system from handlers to processing.</p> <p> Read More</p> </li> <li> <p> Runtime Processing</p> <p>How events are processed synchronously in the same request context.</p> <p> Read More</p> </li> <li> <p> Parallel Processing</p> <p>Configuring parallel event processing with concurrency limits.</p> <p> Read More</p> </li> <li> <p> Event Types</p> <p>DomainEvent vs NotificationEvent and when to use each type.</p> <p> Read More</p> </li> <li> <p> Examples</p> <p>Complete examples of event handling patterns.</p> <p> Read More</p> </li> <li> <p> Best Practices</p> <p>Best practices and recommendations for event handling.</p> <p> Read More</p> </li> <li> <p> Fallback</p> <p>Fallback handler when primary event handler fails or circuit breaker is open.</p> <p> Read More</p> </li> </ul> <p>Event handlers process domain events that are emitted from command handlers. These events represent something that happened in the domain and trigger side effects like sending notifications, updating read models, or triggering other workflows.</p> <p>When a command handler processes a request, it can emit domain events through the <code>events</code> property. These events are automatically collected and processed by event handlers registered in the system. Event handlers can in turn produce follow-up events via their own <code>events</code> property; these follow-ups are processed in the same pipeline (sequential BFS or parallel with semaphore), enabling multi-level event chains.</p> Aspect Description Runtime Processing Events are processed synchronously in the same request context, not asynchronously Automatic Dispatch Events are automatically dispatched to registered handlers after command execution Event Propagation Handlers can return follow-up events via <code>events</code>; they are processed in the same run (BFS or parallel) Parallel Support Multiple events can be processed in parallel with configurable concurrency limits Side Effects Event handlers perform side effects without blocking the main command flow <p>Prerequisites</p> <p>Understanding of Request Handlers and Bootstrap is required. Events are emitted by command handlers and processed by event handlers.</p> <p>Related Topics</p> <ul> <li>Transaction Outbox \u2014 For reliable event delivery to message brokers</li> <li>Event Producing \u2014 For publishing events to Kafka/RabbitMQ</li> <li>FastStream Integration \u2014 For consuming events from message brokers</li> </ul>"},{"location":"event_handler/best_practices/","title":"Best Practices","text":"<ul> <li> <p> Back to Event Handling Overview</p> <p>Return to the Event Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"event_handler/best_practices/#overview","title":"Overview","text":"Practice Description Impact Keep handlers fast Event handlers execute synchronously, so keep them fast Performance Handle errors Implement error handling in event handlers Reliability Use parallel processing Enable parallel processing for independent events Performance Limit concurrency Set appropriate <code>max_concurrent_event_handlers</code> based on resources Resource management Idempotency Make event handlers idempotent when possible Reliability Logging Log important events for debugging and monitoring Observability Follow-up events Use <code>handler.events</code> for multi-level chains; follow-ups run in the same pipeline (BFS or parallel) Design clarity <p>Performance Considerations</p> <p>Event handlers execute synchronously in the request context. Keep them fast to avoid blocking the main request flow.</p> <p>Parallel Processing</p> <p>Enable parallel event processing for independent events to improve performance. Set <code>concurrent_event_handle_enable=True</code> and configure <code>max_concurrent_event_handlers</code>.</p> <p>Event handling in <code>python-cqrs</code>:</p> <ul> <li>Runtime Processing \u2014 Events are processed synchronously in the same request context</li> <li>Automatic Dispatch \u2014 Events are automatically dispatched to registered handlers</li> <li>Event Propagation \u2014 Handlers can return follow-up events via <code>events</code>; they are processed in the same pipeline (BFS or parallel with semaphore)</li> <li>Parallel Support \u2014 Multiple events can be processed in parallel with configurable limits</li> <li>Two Types \u2014 DomainEvent (in-process) and NotificationEvent (message broker)</li> <li>Side Effects \u2014 Event handlers perform side effects without blocking command execution</li> </ul> <p>Use event handlers to implement side effects like notifications, read model updates, and workflow triggers while keeping your command handlers focused on business logic.</p>"},{"location":"event_handler/event_flow/","title":"Event Flow","text":"<ul> <li> <p> Back to Event Handling Overview</p> <p>Return to the Event Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"event_handler/event_flow/#overview","title":"Overview","text":"<p>The event handling flow follows these steps:</p>"},{"location":"event_handler/event_flow/#high-level-flow","title":"High-Level Flow","text":"<pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Mediator\n    participant Handler as Command Handler\n    participant Events as Events Collection\n    participant Processor as Event Processor\n    participant Emitter as Event Emitter\n    participant Handlers as Event Handlers\n    participant Broker as Message Broker\n\n    Client-&gt;&gt;Mediator: 1. Send Command\n    Mediator-&gt;&gt;Handler: 2. Execute Handler\n    Handler-&gt;&gt;Handler: 3. Business Logic\n    Handler-&gt;&gt;Events: 4. Collect Events\n    Handler--&gt;&gt;Mediator: 5. Return Response\n\n    Mediator-&gt;&gt;Processor: 6. Emit Events\n    Processor-&gt;&gt;Emitter: 7. Emit Each Event\n\n    alt DomainEvent\n        Emitter-&gt;&gt;Handlers: 8. Execute Event Handlers\n        Handlers--&gt;&gt;Emitter: 9. handler.events (follow-ups)\n        Emitter--&gt;&gt;Processor: 10. Return follow-ups\n        Note over Processor: Process follow-ups in same pipeline (BFS or parallel)\n    else NotificationEvent\n        Emitter-&gt;&gt;Broker: 8. Send to Message Broker\n        Broker--&gt;&gt;Emitter: 9. Complete\n        Emitter--&gt;&gt;Processor: 10. No follow-ups\n    end\n\n    Processor--&gt;&gt;Mediator: 11. Complete\n    Mediator--&gt;&gt;Client: 12. Return Response</code></pre> <p>Follow-up events</p> <p>For domain events, handlers can return follow-up events via the <code>events</code> property. The processor continues emitting these in the same pipeline (sequential BFS or parallel with semaphore) until the queue is empty.</p>"},{"location":"event_handler/event_flow/#detailed-event-processing-flow","title":"Detailed Event Processing Flow","text":"<pre><code>graph TD\n    A[Command Handler Executes] --&gt;|Collect Events| B[Events Property]\n    B --&gt;|Return Events| C[RequestMediator]\n    C --&gt;|Has Events?| D{Events Exist?}\n\n    D --&gt;|No| E[Return Response]\n    D --&gt;|Yes| F[EventProcessor.emit_events]\n\n    F --&gt;|Queue: initial events| G{Parallel Enabled?}\n\n    G --&gt;|No| H[Sequential: BFS]\n    G --&gt;|Yes| I[Parallel: Semaphore + FIRST_COMPLETED]\n\n    H --&gt; J[Pop Event from Queue]\n    I --&gt; J\n\n    J --&gt; K[EventEmitter.emit]\n    K --&gt; L{Event Type?}\n\n    L --&gt;|DomainEvent| M[EventMap Lookup]\n    L --&gt;|NotificationEvent| N[Send to Broker]\n\n    M --&gt; O[Resolve Handler from DI]\n    O --&gt; P[Execute handler.handle]\n    P --&gt; Q[Collect handler.events - follow-ups]\n    Q --&gt; R[Return follow-ups to Processor]\n\n    N --&gt; R\n    R --&gt; S{More in Queue?}\n    S --&gt;|Yes| G\n    S --&gt;|No| E\n\n    style A fill:#e1f5ff\n    style B fill:#fff3e0\n    style F fill:#c8e6c9\n    style P fill:#c8e6c9\n    style Q fill:#fff9c4\n    style E fill:#f3e5f5</code></pre>"},{"location":"event_handler/event_flow/#1-event-collection","title":"1. Event Collection","text":"<p>Command handlers collect events in the <code>events</code> property:</p> <pre><code>class JoinMeetingCommandHandler(RequestHandler[JoinMeetingCommand, None]):\n    def __init__(self):\n        self._events: list[Event] = []\n\n    @property\n    def events(self) -&gt; list[Event]:\n        return self._events\n\n    async def handle(self, request: JoinMeetingCommand) -&gt; None:\n        # Business logic\n        STORAGE[request.meeting_id].append(request.user_id)\n\n        # Collect domain event\n        self._events.append(\n            UserJoined(user_id=request.user_id, meeting_id=request.meeting_id)\n        )\n</code></pre>"},{"location":"event_handler/event_flow/#2-event-emission","title":"2. Event Emission","text":"<p>After the command handler completes, the mediator collects events and emits them through EventProcessor:</p> <pre><code>dispatch_result = await self._dispatcher.dispatch(request)\n\n# Events are emitted through EventProcessor\n# EventProcessor uses EventEmitter which handles:\n# - DomainEvent: processes via event handlers (in-process)\n# - NotificationEvent: sends to message broker\nawait self._event_processor.emit_events(dispatch_result.events)\n</code></pre> <p>The <code>EventProcessor</code> handles parallel or sequential processing based on configuration, and <code>EventEmitter</code> routes events to appropriate handlers or message brokers.</p>"},{"location":"event_handler/event_flow/#3-event-processing-via-eventemitter","title":"3. Event Processing via EventEmitter","text":"<p>Events are processed through <code>EventEmitter</code>, which routes them based on event type. For domain events, after each handler runs, follow-up events from <code>handler.events</code> are collected and returned; the processor then continues with these in the same pipeline (BFS in sequential mode, or under the same semaphore in parallel mode).</p> <pre><code>graph TD\n    A[EventEmitter.emit] --&gt;|1. Get Event Type| B{Event Type?}\n\n    B --&gt;|DomainEvent| C[EventMap.get]\n    C --&gt;|2. Find Handlers| D{Handlers Found?}\n    D --&gt;|No| E[Log Warning]\n    D --&gt;|Yes| F[Loop Through Handlers]\n    F --&gt;|3. Resolve Handler| G[DI Container]\n    G --&gt;|4. Execute handler.handle| H[Handler.handle]\n    H --&gt;|5. Collect handler.events| I[Follow-up events]\n    I --&gt; J[Return follow-ups to Processor]\n\n    B --&gt;|NotificationEvent| K{Message Broker?}\n    K --&gt;|No| L[Raise RuntimeError]\n    K --&gt;|Yes| M[Send to Message Broker]\n    M --&gt; N[Return empty - no follow-ups]\n\n    style A fill:#e1f5ff\n    style H fill:#c8e6c9\n    style I fill:#fff9c4\n    style J fill:#fff3e0</code></pre>"},{"location":"event_handler/event_flow/#31-follow-up-events-from-event-handlers-event-propagation","title":"3.1. Follow-up events from event handlers (event propagation)","text":"<p>Event handlers can produce follow-up events by implementing the <code>events</code> property. After <code>handle()</code> is called, the emitter reads <code>handler.events</code> and returns them to the processor. These follow-ups are processed in the same pipeline:</p> Mode Behavior Sequential (<code>concurrent_event_handle_enable=False</code>) Events and follow-ups are processed in BFS order: one event at a time, then its follow-ups are appended to the queue. Parallel (<code>concurrent_event_handle_enable=True</code>) Events are processed under a semaphore; as soon as any task completes, its follow-ups are queued and started (FIRST_COMPLETED), without waiting for sibling events. <p>This allows multi-level event chains: e.g. <code>OrderCreated</code> \u2192 handler emits <code>InventoryReserved</code> \u2192 handler emits <code>NotificationScheduled</code>, all in one run.</p> <p>Example: handler that produces a follow-up event:</p> <pre><code>class OrderCreatedEventHandler(cqrs.EventHandler[OrderCreatedEvent]):\n    def __init__(self) -&gt; None:\n        self._follow_ups: list[cqrs.IEvent] = []\n\n    @property\n    def events(self) -&gt; typing.Sequence[cqrs.IEvent]:\n        return tuple(self._follow_ups)\n\n    async def handle(self, event: OrderCreatedEvent) -&gt; None:\n        # Side effects...\n        self._follow_ups.append(InventoryReservedEvent(order_id=event.order_id))\n</code></pre>"},{"location":"event_handler/event_flow/#4-event-routing","title":"4. Event Routing","text":"<p><code>EventEmitter</code> automatically routes events based on their type:</p> <ul> <li>DomainEvent \u2014 Processed by event handlers registered in EventMap (in-process). Handlers may return follow-up events via the <code>events</code> property; these are processed in the same pipeline (BFS or parallel with semaphore).</li> <li>NotificationEvent \u2014 Sent to message broker (Kafka, RabbitMQ, etc.) for asynchronous processing; no follow-ups.</li> </ul> <p>Single Processing</p> <p>Each event instance is processed only once through EventEmitter. Follow-up events returned by handlers are new events that are then processed in the same run (same pipeline) until the queue is empty.</p>"},{"location":"event_handler/event_types/","title":"Event Types","text":"<ul> <li> <p> Back to Event Handling Overview</p> <p>Return to the Event Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"event_handler/event_types/#overview","title":"Overview","text":"Event Type Processing Use Case DomainEvent Processed by event handlers in-process Domain logic, read model updates NotificationEvent Sent to message brokers Cross-service communication"},{"location":"event_handler/event_types/#domainevent","title":"DomainEvent","text":"<p>Domain events represent something that happened in the domain. They are processed by event handlers. Handlers can return follow-up events via the <code>events</code> property; these are processed in the same pipeline (see Event Flow).</p> <pre><code>class UserJoined(cqrs.DomainEvent, frozen=True):\n    user_id: str\n    meeting_id: str\n\nclass UserJoinedEventHandler(cqrs.EventHandler[UserJoined]):\n    async def handle(self, event: UserJoined) -&gt; None:\n        # Process domain event\n        # Optionally populate self._follow_ups and return via events property\n        ...\n</code></pre>"},{"location":"event_handler/event_types/#notificationevent","title":"NotificationEvent","text":"<p>Notification events are sent to message brokers:</p> <pre><code>class UserJoinedNotification(cqrs.NotificationEvent[UserJoinedPayload]):\n    event_name: str = \"user_joined\"\n    topic: str = \"user_events\"\n    payload: UserJoinedPayload\n\n# Automatically sent to message broker via EventEmitter\n</code></pre>"},{"location":"event_handler/event_types/#event-type-comparison","title":"Event Type Comparison","text":"Aspect DomainEvent NotificationEvent Processing In-process handlers Message broker Latency Synchronous Asynchronous Reliability Immediate Requires Outbox pattern Use Case Domain logic Cross-service communication"},{"location":"event_handler/examples/","title":"Complete Examples","text":"<ul> <li> <p> Back to Event Handling Overview</p> <p>Return to the Event Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"event_handler/examples/#overview","title":"Overview","text":"<p>Here's a complete example demonstrating event handling:</p> <pre><code>import asyncio\nimport di\nimport cqrs\nfrom cqrs.requests import bootstrap\n\n# Domain event\nclass UserJoined(cqrs.DomainEvent, frozen=True):\n    user_id: str\n    meeting_id: str\n\n# Command handler\nclass JoinMeetingCommand(cqrs.Request):\n    user_id: str\n    meeting_id: str\n\nclass JoinMeetingCommandHandler(cqrs.RequestHandler[JoinMeetingCommand, None]):\n    def __init__(self):\n        self._events: list[cqrs.Event] = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events\n\n    async def handle(self, request: JoinMeetingCommand) -&gt; None:\n        # Business logic\n        print(f\"User {request.user_id} joined meeting {request.meeting_id}\")\n\n        # Emit domain event\n        self._events.append(\n            UserJoined(user_id=request.user_id, meeting_id=request.meeting_id)\n        )\n\n# Event handler\nclass UserJoinedEventHandler(cqrs.EventHandler[UserJoined]):\n    async def handle(self, event: UserJoined) -&gt; None:\n        print(f\"Processing event: User {event.user_id} joined meeting {event.meeting_id}\")\n        # Side effects: send notification, update read model, etc.\n\n# Mappers\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(JoinMeetingCommand, JoinMeetingCommandHandler)\n\ndef domain_events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(UserJoined, UserJoinedEventHandler)\n\n# Bootstrap with parallel processing\nmediator = bootstrap.bootstrap(\n    di_container=di.Container(),\n    commands_mapper=commands_mapper,\n    domain_events_mapper=domain_events_mapper,\n    max_concurrent_event_handlers=3,\n    concurrent_event_handle_enable=True,\n)\n\n# Execute command\nawait mediator.send(JoinMeetingCommand(user_id=\"123\", meeting_id=\"456\"))\n\n# Flow:\n# 1. Command handler executes\n# 2. UserJoined event is collected\n# 3. EventProcessor.emit_events runs (EventEmitter finds UserJoinedEventHandler)\n# 4. UserJoinedEventHandler.handle() executes\n# 5. Response is returned\n</code></pre>"},{"location":"event_handler/examples/#event-handler-chain-follow-up-events","title":"Event handler chain (follow-up events)","text":"<p>Event handlers can produce follow-up events via the <code>events</code> property. These are processed in the same pipeline (BFS in sequential mode, or under the same semaphore in parallel mode), enabling multi-level chains (e.g. L1 \u2192 L2 \u2192 L3).</p> <pre><code>import typing\nimport cqrs\nfrom cqrs.events.event import IEvent\n\n# Level 1: emitted by command handler\nclass EventL1(cqrs.DomainEvent, frozen=True):\n    seed: str\n\n# Level 2: emitted by HandlerL1\nclass EventL2(cqrs.DomainEvent, frozen=True):\n    seed: str\n\n# Level 3: emitted by HandlerL2 (terminal)\nclass EventL3(cqrs.DomainEvent, frozen=True):\n    seed: str\n\nclass HandlerL1(cqrs.EventHandler[EventL1]):\n    def __init__(self) -&gt; None:\n        self._follow_ups: list[IEvent] = []\n\n    @property\n    def events(self) -&gt; typing.Sequence[IEvent]:\n        return tuple(self._follow_ups)\n\n    async def handle(self, event: EventL1) -&gt; None:\n        # Side effects...\n        self._follow_ups.append(EventL2(seed=event.seed))\n\nclass HandlerL2(cqrs.EventHandler[EventL2]):\n    def __init__(self) -&gt; None:\n        self._follow_ups: list[IEvent] = []\n\n    @property\n    def events(self) -&gt; typing.Sequence[IEvent]:\n        return tuple(self._follow_ups)\n\n    async def handle(self, event: EventL2) -&gt; None:\n        # Side effects...\n        self._follow_ups.append(EventL3(seed=event.seed))\n\nclass HandlerL3(cqrs.EventHandler[EventL3]):\n    async def handle(self, event: EventL3) -&gt; None:\n        # Terminal handler \u2014 no follow-ups (default events = ())\n        pass\n\n# In events_mapper:\ndef domain_events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(EventL1, HandlerL1)\n    mapper.bind(EventL2, HandlerL2)\n    mapper.bind(EventL3, HandlerL3)\n</code></pre> <p>When you emit <code>EventL1(seed=\"x\")</code>, the processor runs: L1 \u2192 HandlerL1 emits L2 \u2192 HandlerL2 emits L3 \u2192 HandlerL3 runs. All in the same <code>emit_events()</code> call (sequential BFS or parallel with FIRST_COMPLETED).</p>"},{"location":"event_handler/fallback/","title":"Event Handler Fallback","text":"<ul> <li> <p> Back to Event Handling Overview</p> <p>Return to the Event Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"event_handler/fallback/#overview","title":"Overview","text":"<p>The Event Handler Fallback pattern allows you to register an alternative event handler that runs when the primary event handler fails (or when the circuit breaker is open). This provides resilience for side effects such as sending notifications or updating read models when the primary path (e.g. external API) is unavailable.</p> Concept Description Primary handler Main event handler that executes first Fallback handler Alternative handler invoked on primary failure or circuit open failure_exceptions Optional tuple of exception types that trigger fallback; if empty, any exception Circuit Breaker Optional; after threshold failures, primary is not called, fallback runs immediately <p>When to Use</p> <p>Use Event Handler Fallback when domain event side effects (notifications, read model updates, integrations) must degrade gracefully: e.g. enqueue for later or log when the primary handler (e.g. external notification API) fails.</p>"},{"location":"event_handler/fallback/#registration","title":"Registration","text":"<p>Bind the event type to <code>EventHandlerFallback(primary, fallback, ...)</code> in your domain events mapper:</p> <pre><code>import cqrs\n\ndef events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(\n        NotificationSent,\n        cqrs.EventHandlerFallback(\n            primary=PrimaryNotificationSentHandler,\n            fallback=FallbackNotificationSentHandler,\n            failure_exceptions=(ConnectionError, TimeoutError),  # optional\n            circuit_breaker=event_cb,  # optional\n        ),\n    )\n</code></pre> <ul> <li>primary \u2014 The primary event handler class (<code>EventHandler[EventType]</code>).</li> <li>fallback \u2014 The fallback event handler class; must handle the same event type.</li> <li>failure_exceptions \u2014 If non-empty, only these exception types trigger fallback; otherwise any exception triggers fallback.</li> <li>circuit_breaker \u2014 Optional <code>ICircuitBreaker</code> instance (e.g. <code>AioBreakerAdapter</code>). Use one instance per domain (e.g. one for events). When the circuit is open, the primary handler is not called and the fallback runs immediately.</li> </ul>"},{"location":"event_handler/fallback/#basic-example","title":"Basic Example","text":"<pre><code>class NotificationSent(cqrs.DomainEvent, frozen=True):\n    user_id: str\n    message: str\n\nclass PrimaryNotificationSentHandler(cqrs.EventHandler[NotificationSent]):\n    async def handle(self, event: NotificationSent) -&gt; None:\n        # e.g. call external notification API\n        raise RuntimeError(\"External notification service unavailable\")\n\nclass FallbackNotificationSentHandler(cqrs.EventHandler[NotificationSent]):\n    async def handle(self, event: NotificationSent) -&gt; None:\n        # e.g. enqueue for later or log\n        logger.info(\"Enqueue notification for user %s: %s\", event.user_id, event.message)\n\n# In events mapper:\nmapper.bind(\n    NotificationSent,\n    cqrs.EventHandlerFallback(\n        primary=PrimaryNotificationSentHandler,\n        fallback=FallbackNotificationSentHandler,\n    ),\n)\n</code></pre> <p>When a command handler emits <code>NotificationSent</code>, the event emitter runs the primary handler first. On exception (or when the circuit is open), the fallback handler is invoked. Events from the handler that actually ran are collected and processed.</p>"},{"location":"event_handler/fallback/#circuit-breaker-optional","title":"Circuit Breaker (optional)","text":"<p>To use a circuit breaker with event handlers:</p> <pre><code>pip install aiobreaker\n# or: pip install python-cqrs[aiobreaker]\n</code></pre> <pre><code>from cqrs.adapters.circuit_breaker import AioBreakerAdapter\n\nevent_cb = AioBreakerAdapter(fail_max=5, timeout_duration=60)\nmapper.bind(\n    NotificationSent,\n    cqrs.EventHandlerFallback(\n        primary=PrimaryNotificationSentHandler,\n        fallback=FallbackNotificationSentHandler,\n        circuit_breaker=event_cb,\n    ),\n)\n</code></pre> <p>After <code>fail_max</code> failures, the circuit opens and the fallback runs without calling the primary handler. See Saga Fallback \u2014 Circuit Breaker for the three-state pattern (CLOSED / OPEN / HALF_OPEN).</p>"},{"location":"event_handler/fallback/#circuit-breaker-configuration","title":"Circuit Breaker configuration","text":"<p>Use the same <code>AioBreakerAdapter</code> as for request handlers. Parameters:</p> Parameter Description Default <code>fail_max</code> Number of failures before opening the circuit <code>5</code> <code>timeout_duration</code> Seconds to wait before attempting HALF_OPEN (retry) <code>60</code> <code>exclude</code> Exception types that do not count as failures (e.g. business/validation errors) <code>[]</code> <code>storage_factory</code> Factory <code>(name: str) -&gt; storage</code> for circuit state; default is in-memory in-memory <p>Example with <code>exclude</code> \u2014 e.g. invalid payload should not open the circuit:</p> <pre><code>event_cb = AioBreakerAdapter(\n    fail_max=5,\n    timeout_duration=60,\n    exclude=[ValidationError],  # invalid events don't open the circuit\n)\nmapper.bind(\n    NotificationSent,\n    cqrs.EventHandlerFallback(\n        primary=PrimaryNotificationSentHandler,\n        fallback=FallbackNotificationSentHandler,\n        circuit_breaker=event_cb,\n    ),\n)\n</code></pre> <p>One instance per domain \u2014 use one <code>AioBreakerAdapter</code> for all event handler fallbacks that share the same policy. The adapter creates an isolated circuit per handler type.</p> <p>Storage: Default is in-memory. For multiple instances (e.g. several workers), pass a <code>storage_factory</code> that returns Redis storage so the circuit state is shared. See Saga Fallback \u2014 Circuit Breaker: Storage Configuration.</p> <p>Failure filtering: Use <code>failure_exceptions</code> on <code>EventHandlerFallback</code> to restrict which exceptions trigger fallback; use <code>exclude</code> on <code>AioBreakerAdapter</code> so certain exceptions do not open the circuit. See Saga Fallback \u2014 Circuit Breaker.</p>"},{"location":"event_handler/fallback/#related","title":"Related","text":"<ul> <li>Request Handler Fallback \u2014 Fallback for command/query handlers</li> <li>Stream Handling Fallback \u2014 Fallback for streaming handlers</li> <li>Saga Fallback Pattern \u2014 Fallback for saga steps</li> </ul>"},{"location":"event_handler/parallel_processing/","title":"Parallel Event Processing","text":"<ul> <li> <p> Back to Event Handling Overview</p> <p>Return to the Event Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"event_handler/parallel_processing/#overview","title":"Overview","text":"<p>Events can be processed in parallel to improve performance. This is controlled by two parameters:</p> <ul> <li><code>max_concurrent_event_handlers</code> \u2014 Maximum number of event handlers running simultaneously</li> <li><code>concurrent_event_handle_enable</code> \u2014 Enable/disable parallel processing</li> </ul>"},{"location":"event_handler/parallel_processing/#how-parallel-processing-works","title":"How Parallel Processing Works","text":"<p>In sequential mode, events and follow-ups (from <code>handler.events</code>) are processed in BFS order: one event at a time, then its follow-ups are appended to the queue. In parallel mode, events are processed under a semaphore; as soon as any task completes (FIRST_COMPLETED), its follow-up events are queued and started without waiting for sibling events. <code>emit_events</code> returns only when all events and follow-ups are done.</p> <pre><code>graph TD\n    Start[EventProcessor.emit_events] --&gt; CheckEnable{Parallel Enabled?}\n\n    CheckEnable --&gt;|No| Sequential[Sequential: BFS]\n    Sequential --&gt; PopSeq[Pop event from queue]\n    PopSeq --&gt; EmitSeq[EventEmitter.emit]\n    EmitSeq --&gt; RouteSeq{Route Event}\n    RouteSeq --&gt;|DomainEvent| HandlerSeq[Execute Handlers]\n    RouteSeq --&gt;|NotificationEvent| BrokerSeq[Send to Broker]\n    HandlerSeq --&gt; CollectSeq[Collect handler.events]\n    BrokerSeq --&gt; CollectSeq\n    CollectSeq --&gt; ExtendSeq[Append follow-ups to queue]\n    ExtendSeq --&gt; MoreSeq{Queue empty?}\n    MoreSeq --&gt;|No| PopSeq\n    MoreSeq --&gt;|Yes| End1[End]\n\n    CheckEnable --&gt;|Yes| Parallel[Parallel: Semaphore + FIRST_COMPLETED]\n    Parallel --&gt; PopPar[Start tasks for queued events]\n    PopPar --&gt; Semaphore[Acquire Semaphore per task]\n    Semaphore --&gt; EmitPar[EventEmitter.emit]\n    EmitPar --&gt; RoutePar{Route Event}\n    RoutePar --&gt;|DomainEvent| HandlerPar[Execute Handlers]\n    RoutePar --&gt;|NotificationEvent| BrokerPar[Send to Broker]\n    HandlerPar --&gt; CollectPar[Collect follow-ups]\n    BrokerPar --&gt; CollectPar\n    CollectPar --&gt; QueuePar[Queue follow-ups, start new tasks]\n    QueuePar --&gt; WaitPar[Wait FIRST_COMPLETED]\n    WaitPar --&gt; MorePar{Pending or queue?}\n    MorePar --&gt;|Yes| PopPar\n    MorePar --&gt;|No| End2[End]\n\n    style Start fill:#e1f5ff\n    style Sequential fill:#fff3e0\n    style Parallel fill:#c8e6c9\n    style Semaphore fill:#ffebee</code></pre>"},{"location":"event_handler/parallel_processing/#implementation","title":"Implementation","text":"<p>The <code>EventProcessor</code> handles parallel or sequential event emission. Follow-up events returned by handlers (via <code>handler.events</code>) are processed in the same pipeline: BFS in sequential mode, or under the same semaphore with FIRST_COMPLETED in parallel mode. The method returns when all events and follow-ups are done.</p> <pre><code>class EventProcessor:\n    def __init__(\n        self,\n        event_map: EventMap,\n        event_emitter: EventEmitter | None = None,\n        max_concurrent_event_handlers: int = 1,\n        concurrent_event_handle_enable: bool = True,\n    ):\n        self._event_emitter = event_emitter\n        self._max_concurrent_event_handlers = max_concurrent_event_handlers\n        self._concurrent_event_handle_enable = concurrent_event_handle_enable\n        self._event_semaphore = asyncio.Semaphore(max_concurrent_event_handlers)\n\n    async def emit_events(self, events: Sequence[IEvent]) -&gt; None:\n        \"\"\"Emit events and process follow-ups in the same pipeline.\"\"\"\n        if not events or not self._event_emitter:\n            return\n\n        if not self._concurrent_event_handle_enable:\n            # Sequential: BFS over events and follow-ups\n            to_process = deque(events)\n            while to_process:\n                event = to_process.popleft()\n                follow_ups = await self._event_emitter.emit(event)\n                to_process.extend(follow_ups)\n        else:\n            # Parallel: tasks under semaphore; follow-ups queued on FIRST_COMPLETED\n            await self._emit_events_parallel_first_completed(deque(events))\n\n    async def _emit_one_event(self, event: IEvent) -&gt; Sequence[IEvent]:\n        \"\"\"Emit one event under semaphore; returns follow-ups from handler.events.\"\"\"\n        async with self._event_semaphore:\n            return await self._event_emitter.emit(event)\n</code></pre> <p>The <code>EventEmitter.emit()</code> returns follow-up events from domain event handlers; the processor continues with these until the queue is empty.</p>"},{"location":"event_handler/parallel_processing/#configuration","title":"Configuration","text":"<pre><code>from cqrs.requests import bootstrap\n\n# Enable parallel processing with max 3 concurrent handlers\nmediator = bootstrap.bootstrap(\n    di_container=container,\n    commands_mapper=commands_mapper,\n    domain_events_mapper=domain_events_mapper,\n    max_concurrent_event_handlers=3,  # Max 3 handlers at once\n    concurrent_event_handle_enable=True,  # Enable parallel processing\n)\n</code></pre>"},{"location":"event_handler/parallel_processing/#default-values","title":"Default Values","text":"<ul> <li><code>RequestMediator</code> \u2014 <code>max_concurrent_event_handlers=1</code>, <code>concurrent_event_handle_enable=True</code></li> <li><code>StreamingRequestMediator</code> \u2014 <code>max_concurrent_event_handlers=10</code>, <code>concurrent_event_handle_enable=True</code></li> </ul>"},{"location":"event_handler/parallel_processing/#example-parallel-processing","title":"Example: Parallel Processing","text":"<pre><code># Command handler emits multiple events\nclass ProcessOrderCommandHandler(RequestHandler[ProcessOrderCommand, None]):\n    def __init__(self):\n        self._events: list[Event] = []\n\n    @property\n    def events(self) -&gt; list[Event]:\n        return self._events\n\n    async def handle(self, request: ProcessOrderCommand) -&gt; None:\n        # Business logic\n        ...\n\n        # Emit multiple events\n        self._events.append(OrderProcessedEvent(...))\n        self._events.append(InventoryUpdateEvent(...))\n        self._events.append(AuditLogEvent(...))\n        self._events.append(EmailNotificationEvent(...))\n\n# With max_concurrent_event_handlers=3:\n# - Up to 3 events (or follow-ups) run at once under the semaphore\n# - When any task completes, its follow-ups (from handler.events) are queued and started (FIRST_COMPLETED)\n# - emit_events() returns only when all events and follow-ups are done\n# - Each event is routed by EventEmitter:\n#   - DomainEvents \u2192 processed by handlers (follow-ups collected and processed in same pipeline)\n#   - NotificationEvents \u2192 sent to message broker (no follow-ups)\n</code></pre>"},{"location":"event_handler/runtime_processing/","title":"Runtime Processing","text":"<ul> <li> <p> Back to Event Handling Overview</p> <p>Return to the Event Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"event_handler/runtime_processing/#overview","title":"Overview","text":"<p>Important: Events are processed synchronously in the same request context, not asynchronously. This means:</p> <ul> <li>Events are processed before the command response is returned</li> <li>Event handlers execute in the same request lifecycle</li> <li>If an event handler fails, it can affect the command response</li> <li>Events are not queued or processed in background</li> </ul>"},{"location":"event_handler/runtime_processing/#why-runtime-processing","title":"Why Runtime Processing?","text":"<p>Runtime processing ensures:</p> <ol> <li>Consistency \u2014 Events are processed immediately, ensuring data consistency</li> <li>Error Handling \u2014 Errors in event handlers can be caught and handled in the same request</li> <li>Transaction Safety \u2014 Events can be part of the same transaction as business logic</li> <li>Predictability \u2014 You know when events are processed (immediately after command)</li> </ol>"},{"location":"event_handler/runtime_processing/#example-flow","title":"Example Flow","text":"<pre><code># Command execution\nawait mediator.send(JoinMeetingCommand(user_id=\"123\", meeting_id=\"456\"))\n\n# What happens:\n# 1. Command handler executes (synchronously)\n# 2. Events are collected from handler.events\n# 3. Events are emitted through EventProcessor (synchronously, in parallel if enabled)\n#    - EventProcessor uses EventEmitter which routes events:\n#      - DomainEvent \u2192 processed by event handlers (in-process)\n#      - NotificationEvent \u2192 sent to message broker\n# 4. Response is returned\n</code></pre> <p>The <code>EventEmitter</code> routes events to their handlers or message brokers. For DomainEvents, it uses EventDispatcher logic internally:</p> <pre><code>graph TD\n    Start[EventEmitter.emit DomainEvent] --&gt; GetType[Get Event Type]\n    GetType --&gt; Lookup[Lookup in EventMap]\n    Lookup --&gt; Found{Handlers Found?}\n\n    Found --&gt;|No| Warn[Log Warning]\n    Warn --&gt; End1[End]\n\n    Found --&gt;|Yes| LoopStart[For Each Handler Type]\n    LoopStart --&gt; Resolve[Resolve Handler from DI]\n    Resolve --&gt; Execute[await handler.handle]\n\n    Execute --&gt; NextHandler{More Handlers?}\n\n    NextHandler --&gt;|Yes| LoopStart\n    NextHandler --&gt;|No| End2[End]\n\n    style Start fill:#e1f5ff\n    style Resolve fill:#fff3e0\n    style Execute fill:#c8e6c9</code></pre>"},{"location":"event_handler/runtime_processing/#eventemitter-implementation-for-domainevents","title":"EventEmitter Implementation for DomainEvents","text":"<p><code>EventEmitter.emit()</code> returns a sequence of follow-up events from handlers. The processor uses these to continue the pipeline (BFS in sequential mode, or under the same semaphore in parallel mode).</p> <pre><code>class EventEmitter:\n    @emit.register\n    async def _(self, event: DomainEvent) -&gt; Sequence[IEvent]:\n        # 1. Find handlers for event type\n        handlers_types = self._event_map.get(type(event), [])\n\n        if not handlers_types:\n            logger.warning(f\"Handlers for event {type(event).__name__} not found\")\n            return ()\n\n        follow_ups: list[IEvent] = []\n        # 2. Process each handler\n        for handler_type in handlers_types:\n            # 3. Resolve handler from DI container\n            handler = await self._container.resolve(handler_type)\n\n            # 4. Execute handler\n            await handler.handle(event)\n            # 5. Collect follow-up events from handler.events\n            follow_ups.extend(list(handler.events))\n\n        return follow_ups\n</code></pre> <p>The <code>EventEmitter</code> is responsible for emitting events and routing them based on type:</p> <pre><code>graph TD\n    Start[EventEmitter.emit] --&gt; CheckType{Event Type?}\n\n    CheckType --&gt;|DomainEvent| DomainFlow[Domain Event Flow]\n    CheckType --&gt;|NotificationEvent| NotificationFlow[Notification Event Flow]\n\n    DomainFlow --&gt; FindHandlers[Find Handlers in EventMap]\n    FindHandlers --&gt; ResolveHandler[Resolve Handler]\n    ResolveHandler --&gt; ExecuteHandler[Execute Handler]\n    ExecuteHandler --&gt; CollectFollowUps[Collect handler.events]\n    CollectFollowUps --&gt; ReturnFollowUps[Return follow-ups to Processor]\n    ReturnFollowUps --&gt; End1[End]\n\n    NotificationFlow --&gt; CheckBroker{Broker Available?}\n    CheckBroker --&gt;|No| Error[Raise RuntimeError]\n    CheckBroker --&gt;|Yes| CreateMessage[Create Message]\n    CreateMessage --&gt; SendBroker[Send to Message Broker]\n    SendBroker --&gt; End2[End]\n\n    style Start fill:#e1f5ff\n    style DomainFlow fill:#c8e6c9\n    style NotificationFlow fill:#fff3e0\n    style ExecuteHandler fill:#c8e6c9\n    style SendBroker fill:#fff3e0</code></pre>"},{"location":"event_handler/runtime_processing/#emitter-implementation","title":"Emitter Implementation","text":"<pre><code>class EventEmitter:\n    @emit.register\n    async def _(self, event: DomainEvent) -&gt; Sequence[IEvent]:\n        # Find handlers for domain event\n        handlers_types = self._event_map.get(type(event), [])\n        follow_ups: list[IEvent] = []\n        for handler_type in handlers_types:\n            handler = await self._container.resolve(handler_type)\n            await handler.handle(event)\n            follow_ups.extend(list(handler.events))  # Follow-ups processed in same pipeline\n        return follow_ups\n\n    @emit.register\n    async def _(self, event: NotificationEvent) -&gt; Sequence[IEvent]:\n        await self._send_to_broker(event)\n        return ()  # No follow-ups for notification events\n</code></pre>"},{"location":"mermaid/","title":"Mermaid Diagram Generation","text":"<p>The <code>python-cqrs</code> package includes built-in support for generating Mermaid diagrams from various components. This feature is perfect for documentation, visualization, and understanding component structure and execution flow.</p>"},{"location":"mermaid/#overview","title":"Overview","text":"<p>Mermaid diagram generation is available for:</p> <ol> <li>Chain of Responsibility - Generate Sequence and Class diagrams for handler chains</li> <li>Saga Pattern - Generate Sequence and Class diagrams for saga execution flows</li> </ol>"},{"location":"mermaid/#available-generators","title":"Available Generators","text":""},{"location":"mermaid/#chain-of-responsibility","title":"Chain of Responsibility","text":"<p>The <code>CoRMermaid</code> class generates diagrams for Chain of Responsibility handler chains:</p> <ul> <li>Sequence Diagram - Shows the execution flow through the chain, successful handling, and pass-through scenarios</li> <li>Class Diagram - Shows the type structure, relationships between handlers, request types, response types, and chain links</li> </ul> <p>Learn more about Chain of Responsibility Mermaid \u2192</p>"},{"location":"mermaid/#saga-pattern","title":"Saga Pattern","text":"<p>The <code>SagaMermaid</code> class generates diagrams for Saga instances:</p> <ul> <li>Sequence Diagram - Shows the execution flow, success/failure scenarios, and compensation logic</li> <li>Class Diagram - Shows the type structure, relationships between Saga, steps, contexts, responses, and events</li> </ul> <p>Learn more about Saga Mermaid \u2192</p>"},{"location":"mermaid/#usage-in-documentation","title":"Usage in Documentation","text":"<p>Generated diagrams can be:</p> <ul> <li>Copied and pasted into Mermaid Live Editor for visualization</li> <li>Embedded directly in Markdown files (GitHub/GitLab support Mermaid)</li> <li>Used in documentation tools (Confluence, Notion, etc.)</li> <li>Included in README files for better understanding</li> </ul>"},{"location":"mermaid/#see-also","title":"See Also","text":"<ul> <li>Chain of Responsibility Mermaid Diagrams - Detailed guide for CoR diagrams</li> <li>Saga Mermaid Diagrams - Detailed guide for Saga diagrams</li> <li>Chain of Responsibility Overview - Learn about the Chain of Responsibility pattern</li> <li>Saga Pattern Overview - Learn about the Saga pattern</li> </ul>"},{"location":"mermaid/chain_of_responsibility/","title":"Mermaid Diagram Generation for Chain of Responsibility","text":"<p>The package includes built-in support for generating Mermaid diagrams from Chain of Responsibility handler chains. This feature is perfect for documentation, visualization, and understanding handler chain structure and execution flow.</p>"},{"location":"mermaid/chain_of_responsibility/#overview","title":"Overview","text":"<p>The <code>CoRMermaid</code> class can generate two types of diagrams:</p> <ol> <li>Sequence Diagram - Shows the execution flow through the chain, successful handling, and pass-through scenarios</li> <li>Class Diagram - Shows the type structure, relationships between handlers, request types, response types, and chain links</li> </ol>"},{"location":"mermaid/chain_of_responsibility/#example","title":"Example","text":"<p>You can find a complete working example in the repository:</p> <p>View Example: <code>cor_mermaid.py</code></p>"},{"location":"mermaid/chain_of_responsibility/#basic-usage","title":"Basic Usage","text":"<pre><code>from cqrs.requests.mermaid import CoRMermaid\nfrom cqrs.requests.cor_request_handler import CORRequestHandler\n\n# Create your handler chain (see Chain of Responsibility documentation for details)\nhandlers = [\n    CreditCardHandler,\n    PayPalHandler,\n    BankTransferHandler,\n    DefaultPaymentHandler,\n]\n\n# Create Mermaid generator\ngenerator = CoRMermaid(handlers)\n\n# Generate Sequence diagram showing execution flow\nsequence_diagram = generator.sequence()\nprint(sequence_diagram)\n\n# Generate Class diagram showing type structure\nclass_diagram = generator.class_diagram()\nprint(class_diagram)\n</code></pre>"},{"location":"mermaid/chain_of_responsibility/#sequence-diagram","title":"Sequence Diagram","text":"<p>The Sequence diagram visualizes the complete execution flow of a handler chain using nested <code>alt/else</code> blocks:</p> <ul> <li>Each handler can either process the request (return result and stop the chain) or pass to the next handler</li> <li>The diagram shows all possible paths through the chain using nested conditional blocks</li> <li>Any handler can process the request and stop the chain, not just the last one</li> <li>Handler names (not aliases) are used in <code>alt</code> conditions for better readability</li> <li>After a handler successfully processes a request, events are collected from the handler's <code>events</code> property and processed by the EventMediator</li> </ul>"},{"location":"mermaid/chain_of_responsibility/#example-handler-chain-code","title":"Example Handler Chain Code","text":"<pre><code>from cqrs.requests.cor_request_handler import CORRequestHandler\nfrom cqrs.response import Response\n\nclass ProcessPaymentCommand(cqrs.Request):\n    amount: float\n    payment_method: str\n    user_id: str\n\nclass PaymentResult(Response):\n    success: bool\n    transaction_id: str | None = None\n    message: str = \"\"\n\nclass CreditCardHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        if request.payment_method == \"credit_card\":\n            return PaymentResult(success=True, transaction_id=\"cc_123\")\n        return await self.next(request)\n\nclass PayPalHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        if request.payment_method == \"paypal\":\n            return PaymentResult(success=True, transaction_id=\"pp_123\")\n        return await self.next(request)\n\nclass DefaultPaymentHandler(CORRequestHandler[ProcessPaymentCommand, PaymentResult]):\n    async def handle(self, request: ProcessPaymentCommand) -&gt; PaymentResult | None:\n        return PaymentResult(success=False, message=\"Unsupported method\")\n\nhandlers = [CreditCardHandler, PayPalHandler, DefaultPaymentHandler]\n</code></pre>"},{"location":"mermaid/chain_of_responsibility/#generated-sequence-diagram","title":"Generated Sequence Diagram","text":""},{"location":"mermaid/chain_of_responsibility/#text-format","title":"Text Format","text":"<pre><code>sequenceDiagram\n    participant C as Chain\n    participant E as EventMediator\n    participant H1 as CreditCardHandler\n    participant H2 as PayPalHandler\n    participant H3 as DefaultPaymentHandler\n\n    Note over C: Chain Execution Flow\n    C-&gt;&gt;H1: handle(request)\n\n    alt CreditCardHandler can handle\n        H1--&gt;&gt;C: result\n        Note over H1: Handler processed, chain stops\n        C-&gt;&gt;H1: events\n        H1--&gt;&gt;C: List[Event]\n        C-&gt;&gt;E: process events\n        Note over E: Events from CreditCardHandler processed\n    else\n        H1-&gt;&gt;H2: next(request)\n        Note over H1: Cannot handle, passing to next\n        alt PayPalHandler can handle\n            H2--&gt;&gt;C: result\n            Note over H2: Handler processed, chain stops\n            C-&gt;&gt;H2: events\n            H2--&gt;&gt;C: List[Event]\n            C-&gt;&gt;E: process events\n            Note over E: Events from PayPalHandler processed\n        else\n            H2-&gt;&gt;H3: next(request)\n            Note over H2: Cannot handle, passing to next\n            alt DefaultPaymentHandler can handle\n                H3--&gt;&gt;C: result\n                Note over H3: Handler processed (default)\n                C-&gt;&gt;H3: events\n                H3--&gt;&gt;C: List[Event]\n                C-&gt;&gt;E: process events\n                Note over E: Events from DefaultPaymentHandler processed\n            end\n        end\n    end\n</code></pre>"},{"location":"mermaid/chain_of_responsibility/#rendered-diagram","title":"Rendered Diagram","text":"<pre><code>sequenceDiagram\n    participant C as Chain\n    participant E as EventMediator\n    participant H1 as CreditCardHandler\n    participant H2 as PayPalHandler\n    participant H3 as DefaultPaymentHandler\n\n    Note over C: Chain Execution Flow\n    C-&gt;&gt;H1: handle(request)\n\n    alt CreditCardHandler can handle\n        H1--&gt;&gt;C: result\n        Note over H1: Handler processed, chain stops\n        C-&gt;&gt;H1: events\n        H1--&gt;&gt;C: List[Event]\n        C-&gt;&gt;E: process events\n        Note over E: Events from CreditCardHandler processed\n    else\n        H1-&gt;&gt;H2: next(request)\n        Note over H1: Cannot handle, passing to next\n        alt PayPalHandler can handle\n            H2--&gt;&gt;C: result\n            Note over H2: Handler processed, chain stops\n            C-&gt;&gt;H2: events\n            H2--&gt;&gt;C: List[Event]\n            C-&gt;&gt;E: process events\n            Note over E: Events from PayPalHandler processed\n        else\n            H2-&gt;&gt;H3: next(request)\n            Note over H2: Cannot handle, passing to next\n            alt DefaultPaymentHandler can handle\n                H3--&gt;&gt;C: result\n                Note over H3: Handler processed (default)\n                C-&gt;&gt;H3: events\n                H3--&gt;&gt;C: List[Event]\n                C-&gt;&gt;E: process events\n                Note over E: Events from DefaultPaymentHandler processed\n            end\n        end\n    end</code></pre>"},{"location":"mermaid/chain_of_responsibility/#class-diagram","title":"Class Diagram","text":"<p>The Class diagram shows the complete type structure and relationships:</p> <ul> <li>CORRequestHandler base class with its methods</li> <li>Handler classes with their methods (<code>handle</code>, <code>next</code>, <code>events</code>)</li> <li>Request classes with their fields</li> <li>Response classes with their fields</li> <li>Relationships between classes (inheritance, chain links, usage, return types)</li> </ul>"},{"location":"mermaid/chain_of_responsibility/#generated-class-diagram","title":"Generated Class Diagram","text":""},{"location":"mermaid/chain_of_responsibility/#text-format_1","title":"Text Format","text":"<pre><code>classDiagram\n    class CORRequestHandler {\n        &lt;&lt;abstract&gt;&gt;\n        +handle(request) Response | None\n        +next(request) Response | None\n        +set_next(handler) CORRequestHandler\n        +events: List[Event]\n    }\n\n    class CreditCardHandler {\n        +handle(request) Response | None\n        +next(request) Response | None\n        +events: List[Event]\n    }\n\n    class PayPalHandler {\n        +handle(request) Response | None\n        +next(request) Response | None\n        +events: List[Event]\n    }\n\n    class DefaultPaymentHandler {\n        +handle(request) Response | None\n        +next(request) Response | None\n        +events: List[Event]\n    }\n\n    class ProcessPaymentCommand {\n        +amount: float\n        +payment_method: str\n        +user_id: str\n    }\n\n    class PaymentResult {\n        +success: bool\n        +transaction_id: str | None\n        +message: str\n    }\n\n    %% Inheritance relationships\n    CORRequestHandler &lt;|-- CreditCardHandler\n    CORRequestHandler &lt;|-- PayPalHandler\n    CORRequestHandler &lt;|-- DefaultPaymentHandler\n\n    %% Chain relationships (set_next)\n    CreditCardHandler --&gt; PayPalHandler : set_next\n    PayPalHandler --&gt; DefaultPaymentHandler : set_next\n\n    %% Handler to Request relationships\n    CreditCardHandler ..&gt; ProcessPaymentCommand : uses\n    PayPalHandler ..&gt; ProcessPaymentCommand : uses\n    DefaultPaymentHandler ..&gt; ProcessPaymentCommand : uses\n\n    %% Handler to Response relationships\n    CreditCardHandler ..&gt; PaymentResult : returns\n    PayPalHandler ..&gt; PaymentResult : returns\n    DefaultPaymentHandler ..&gt; PaymentResult : returns\n</code></pre>"},{"location":"mermaid/chain_of_responsibility/#rendered-diagram_1","title":"Rendered Diagram","text":"<pre><code>classDiagram\n    class CORRequestHandler {\n        &lt;&lt;abstract&gt;&gt;\n        +handle(request) Response | None\n        +next(request) Response | None\n        +set_next(handler) CORRequestHandler\n        +events: List[Event]\n    }\n\n    class CreditCardHandler {\n        +handle(request) Response | None\n        +next(request) Response | None\n        +events: List[Event]\n    }\n\n    class PayPalHandler {\n        +handle(request) Response | None\n        +next(request) Response | None\n        +events: List[Event]\n    }\n\n    class DefaultPaymentHandler {\n        +handle(request) Response | None\n        +next(request) Response | None\n        +events: List[Event]\n    }\n\n    class ProcessPaymentCommand {\n        +amount: float\n        +payment_method: str\n        +user_id: str\n    }\n\n    class PaymentResult {\n        +success: bool\n        +transaction_id: str | None\n        +message: str\n    }\n\n    %% Inheritance relationships\n    CORRequestHandler &lt;|-- CreditCardHandler\n    CORRequestHandler &lt;|-- PayPalHandler\n    CORRequestHandler &lt;|-- DefaultPaymentHandler\n\n    %% Chain relationships (set_next)\n    CreditCardHandler --&gt; PayPalHandler : set_next\n    PayPalHandler --&gt; DefaultPaymentHandler : set_next\n\n    %% Handler to Request relationships\n    CreditCardHandler ..&gt; ProcessPaymentCommand : uses\n    PayPalHandler ..&gt; ProcessPaymentCommand : uses\n    DefaultPaymentHandler ..&gt; ProcessPaymentCommand : uses\n\n    %% Handler to Response relationships\n    CreditCardHandler ..&gt; PaymentResult : returns\n    PayPalHandler ..&gt; PaymentResult : returns\n    DefaultPaymentHandler ..&gt; PaymentResult : returns</code></pre>"},{"location":"mermaid/chain_of_responsibility/#usage-in-documentation","title":"Usage in Documentation","text":"<p>Generated diagrams can be:</p> <ul> <li>Copied and pasted into Mermaid Live Editor for visualization</li> <li>Embedded directly in Markdown files (GitHub/GitLab support Mermaid)</li> <li>Used in documentation tools (Confluence, Notion, etc.)</li> <li>Included in README files for better understanding</li> </ul>"},{"location":"mermaid/chain_of_responsibility/#running-the-example","title":"Running the Example","text":"<p>To see the diagrams generated from a real handler chain, run:</p> <pre><code>python examples/cor_mermaid.py\n</code></pre> <p>This will output both Sequence and Class diagrams in a format ready to copy and paste into any Mermaid-compatible viewer.</p>"},{"location":"mermaid/chain_of_responsibility/#api-reference","title":"API Reference","text":""},{"location":"mermaid/chain_of_responsibility/#cormermaid-class","title":"CoRMermaid Class","text":""},{"location":"mermaid/chain_of_responsibility/#__init__handlers-listtypecorrequesthandlerany-any","title":"<code>__init__(handlers: List[type[CORRequestHandler[Any, Any]]])</code>","text":"<p>Initialize Mermaid diagram generator.</p> <p>Parameters: - <code>handlers</code>: List of handler classes in chain order</p>"},{"location":"mermaid/chain_of_responsibility/#sequence-str","title":"<code>sequence() -&gt; str</code>","text":"<p>Generate a Mermaid Sequence diagram showing chain execution flow.</p> <p>Returns: - A string containing the Mermaid Sequence diagram code</p>"},{"location":"mermaid/chain_of_responsibility/#class_diagram-str","title":"<code>class_diagram() -&gt; str</code>","text":"<p>Generate a Mermaid Class diagram showing handler chain structure, types, and relationships.</p> <p>Returns: - A string containing the Mermaid Class diagram code</p>"},{"location":"mermaid/chain_of_responsibility/#see-also","title":"See Also","text":"<ul> <li>Mermaid Overview - Overview of Mermaid diagram generation</li> <li>Chain of Responsibility Overview - Learn about the Chain of Responsibility pattern implementation</li> <li>Chain of Responsibility Examples - Complete examples</li> <li>Chain of Responsibility Advanced Topics - Advanced usage patterns</li> <li>Example: Basic CoR</li> <li>Example: CoR Mermaid Diagrams</li> </ul>"},{"location":"mermaid/saga/","title":"Mermaid Diagram Generation for Saga","text":"<p>The package includes built-in support for generating Mermaid diagrams from Saga instances. This feature is perfect for documentation, visualization, and understanding saga structure and execution flow.</p>"},{"location":"mermaid/saga/#overview","title":"Overview","text":"<p>The <code>SagaMermaid</code> class can generate two types of diagrams:</p> <ol> <li>Sequence Diagram - Shows the execution flow, success/failure scenarios, and compensation logic</li> <li>Class Diagram - Shows the type structure, relationships between Saga, steps, contexts, responses, and events</li> </ol>"},{"location":"mermaid/saga/#example","title":"Example","text":"<p>You can find a complete working example in the repository:</p> <p>View Example: <code>saga_mermaid.py</code></p>"},{"location":"mermaid/saga/#basic-usage","title":"Basic Usage","text":"<pre><code>from cqrs.saga.mermaid import SagaMermaid\nfrom cqrs.saga.saga import Saga\nfrom cqrs.saga.storage.memory import MemorySagaStorage\n\n# Create your saga class (steps are defined as class attribute)\nclass OrderSaga(Saga[OrderContext]):\n    steps = [ReserveInventoryStep, ProcessPaymentStep, ShipOrderStep]\n\n# Create saga instance\nsaga = OrderSaga()\n\n# Create Mermaid generator\ngenerator = SagaMermaid(saga)\n\n# Generate Sequence diagram showing execution flow\nsequence_diagram = generator.sequence()\nprint(sequence_diagram)\n\n# Generate Class diagram showing type structure\nclass_diagram = generator.class_diagram()\nprint(class_diagram)\n</code></pre>"},{"location":"mermaid/saga/#sequence-diagram","title":"Sequence Diagram","text":"<p>The Sequence diagram visualizes the complete execution flow of a saga, including:</p> <ul> <li>All saga steps in execution order (act methods)</li> <li>Successful execution flow</li> <li>Failure scenarios with automatic compensation</li> <li>Compensation flow in reverse order</li> </ul>"},{"location":"mermaid/saga/#example-saga-code","title":"Example Saga Code","text":"<pre><code>from cqrs.saga.saga import Saga\nfrom cqrs.saga.step import SagaStepHandler, SagaStepResult\nfrom cqrs.saga.models import SagaContext\nfrom cqrs.response import Response\nimport dataclasses\n\n@dataclasses.dataclass\nclass OrderContext(SagaContext):\n    order_id: str\n    user_id: str\n    items: list[str]\n    total_amount: float\n    shipping_address: str\n    inventory_reservation_id: str | None = None\n    payment_id: str | None = None\n    shipment_id: str | None = None\n\nclass ReserveInventoryResponse(Response):\n    reservation_id: str\n    items_reserved: list[str]\n\nclass ProcessPaymentResponse(Response):\n    payment_id: str\n    amount_charged: float\n    transaction_id: str\n\nclass ShipOrderResponse(Response):\n    shipment_id: str\n    tracking_number: str\n    estimated_delivery: str\n\nclass ReserveInventoryStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    # ... implementation\n\nclass ProcessPaymentStep(SagaStepHandler[OrderContext, ProcessPaymentResponse]):\n    # ... implementation\n\nclass ShipOrderStep(SagaStepHandler[OrderContext, ShipOrderResponse]):\n    # ... implementation\n\nclass OrderSaga(Saga[OrderContext]):\n    steps = [\n        ReserveInventoryStep,\n        ProcessPaymentStep,\n        ShipOrderStep,\n    ]\n\nsaga = OrderSaga()\n</code></pre>"},{"location":"mermaid/saga/#generated-sequence-diagram","title":"Generated Sequence Diagram","text":""},{"location":"mermaid/saga/#text-format","title":"Text Format","text":"<pre><code>sequenceDiagram\n    participant S as Saga\n    participant S1 as ReserveInventoryStep\n    participant S2 as ProcessPaymentStep\n    participant S3 as ShipOrderStep\n\n    Note over S: Successful Execution Flow\n    S-&gt;&gt;S1: act()\n    S1--&gt;&gt;S: success\n    S-&gt;&gt;S2: act()\n    S2--&gt;&gt;S: success\n    S-&gt;&gt;S3: act()\n    S3--&gt;&gt;S: success\n    Note over S: Saga Completed\n\n    Note over S: Failure &amp; Compensation Flow\n    S-&gt;&gt;S1: act()\n    S1--&gt;&gt;S: success\n    S-&gt;&gt;S2: act()\n    S2--&gt;&gt;S: success\n    S-&gt;&gt;S3: act()\n    S3--&gt;&gt;S: error\n\n    Note over S: Compensation (reverse order)\n    S-&gt;&gt;S2: compensate()\n    S2--&gt;&gt;S: success\n    S-&gt;&gt;S1: compensate()\n    S1--&gt;&gt;S: success\n    Note over S: Saga Failed\n</code></pre>"},{"location":"mermaid/saga/#rendered-diagram","title":"Rendered Diagram","text":"<pre><code>sequenceDiagram\n    participant S as Saga\n    participant S1 as ReserveInventoryStep\n    participant S2 as ProcessPaymentStep\n    participant S3 as ShipOrderStep\n\n    Note over S: Successful Execution Flow\n    S-&gt;&gt;S1: act()\n    S1--&gt;&gt;S: success\n    S-&gt;&gt;S2: act()\n    S2--&gt;&gt;S: success\n    S-&gt;&gt;S3: act()\n    S3--&gt;&gt;S: success\n    Note over S: Saga Completed\n\n    Note over S: Failure &amp; Compensation Flow\n    S-&gt;&gt;S1: act()\n    S1--&gt;&gt;S: success\n    S-&gt;&gt;S2: act()\n    S2--&gt;&gt;S: success\n    S-&gt;&gt;S3: act()\n    S3--&gt;&gt;S: error\n\n    Note over S: Compensation (reverse order)\n    S-&gt;&gt;S2: compensate()\n    S2--&gt;&gt;S: success\n    S-&gt;&gt;S1: compensate()\n    S1--&gt;&gt;S: success\n    Note over S: Saga Failed</code></pre>"},{"location":"mermaid/saga/#class-diagram","title":"Class Diagram","text":"<p>The Class diagram shows the complete type structure and relationships:</p> <ul> <li>Saga class with its methods and properties</li> <li>Step handler classes with their methods (<code>act</code>, <code>compensate</code>, <code>events</code>)</li> <li>Context classes with their fields</li> <li>Response classes with their fields</li> <li>Relationships between classes (composition, usage, return types)</li> </ul>"},{"location":"mermaid/saga/#generated-class-diagram","title":"Generated Class Diagram","text":""},{"location":"mermaid/saga/#text-format_1","title":"Text Format","text":"<pre><code>classDiagram\n    class Saga {\n        +steps: List[SagaStepHandler]\n        +transaction(context) SagaTransaction\n    }\n\n    class ReserveInventoryStep {\n        +act(context) SagaStepResult\n        +compensate(context) void\n        +events: List[Event]\n    }\n\n    class ProcessPaymentStep {\n        +act(context) SagaStepResult\n        +compensate(context) void\n        +events: List[Event]\n    }\n\n    class ShipOrderStep {\n        +act(context) SagaStepResult\n        +compensate(context) void\n        +events: List[Event]\n    }\n\n    class OrderContext {\n        +order_id: str\n        +user_id: str\n        +items: list[str]\n        +total_amount: float\n        +shipping_address: str\n        +inventory_reservation_id: str | None\n        +payment_id: str | None\n        +shipment_id: str | None\n    }\n\n    class ReserveInventoryResponse {\n        +reservation_id: str\n        +items_reserved: list[str]\n    }\n\n    class ProcessPaymentResponse {\n        +payment_id: str\n        +amount_charged: float\n        +transaction_id: str\n    }\n\n    class ShipOrderResponse {\n        +shipment_id: str\n        +tracking_number: str\n        +estimated_delivery: str\n    }\n\n    %% Saga relationships\n    Saga --&gt; ReserveInventoryStep : contains\n    Saga --&gt; ProcessPaymentStep : contains\n    Saga --&gt; ShipOrderStep : contains\n\n    %% Step to Context relationships\n    ReserveInventoryStep ..&gt; OrderContext : uses\n    ProcessPaymentStep ..&gt; OrderContext : uses\n    ShipOrderStep ..&gt; OrderContext : uses\n\n    %% Step to Response relationships\n    ReserveInventoryStep ..&gt; ReserveInventoryResponse : returns\n    ProcessPaymentStep ..&gt; ProcessPaymentResponse : returns\n    ShipOrderStep ..&gt; ShipOrderResponse : returns\n</code></pre>"},{"location":"mermaid/saga/#rendered-diagram_1","title":"Rendered Diagram","text":"<pre><code>classDiagram\n    class Saga {\n        +steps: List[SagaStepHandler]\n        +transaction(context) SagaTransaction\n    }\n\n    class ReserveInventoryStep {\n        +act(context) SagaStepResult\n        +compensate(context) void\n        +events: List[Event]\n    }\n\n    class ProcessPaymentStep {\n        +act(context) SagaStepResult\n        +compensate(context) void\n        +events: List[Event]\n    }\n\n    class ShipOrderStep {\n        +act(context) SagaStepResult\n        +compensate(context) void\n        +events: List[Event]\n    }\n\n    class OrderContext {\n        +order_id: str\n        +user_id: str\n        +items: list[str]\n        +total_amount: float\n        +shipping_address: str\n        +inventory_reservation_id: str | None\n        +payment_id: str | None\n        +shipment_id: str | None\n    }\n\n    class ReserveInventoryResponse {\n        +reservation_id: str\n        +items_reserved: list[str]\n    }\n\n    class ProcessPaymentResponse {\n        +payment_id: str\n        +amount_charged: float\n        +transaction_id: str\n    }\n\n    class ShipOrderResponse {\n        +shipment_id: str\n        +tracking_number: str\n        +estimated_delivery: str\n    }\n\n    %% Saga relationships\n    Saga --&gt; ReserveInventoryStep : contains\n    Saga --&gt; ProcessPaymentStep : contains\n    Saga --&gt; ShipOrderStep : contains\n\n    %% Step to Context relationships\n    ReserveInventoryStep ..&gt; OrderContext : uses\n    ProcessPaymentStep ..&gt; OrderContext : uses\n    ShipOrderStep ..&gt; OrderContext : uses\n\n    %% Step to Response relationships\n    ReserveInventoryStep ..&gt; ReserveInventoryResponse : returns\n    ProcessPaymentStep ..&gt; ProcessPaymentResponse : returns\n    ShipOrderStep ..&gt; ShipOrderResponse : returns</code></pre>"},{"location":"mermaid/saga/#usage-in-documentation","title":"Usage in Documentation","text":"<p>Generated diagrams can be:</p> <ul> <li>Copied and pasted into Mermaid Live Editor for visualization</li> <li>Embedded directly in Markdown files (GitHub/GitLab support Mermaid)</li> <li>Used in documentation tools (Confluence, Notion, etc.)</li> <li>Included in README files for better understanding</li> </ul>"},{"location":"mermaid/saga/#running-the-example","title":"Running the Example","text":"<p>To see the diagrams generated from a real saga, run:</p> <pre><code>python examples/saga_mermaid.py\n</code></pre> <p>This will output both Sequence and Class diagrams in a format ready to copy and paste into any Mermaid-compatible viewer.</p>"},{"location":"mermaid/saga/#api-reference","title":"API Reference","text":""},{"location":"mermaid/saga/#sagamermaid-class","title":"SagaMermaid Class","text":""},{"location":"mermaid/saga/#__init__saga-sagaany","title":"<code>__init__(saga: Saga[Any])</code>","text":"<p>Initialize Mermaid diagram generator.</p> <p>Parameters: - <code>saga</code>: The saga instance to generate diagram for</p>"},{"location":"mermaid/saga/#sequence-str","title":"<code>sequence() -&gt; str</code>","text":"<p>Generate a Mermaid Sequence diagram showing all saga steps and compensations.</p> <p>Returns: - A string containing the Mermaid Sequence diagram code</p>"},{"location":"mermaid/saga/#class_diagram-str","title":"<code>class_diagram() -&gt; str</code>","text":"<p>Generate a Mermaid Class diagram showing saga structure, types, and relationships.</p> <p>Returns: - A string containing the Mermaid Class diagram code</p>"},{"location":"mermaid/saga/#see-also","title":"See Also","text":"<ul> <li>Mermaid Overview - Overview of Mermaid diagram generation</li> <li>Saga Pattern Overview - Learn about the Saga pattern implementation</li> <li>Saga Flow Diagrams - Understanding saga execution flow</li> <li>Saga Recovery - Understanding saga recovery mechanisms</li> <li>Saga Compensation - Compensation strategies</li> <li>Saga Examples - Complete examples</li> <li>Example: Basic Saga</li> <li>Example: Saga Mermaid Diagrams</li> </ul>"},{"location":"outbox/","title":"Transactional Outbox","text":"<p>The Transactional Outbox pattern ensures reliable event publishing by storing events in a database table within the same transaction as business logic. This guarantees that events are persisted even if the system crashes before they can be published to a message broker.</p>"},{"location":"outbox/#overview","title":"Overview","text":"<ul> <li> <p> Implementation</p> <p>Interface and SQLAlchemy implementation for transactional outbox.</p> <p> Read More</p> </li> <li> <p> Usage</p> <p>Event registration and publishing with at-least-once delivery guarantees.</p> <p> Read More</p> </li> <li> <p> Examples</p> <p>Complete examples of transactional outbox pattern.</p> <p> Read More</p> </li> <li> <p> Best Practices</p> <p>Best practices and recommendations for reliable event delivery.</p> <p> Read More</p> </li> </ul> <p>The Transactional Outbox pattern solves the problem of ensuring event delivery in distributed systems. When a command handler processes a request and generates events, those events need to be published to a message broker. However, if the system crashes between processing the command and publishing the event, the event can be lost.</p> <p>The Outbox pattern solves this by:</p> Step Description Benefit 1. Store in Database Events are saved to an outbox table in the same transaction as business logic Guaranteed persistence 2. Separate Publishing A background process reads from the outbox and publishes events Decoupled publishing 3. At-least-once Delivery Events are only removed from outbox after successful publishing Reliable delivery <p>Prerequisites</p> <p>Understanding of Event Handling is required. The Outbox pattern ensures reliable delivery of events that are emitted by command handlers.</p> <p>Related Topics</p> <ul> <li>Event Producing \u2014 For configuring message brokers</li> <li>FastStream Integration \u2014 For consuming events from message brokers</li> <li>Bootstrap \u2014 For configuring outbox in bootstrap process</li> </ul>"},{"location":"outbox/#why-use-transactional-outbox","title":"Why Use Transactional Outbox?","text":""},{"location":"outbox/#the-problem","title":"The Problem","text":"<p>Without the Outbox pattern, event publishing can fail:</p> <pre><code>sequenceDiagram\n    participant Handler as Command Handler\n    participant DB as Database\n    participant Broker as Message Broker\n\n    Handler-&gt;&gt;DB: Process Command &amp; Commit\n    Handler-&gt;&gt;Broker: Publish Event\n    Note over Handler,Broker: \u274c System Crashes&lt;br/&gt;Event Lost!</code></pre>"},{"location":"outbox/#the-solution","title":"The Solution","text":"<p>With the Outbox pattern, events are safely stored:</p> <pre><code>sequenceDiagram\n    participant Handler as Command Handler\n    participant DB as Database\n    participant Outbox as Outbox Table\n    participant Publisher as Publisher Process\n    participant Broker as Message Broker\n\n    Handler-&gt;&gt;DB: Process Command\n    Handler-&gt;&gt;Outbox: Save Event (same transaction)\n    Handler-&gt;&gt;DB: Commit Transaction\n    Note over Handler,Outbox: \u2705 System Crashes&lt;br/&gt;Event Safe in Outbox!\n\n    Publisher-&gt;&gt;Outbox: Read Events\n    Publisher-&gt;&gt;Broker: Publish Events\n    Publisher-&gt;&gt;Outbox: Update Status</code></pre>"},{"location":"outbox/#pattern-flow","title":"Pattern Flow","text":"<p>The Transactional Outbox pattern follows this flow:</p> <pre><code>sequenceDiagram\n    participant Handler as Command Handler\n    participant DB as Database\n    participant Outbox as Outbox Table\n    participant Publisher as Event Publisher\n    participant Broker as Message Broker\n\n    Handler-&gt;&gt;DB: 1. Process Business Logic\n    Handler-&gt;&gt;Outbox: 2. Save Events (same transaction)\n    Handler-&gt;&gt;DB: 3. Commit Transaction\n    Note over DB,Outbox: Events safely stored\n\n    Publisher-&gt;&gt;Outbox: 4. Read Events (batch)\n    Publisher-&gt;&gt;Broker: 5. Publish Events\n    Publisher-&gt;&gt;Outbox: 6. Update Status (PRODUCED)\n    Publisher-&gt;&gt;DB: 7. Commit Transaction</code></pre>"},{"location":"outbox/#detailed-flow-diagram","title":"Detailed Flow Diagram","text":"<pre><code>graph TD\n    A[Command Handler] --&gt;|1. Process Command| B[Business Logic]\n    B --&gt;|2. Generate Events| C[Create Events]\n    C --&gt;|3. Save to Outbox| D[Outbox Table]\n    B --&gt;|Same Transaction| D\n    D --&gt;|4. Commit| E[Transaction Committed]\n\n    E --&gt;|Events Stored| F[Event Publisher Process]\n    F --&gt;|5. Read Batch| D\n    D --&gt;|6. Return Events| F\n    F --&gt;|7. Publish| G[Message Broker]\n    G --&gt;|8. Success| F\n    F --&gt;|9. Update Status| D\n    F --&gt;|10. Commit| E\n\n    style D fill:#e1f5ff\n    style E fill:#c8e6c9\n    style G fill:#fff3e0</code></pre>"},{"location":"outbox/best_practices/","title":"Best Practices","text":"<ul> <li> <p> Back to Transactional Outbox Overview</p> <p>Return to the Transactional Outbox overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"outbox/best_practices/#overview","title":"Overview","text":"<ol> <li>Always commit \u2014 Always call <code>commit()</code> after adding events</li> <li>Use transactions \u2014 Ensure outbox operations are in the same transaction as business logic</li> <li>Register events \u2014 Register all event types in <code>OutboxedEventMap</code></li> <li>Handle failures \u2014 Implement retry logic in the publisher process</li> <li>Monitor status \u2014 Track <code>NOT_PRODUCED</code> events for debugging</li> <li>Use compression \u2014 Enable compression for large payloads</li> <li> <p>Batch processing \u2014 Process events in batches for efficiency</p> </li> <li> <p>Event Producing \u2014 How to produce events without outbox</p> </li> <li>FastStream Integration \u2014 Kafka and RabbitMQ message broker configuration</li> <li>Dependency Injection \u2014 How to inject outbox repository</li> </ol>"},{"location":"outbox/examples/","title":"Examples","text":"<ul> <li> <p> Back to Transactional Outbox Overview</p> <p>Return to the Transactional Outbox overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"outbox/examples/#overview","title":"Overview","text":"<p>Here's a complete example showing the outbox pattern:</p> <pre><code>import asyncio\nimport di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom sqlalchemy.ext.asyncio import async_sessionmaker, create_async_engine\n\n# Register events\nclass UserJoinedPayload(cqrs.BaseModel, frozen=True):\n    user_id: str\n    meeting_id: str\n\ncqrs.OutboxedEventMap.register(\n    \"user_joined\",\n    cqrs.NotificationEvent[UserJoinedPayload],\n)\n\n# Command handler\nclass JoinMeetingCommand(cqrs.Request):\n    user_id: str\n    meeting_id: str\n\nclass JoinMeetingCommandHandler(cqrs.RequestHandler[JoinMeetingCommand, None]):\n    def __init__(self, outbox: cqrs.OutboxedEventRepository):\n        self.outbox = outbox\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return []\n\n    async def handle(self, request: JoinMeetingCommand) -&gt; None:\n        # Business logic\n        print(f\"User {request.user_id} joined meeting {request.meeting_id}\")\n\n        # Save event to outbox\n        self.outbox.add(\n            cqrs.NotificationEvent[UserJoinedPayload](\n                event_name=\"user_joined\",\n                topic=\"user_events\",\n                payload=UserJoinedPayload(\n                    user_id=request.user_id,\n                    meeting_id=request.meeting_id,\n                ),\n            )\n        )\n\n        # Commit transaction\n        await self.outbox.commit()\n\n# Setup DI\ndef setup_di():\n    container = di.Container()\n    session_factory = async_sessionmaker(\n        create_async_engine(\"mysql+asyncmy://user:pass@localhost/db\")\n    )\n\n    container.bind(\n        di.bind_by_type(\n            di.Dependent(\n                lambda: cqrs.SqlAlchemyOutboxedEventRepository(\n                    session=session_factory(),\n                ),\n                scope=\"request\",\n            ),\n            cqrs.OutboxedEventRepository,\n        )\n    )\n    return container\n\n# Bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=setup_di(),\n    commands_mapper=lambda m: m.bind(JoinMeetingCommand, JoinMeetingCommandHandler),\n)\n\n# Use mediator\nawait mediator.send(JoinMeetingCommand(user_id=\"123\", meeting_id=\"456\"))\n</code></pre>"},{"location":"outbox/implementation/","title":"Implementation","text":"<ul> <li> <p> Back to Transactional Outbox Overview</p> <p>Return to the Transactional Outbox overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"outbox/implementation/#overview","title":"Overview","text":"<p>The <code>OutboxedEventRepository</code> interface defines the contract for outbox implementations:</p> <pre><code>from abc import ABC\nfrom typing import Generic, List, Text\nimport cqrs\nfrom cqrs.outbox.repository import EventStatus, OutboxedEvent\n\nclass OutboxedEventRepository(ABC, Generic[Session]):\n    \"\"\"Abstract interface for outbox event repositories.\"\"\"\n\n    def add(self, event: cqrs.NotificationEvent) -&gt; None:\n        \"\"\"Add an event to the outbox repository.\"\"\"\n        pass\n\n    async def get_many(\n        self,\n        batch_size: int = 100,\n        topic: Text | None = None,\n    ) -&gt; List[OutboxedEvent]:\n        \"\"\"Get many events from the repository.\"\"\"\n        pass\n\n    async def update_status(\n        self,\n        outboxed_event_id: int,\n        new_status: EventStatus,\n    ) -&gt; None:\n        \"\"\"Update the event status.\"\"\"\n        pass\n\n    async def commit(self) -&gt; None:\n        \"\"\"Commit the transaction.\"\"\"\n        pass\n\n    async def rollback(self) -&gt; None:\n        \"\"\"Rollback the transaction.\"\"\"\n        pass\n</code></pre>"},{"location":"outbox/implementation/#methods","title":"Methods","text":""},{"location":"outbox/implementation/#addevent","title":"<code>add(event)</code>","text":"<p>Adds an event to the outbox. The event is stored but not yet committed. Must be called within a transaction context.</p> <p>Parameters: - <code>event</code> \u2014 <code>cqrs.NotificationEvent</code> to store</p> <p>Example: <pre><code>outbox.add(\n    cqrs.NotificationEvent[UserJoinedPayload](\n        event_name=\"user_joined\",\n        topic=\"user_events\",\n        payload=UserJoinedPayload(user_id=\"123\", meeting_id=\"456\"),\n    )\n)\n</code></pre></p>"},{"location":"outbox/implementation/#get_manybatch_size-topic","title":"<code>get_many(batch_size, topic)</code>","text":"<p>Retrieves events from the outbox in batches. Used by the publisher process.</p> <p>Parameters: - <code>batch_size</code> \u2014 Maximum number of events to retrieve (default: 100) - <code>topic</code> \u2014 Optional topic filter to retrieve events for specific topic</p> <p>Returns: - <code>List[OutboxedEvent]</code> \u2014 List of outboxed events</p> <p>Example: <pre><code>events = await outbox.get_many(batch_size=50, topic=\"user_events\")\n</code></pre></p>"},{"location":"outbox/implementation/#update_statusoutboxed_event_id-new_status","title":"<code>update_status(outboxed_event_id, new_status)</code>","text":"<p>Updates the status of an event in the outbox. Used to mark events as produced or failed.</p> <p>Parameters: - <code>outboxed_event_id</code> \u2014 ID of the event in outbox - <code>new_status</code> \u2014 New status (<code>EventStatus.NEW</code>, <code>EventStatus.PRODUCED</code>, <code>EventStatus.NOT_PRODUCED</code>)</p> <p>Example: <pre><code>await outbox.update_status(event_id=1, new_status=EventStatus.PRODUCED)\n</code></pre></p>"},{"location":"outbox/implementation/#commit","title":"<code>commit()</code>","text":"<p>Commits the current transaction. All events added via <code>add()</code> are persisted.</p> <p>Example: <pre><code>outbox.add(event1)\noutbox.add(event2)\nawait outbox.commit()  # Events are now persisted\n</code></pre></p>"},{"location":"outbox/implementation/#rollback","title":"<code>rollback()</code>","text":"<p>Rolls back the current transaction. All events added via <code>add()</code> are discarded.</p> <p>Example: <pre><code>try:\n    outbox.add(event1)\n    await outbox.commit()\nexcept Exception:\n    await outbox.rollback()  # Event is discarded\n</code></pre></p> <p>Events in the outbox have three possible statuses:</p> <pre><code>class EventStatus(StrEnum):\n    NEW = \"new\"              # Event is new and ready to be published\n    PRODUCED = \"produced\"    # Event has been successfully published\n    NOT_PRODUCED = \"not_produced\"  # Event publishing failed\n</code></pre> <p>The <code>python-cqrs</code> package includes a SQLAlchemy implementation of the outbox pattern.</p>"},{"location":"outbox/implementation/#database-schema","title":"Database Schema","text":"<p>The outbox table has the following structure:</p> <pre><code>CREATE TABLE outbox (\n    id BIGINT AUTO_INCREMENT PRIMARY KEY,\n    event_id UUID NOT NULL,\n    event_id_bin BINARY(16) NOT NULL,\n    event_status ENUM('new', 'produced', 'not_produced') NOT NULL DEFAULT 'new',\n    flush_counter SMALLINT NOT NULL DEFAULT 0,\n    event_name VARCHAR(255) NOT NULL,\n    topic VARCHAR(255) NOT NULL DEFAULT '',\n    created_at DATETIME NOT NULL,\n    payload BLOB NOT NULL,\n    UNIQUE KEY event_id_unique_index (event_id_bin, event_name)\n);\n</code></pre>"},{"location":"outbox/implementation/#features","title":"Features","text":"<ul> <li>UUID Support \u2014 Events have unique IDs for idempotency</li> <li>Binary Storage \u2014 Efficient storage of UUIDs as binary</li> <li>Status Tracking \u2014 Tracks event publishing status</li> <li>Compression Support \u2014 Optional payload compression</li> <li>Batch Processing \u2014 Optimized queries for batch retrieval</li> </ul>"},{"location":"outbox/implementation/#usage","title":"Usage","text":"<pre><code>from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine\nfrom cqrs import SqlAlchemyOutboxedEventRepository\nfrom cqrs.compressors import ZlibCompressor\n\n# Create session factory\nsession_factory = async_sessionmaker(\n    create_async_engine(\n        \"mysql+asyncmy://user:password@localhost/database\",\n        isolation_level=\"REPEATABLE READ\",\n    )\n)\n\n# Create repository with optional compression\noutbox = SqlAlchemyOutboxedEventRepository(\n    session=session_factory(),\n    compressor=ZlibCompressor(),  # Optional\n)\n\n# Use in command handler\nclass MyCommandHandler(RequestHandler[MyCommand, None]):\n    def __init__(self, outbox: OutboxedEventRepository):\n        self.outbox = outbox\n\n    async def handle(self, request: MyCommand) -&gt; None:\n        # Business logic\n        ...\n\n        # Save events to outbox\n        self.outbox.add(\n            cqrs.NotificationEvent[MyPayload](\n                event_name=\"my_event\",\n                topic=\"my_topic\",\n                payload=MyPayload(...),\n            )\n        )\n\n        # Commit transaction\n        await self.outbox.commit()\n</code></pre>"},{"location":"outbox/implementation/#configuration","title":"Configuration","text":""},{"location":"outbox/implementation/#table-name","title":"Table Name","text":"<p>By default, the table name is <code>outbox</code>. You can change it using the environment variable:</p> <pre><code>export OUTBOX_SQLA_TABLE=my_outbox_table\n</code></pre>"},{"location":"outbox/implementation/#compression","title":"Compression","text":"<p>Compression is optional but recommended for large payloads:</p> <pre><code>from cqrs.compressors import ZlibCompressor\n\noutbox = SqlAlchemyOutboxedEventRepository(\n    session=session,\n    compressor=ZlibCompressor(),\n)\n</code></pre>"},{"location":"outbox/usage/","title":"Usage","text":"<ul> <li> <p> Back to Transactional Outbox Overview</p> <p>Return to the Transactional Outbox overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"outbox/usage/#overview","title":"Overview","text":"<p>Events must be registered in <code>OutboxedEventMap</code> before they can be stored:</p> <pre><code>import cqrs\nfrom pydantic import BaseModel\n\nclass UserJoinedPayload(BaseModel, frozen=True):\n    user_id: str\n    meeting_id: str\n\n# Register event type\ncqrs.OutboxedEventMap.register(\n    \"user_joined\",\n    cqrs.NotificationEvent[UserJoinedPayload],\n)\n</code></pre> <p>This registration is required for: - Type safety when storing events - Deserialization when reading events - Validation of event structure</p> <p>Events are published by a separate process using <code>EventProducer</code>:</p> <pre><code>import asyncio\nimport cqrs\nfrom cqrs.message_brokers import kafka\nfrom cqrs.adapters import kafka as kafka_adapters\n\n# Create message broker\nbroker = kafka.KafkaMessageBroker(\n    producer=kafka_adapters.kafka_producer_factory(dsn=\"localhost:9092\"),\n)\n\n# Create event producer\nproducer = cqrs.EventProducer(\n    message_broker=broker,\n    repository=outbox_repository,\n)\n\n# Publish events in batches\nasync def publish_events():\n    async for events in producer.event_batch_generator():\n        for event in events:\n            await producer.send_message(event)\n        await producer.repository.commit()\n        await asyncio.sleep(10)  # Poll interval\n\nasyncio.run(publish_events())\n</code></pre>"},{"location":"request_handler/","title":"Request Handlers","text":""},{"location":"request_handler/#overview","title":"Overview","text":"<p>Request handlers process commands (write operations) and queries (read operations) in your CQRS application. They are the core of your business logic and are automatically resolved through the Dependency Injection container configured in Bootstrap.</p> Concept Description Can Emit Events Commands Modify system state \u2705 Yes Queries Read data without side effects \u274c No (typically) Handlers Implement business logic, resolved via DI Depends on type <p>Prerequisites</p> <p>Before creating handlers, ensure you've configured Bootstrap and understand Dependency Injection.</p> <p>Related Topics</p> <ul> <li>Request / Response Types \u2014 Different types for requests and responses (Pydantic, Dataclasses, attrs, etc.)</li> <li>Stream Handling \u2014 For incremental processing</li> <li>Chain of Responsibility \u2014 For sequential handler chains</li> <li>Saga Pattern \u2014 For distributed transactions with compensation</li> <li>Event Handling \u2014 For processing events emitted by command handlers</li> <li>Request Handler Fallback \u2014 Fallback mechanism for resilient command/query handling</li> </ul> <p>Request handlers can be divided into two main types:</p>"},{"location":"request_handler/#command-handler","title":"Command Handler","text":"<p>Command Handler executes the received command. The logic of the handler may include, for example, modifying the state of the domain model. As a result of executing the command, an event may be produced to the broker.</p> Aspect Description Purpose Execute write operations, modify system state Return Value Optional (can return <code>None</code> or a response) Events Can emit domain events via <code>events</code> property Handler Type <code>RequestHandler[Command, Response]</code> or <code>RequestHandler[Command, None]</code> <p>Return Value</p> <p>By default, the command handler does not return any result, but it is not mandatory. You can return a response if needed.</p> Command Handler Characteristics <ul> <li>Modifies state: Changes the system's state</li> <li>Can emit events: Returns events through <code>events</code> property</li> <li>Idempotent: Should be idempotent when possible</li> <li>Transactional: Often wrapped in database transactions</li> </ul> <pre><code>from cqrs.requests.request_handler import RequestHandler\nfrom cqrs.events.event import Event\n\nclass JoinMeetingCommandHandler(RequestHandler[JoinMeetingCommand, None]):\n\n      def __init__(self, meetings_api: MeetingAPIProtocol) -&gt; None:\n          self._meetings_api = meetings_api\n          self.events: list[Event] = []\n\n      @property\n      def events(self) -&gt; typing.List[events.Event]:\n          return self._events\n\n      async def handle(self, request: JoinMeetingCommand) -&gt; None:\n          await self._meetings_api.join_user(request.user_id, request.meeting_id)\n</code></pre>"},{"location":"request_handler/#query-handler","title":"Query Handler","text":"<p>Query Handler returns a representation of the requested data, for example, from the read model.</p> Aspect Description Purpose Read data without modifying system state Return Value Always returns a response Events Typically does not emit events Handler Type <code>RequestHandler[Query, QueryResponse]</code> <p>Read Model</p> <p>The read model can be constructed based on domain events produced by the <code>Command Handler</code>. This allows for optimized read operations.</p> Query Handler Characteristics <ul> <li>Read-only: Does not modify system state</li> <li>No side effects: Should not have side effects</li> <li>Optimized: Can use read models optimized for specific queries</li> <li>Fast: Should be fast and efficient</li> </ul> <pre><code>from cqrs.requests.request_handler import RequestHandler\nfrom cqrs.events.event import Event\n\nclass ReadMeetingQueryHandler(RequestHandler[ReadMeetingQuery, ReadMeetingQueryResult]):\n\n      def __init__(self, meetings_api: MeetingAPIProtocol) -&gt; None:\n          self._meetings_api = meetings_api\n          self.events: list[Event] = []\n\n      @property\n      def events(self) -&gt; typing.List[events.Event]:\n          return self._events\n\n      async def handle(self, request: ReadMeetingQuery) -&gt; ReadMeetingQueryResult:\n          link = await self._meetings_api.get_link(request.meeting_id)\n          return ReadMeetingQueryResult(link=link, meeting_id=request.meeting_id)\n</code></pre>"},{"location":"request_handler/fallback/","title":"Request Handler Fallback","text":"<ul> <li> <p> Back to Request Handlers Overview</p> <p>Return to the Request Handlers overview page.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"request_handler/fallback/#overview","title":"Overview","text":"<p>The Request Handler Fallback pattern allows you to register an alternative handler that runs when the primary request handler fails (or when the circuit breaker is open). This provides resilience for commands and queries when the primary path (e.g. database or external API) is unavailable.</p> Concept Description Primary handler Main request handler that executes first Fallback handler Alternative handler invoked on primary failure or circuit open failure_exceptions Optional tuple of exception types that trigger fallback; if empty, any exception Circuit Breaker Optional; after threshold failures, primary is not called, fallback runs immediately <p>When to Use</p> <p>Use Request Handler Fallback when you need resilient reads or writes: cached/default responses when the primary path fails, or when integrating with external services that may be temporarily unavailable.</p>"},{"location":"request_handler/fallback/#registration","title":"Registration","text":"<p>Bind the request type to <code>RequestHandlerFallback(primary, fallback, ...)</code> in your commands or queries mapper:</p> <pre><code>import cqrs\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(\n        GetUserProfileCommand,\n        cqrs.RequestHandlerFallback(\n            primary=PrimaryGetUserProfileHandler,\n            fallback=FallbackGetUserProfileHandler,\n            failure_exceptions=(ConnectionError, TimeoutError),  # optional\n            circuit_breaker=request_cb,  # optional\n        ),\n    )\n</code></pre> <ul> <li>primary \u2014 The primary request handler class (<code>RequestHandler</code> or <code>StreamingRequestHandler</code>).</li> <li>fallback \u2014 The fallback handler class; must handle the same request/response types.</li> <li>failure_exceptions \u2014 If non-empty, only these exception types trigger fallback; otherwise any exception triggers fallback.</li> <li>circuit_breaker \u2014 Optional <code>ICircuitBreaker</code> instance (e.g. <code>AioBreakerAdapter</code>). Use one instance per domain (e.g. one for requests). When the circuit is open, the primary handler is not called and the fallback runs immediately.</li> </ul>"},{"location":"request_handler/fallback/#basic-example","title":"Basic Example","text":"<pre><code>class GetUserProfileCommand(cqrs.Request):\n    user_id: str\n\nclass UserProfileResult(cqrs.Response):\n    user_id: str\n    name: str\n    source: str  # \"primary\" or \"fallback\"\n\nclass PrimaryGetUserProfileHandler(\n    cqrs.RequestHandler[GetUserProfileCommand, UserProfileResult],\n):\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return []\n\n    async def handle(self, request: GetUserProfileCommand) -&gt; UserProfileResult:\n        # e.g. database call that may raise\n        raise ConnectionError(\"Database unavailable\")\n\nclass FallbackGetUserProfileHandler(\n    cqrs.RequestHandler[GetUserProfileCommand, UserProfileResult],\n):\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return []\n\n    async def handle(self, request: GetUserProfileCommand) -&gt; UserProfileResult:\n        return UserProfileResult(\n            user_id=request.user_id,\n            name=\"Unknown User\",\n            source=\"fallback\",\n        )\n\n# In mapper:\nmapper.bind(\n    GetUserProfileCommand,\n    cqrs.RequestHandlerFallback(\n        primary=PrimaryGetUserProfileHandler,\n        fallback=FallbackGetUserProfileHandler,\n        failure_exceptions=(ConnectionError, TimeoutError),\n    ),\n)\n</code></pre> <p>The mediator dispatches to the primary handler; on exception (or when the circuit is open), the fallback handler is invoked. The response and events from the handler that actually ran are returned.</p>"},{"location":"request_handler/fallback/#circuit-breaker-optional","title":"Circuit Breaker (optional)","text":"<p>To use a circuit breaker, install the optional dependency and pass an adapter instance:</p> <pre><code>pip install aiobreaker\n# or: pip install python-cqrs[aiobreaker]\n</code></pre> <pre><code>from cqrs.adapters.circuit_breaker import AioBreakerAdapter\n\nrequest_cb = AioBreakerAdapter(fail_max=5, timeout_duration=60)\nmapper.bind(\n    GetUserProfileCommand,\n    cqrs.RequestHandlerFallback(\n        primary=PrimaryGetUserProfileHandler,\n        fallback=FallbackGetUserProfileHandler,\n        failure_exceptions=(ConnectionError, TimeoutError),\n        circuit_breaker=request_cb,\n    ),\n)\n</code></pre> <p>After <code>fail_max</code> failures, the circuit opens: the primary handler is not called and the fallback runs immediately. See Saga Fallback \u2014 Circuit Breaker for the same three-state pattern (CLOSED / OPEN / HALF_OPEN).</p>"},{"location":"request_handler/fallback/#circuit-breaker-configuration","title":"Circuit Breaker configuration","text":"<p>Adapter <code>AioBreakerAdapter</code> (from <code>cqrs.adapters.circuit_breaker</code>) implements <code>ICircuitBreaker</code> and accepts the following parameters:</p> Parameter Description Default <code>fail_max</code> Number of failures before opening the circuit <code>5</code> <code>timeout_duration</code> Seconds to wait before attempting HALF_OPEN (retry) <code>60</code> <code>exclude</code> Exception types that do not count as failures (e.g. business errors) <code>[]</code> <code>storage_factory</code> Factory <code>(name: str) -&gt; storage</code> for circuit state; default is in-memory in-memory <p>Example with <code>exclude</code> \u2014 business exceptions do not open the circuit:</p> <pre><code>class UserNotFoundError(Exception):\n    pass\n\nrequest_cb = AioBreakerAdapter(\n    fail_max=5,\n    timeout_duration=60,\n    exclude=[UserNotFoundError],  # 404-style errors don't open the circuit\n)\nmapper.bind(\n    GetUserProfileCommand,\n    cqrs.RequestHandlerFallback(\n        primary=PrimaryGetUserProfileHandler,\n        fallback=FallbackGetUserProfileHandler,\n        circuit_breaker=request_cb,\n    ),\n)\n</code></pre> <p>One instance per domain \u2014 use a single <code>AioBreakerAdapter</code> instance for all request fallbacks that share the same policy (e.g. one for commands). The adapter creates an isolated circuit per handler type (identifier = handler class).</p> <p>Storage: By default the circuit state is in-memory (per process). For distributed apps, you can pass a <code>storage_factory</code> that returns Redis (or other) storage so the circuit state is shared across instances. See Saga Fallback \u2014 Circuit Breaker: Storage Configuration.</p> <p>Failure filtering: Use <code>failure_exceptions</code> on <code>RequestHandlerFallback</code> to restrict which exceptions trigger fallback; use <code>exclude</code> on <code>AioBreakerAdapter</code> to prevent certain exceptions from opening the circuit. Details: Saga Fallback \u2014 Circuit Breaker: Failure Exception Filtering and Business Exception Exclusion.</p>"},{"location":"request_handler/fallback/#streaming-handlers","title":"Streaming Handlers","text":"<p><code>RequestHandlerFallback</code> also supports streaming handlers. Both <code>primary</code> and <code>fallback</code> can be <code>StreamingRequestHandler</code>. When the primary stream raises (e.g. after yielding some items), the dispatcher switches to the fallback handler's stream. See Stream Handling Fallback for details.</p>"},{"location":"request_handler/fallback/#related","title":"Related","text":"<ul> <li>Event Handler Fallback \u2014 Fallback for event handlers</li> <li>Stream Handling Fallback \u2014 Fallback for streaming handlers</li> <li>Chain of Responsibility \u2014 Can be combined with fallback (COR as primary)</li> <li>Saga Fallback Pattern \u2014 Fallback for saga steps</li> </ul>"},{"location":"request_response_types/","title":"Request and Response Types","text":""},{"location":"request_response_types/#overview","title":"Overview","text":"<p>The <code>python-cqrs</code> library provides flexible support for different types of request and response implementations. All request types must implement the <code>IRequest</code> interface, and all response types must implement the <code>IResponse</code> interface. This allows you to choose the best implementation for your specific use case.</p> <p>Interface Requirements</p> <p>Both <code>IRequest</code> and <code>IResponse</code> interfaces require:</p> <ul> <li><code>to_dict()</code> method: Convert instance to dictionary</li> <li><code>from_dict()</code> classmethod: Create instance from dictionary</li> </ul>"},{"location":"request_response_types/#navigation","title":"Navigation","text":"<ul> <li> <p> Pydantic</p> <p>Default implementation with validation and serialization features.</p> <p> Read More</p> </li> <li> <p> Dataclasses</p> <p>Lightweight implementation using Python's standard library.</p> <p> Read More</p> </li> <li> <p> Standard Classes</p> <p>Full control with custom Python classes.</p> <p> Read More</p> </li> <li> <p> NamedTuple</p> <p>Immutable data structures with memory efficiency.</p> <p> Read More</p> </li> <li> <p> Attrs</p> <p>Advanced features beyond standard dataclasses.</p> <p> Read More</p> </li> <li> <p> Msgspec</p> <p>High-performance serialization for microservices.</p> <p> Read More</p> </li> <li> <p> TypedDict</p> <p>Type hints with zero runtime overhead.</p> <p> Read More</p> </li> <li> <p> Mixed Usage</p> <p>Combining different types for requests and responses.</p> <p> Read More</p> </li> <li> <p> Best Practices</p> <p>Recommendations for choosing and using types.</p> <p> Read More</p> </li> </ul>"},{"location":"request_response_types/#comparison-table","title":"Comparison Table","text":"Type Validation Performance Dependencies Best For PydanticRequest/Response \u2705 Runtime Medium pydantic Web APIs, validation needed DCRequest/DCResponse \u274c Fast None (stdlib) Internal systems, lightweight Standard Classes Custom Fast None Full control, custom logic NamedTuple \u274c Very Fast None (stdlib) Immutable, memory-efficient Attrs \u2705 (with validators) Fast attrs More features than dataclasses Msgspec \u2705 Runtime Very Fast msgspec High-performance microservices TypedDict \u274c (static only) Fastest None (stdlib) Type hints, zero overhead"},{"location":"request_response_types/#quick-decision-guide","title":"Quick Decision Guide","text":""},{"location":"request_response_types/#need-validation","title":"Need Validation?","text":"<ul> <li>Pydantic \u2014 Best for web APIs with comprehensive validation</li> <li>Msgspec \u2014 High-performance alternative with validation</li> <li>Attrs \u2014 Custom validators with more flexibility</li> </ul>"},{"location":"request_response_types/#need-performance","title":"Need Performance?","text":"<ul> <li>Msgspec \u2014 Fastest serialization (Rust-based)</li> <li>Dataclasses \u2014 Fast, no dependencies</li> <li>NamedTuple \u2014 Very fast, immutable</li> </ul>"},{"location":"request_response_types/#need-lightweight","title":"Need Lightweight?","text":"<ul> <li>Dataclasses \u2014 Standard library, no dependencies</li> <li>NamedTuple \u2014 Minimal overhead</li> <li>TypedDict \u2014 Zero runtime overhead</li> </ul>"},{"location":"request_response_types/#need-flexibility","title":"Need Flexibility?","text":"<ul> <li>Standard Classes \u2014 Full control over implementation</li> <li>Attrs \u2014 Advanced features and customization</li> <li>Pydantic \u2014 Rich ecosystem and integrations</li> </ul>"},{"location":"request_response_types/#interface-contract","title":"Interface Contract","text":"<p>All request and response types must implement the following interface:</p> <pre><code>from abc import ABC, abstractmethod\nfrom typing import Self\n\nclass IRequest(ABC):\n    @abstractmethod\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert instance to dictionary.\"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    @abstractmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create instance from dictionary.\"\"\"\n        raise NotImplementedError\n\nclass IResponse(ABC):\n    @abstractmethod\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert instance to dictionary.\"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    @abstractmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create instance from dictionary.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"request_response_types/#built-in-types","title":"Built-in Types","text":"<p>The library provides two built-in implementations that you can use directly:</p> <ol> <li>PydanticRequest/PydanticResponse (aliased as <code>Request</code>/<code>Response</code>)</li> <li>Default implementation</li> <li>Runtime validation</li> <li>Type coercion</li> <li> <p>JSON Schema support</p> </li> <li> <p>DCRequest/DCResponse</p> </li> <li>Lightweight dataclass-based</li> <li>No external dependencies</li> <li>Fast and simple</li> </ol> <p>Prerequisites</p> <p>Understanding of Request Handlers is recommended. Request and response types are used in handler definitions.</p> <p>Related Topics</p> <ul> <li>Request Handlers \u2014 Learn how to use types in handlers</li> <li>Bootstrap \u2014 Setup and configuration</li> <li>Dependency Injection \u2014 DI container usage</li> </ul>"},{"location":"request_response_types/attrs/","title":"Attrs Request/Response","text":"<p>Advanced features - Uses the <code>attrs</code> library for more features than standard dataclasses.</p>"},{"location":"request_response_types/attrs/#best-for","title":"Best For","text":"<ul> <li>More features than standard dataclasses</li> <li>Functional-style codebases</li> <li>When you need more control than dataclasses</li> <li>Complex validation scenarios</li> </ul> <p>Installation</p> <pre><code>pip install attrs\n</code></pre>"},{"location":"request_response_types/attrs/#usage","title":"Usage","text":"<pre><code>import cqrs\nimport attrs\nfrom typing import Self\n\n@attrs.define\nclass AttrsRequest(cqrs.IRequest):\n    \"\"\"Request using attrs.\"\"\"\n    user_id: str = attrs.field(validator=attrs.validators.instance_of(str))\n    action: str = attrs.field(validator=attrs.validators.instance_of(str))\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return attrs.asdict(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(**kwargs)\n\n@attrs.define(frozen=True)\nclass AttrsResponse(cqrs.IResponse):\n    \"\"\"Immutable response using attrs.\"\"\"\n    result: str = attrs.field()\n    status: str = attrs.field()\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return attrs.asdict(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(**kwargs)\n\nclass AttrsHandler(cqrs.RequestHandler[AttrsRequest, AttrsResponse]):\n    @property\n    def events(self) -&gt; list[cqrs.IEvent]:\n        return []\n\n    async def handle(self, request: AttrsRequest) -&gt; AttrsResponse:\n        return AttrsResponse(\n            result=f\"Processed {request.action}\",\n            status=\"success\"\n        )\n</code></pre>"},{"location":"request_response_types/attrs/#validation","title":"Validation","text":"<p>Attrs provides powerful validation capabilities:</p> <pre><code>import attrs\nfrom typing import Self\n\n@attrs.define\nclass ValidatedRequest(cqrs.IRequest):\n    email: str = attrs.field(\n        validator=attrs.validators.matches_re(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n    )\n    age: int = attrs.field(\n        validator=attrs.validators.and_(\n            attrs.validators.ge(0),\n            attrs.validators.le(120)\n        )\n    )\n\n    def to_dict(self) -&gt; dict:\n        return attrs.asdict(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return cls(**kwargs)\n</code></pre>"},{"location":"request_response_types/attrs/#custom-converters","title":"Custom Converters","text":"<p>You can use converters for automatic type conversion:</p> <pre><code>@attrs.define\nclass ConvertedRequest(cqrs.IRequest):\n    count: int = attrs.field(converter=int)\n    tags: list[str] = attrs.field(\n        converter=lambda x: x.split(\",\") if isinstance(x, str) else x\n    )\n\n    def to_dict(self) -&gt; dict:\n        return attrs.asdict(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return cls(**kwargs)\n</code></pre>"},{"location":"request_response_types/attrs/#factory-functions","title":"Factory Functions","text":"<p>Attrs supports factory functions for default values:</p> <pre><code>@attrs.define\nclass RequestWithDefaults(cqrs.IRequest):\n    user_id: str\n    metadata: dict = attrs.field(factory=dict)\n    tags: list[str] = attrs.field(factory=list)\n\n    def to_dict(self) -&gt; dict:\n        return attrs.asdict(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return cls(**kwargs)\n</code></pre>"},{"location":"request_response_types/attrs/#immutable-classes","title":"Immutable Classes","text":"<p>Use <code>frozen=True</code> for immutability:</p> <pre><code>@attrs.define(frozen=True)\nclass ImmutableRequest(cqrs.IRequest):\n    user_id: str\n    action: str\n\n    def to_dict(self) -&gt; dict:\n        return attrs.asdict(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return cls(**kwargs)\n</code></pre>"},{"location":"request_response_types/attrs/#see-also","title":"See Also","text":"<ul> <li>Dataclasses - Standard library alternative</li> <li>Request Handlers - Learn about handler implementation</li> </ul>"},{"location":"request_response_types/best_practices/","title":"Best Practices","text":"<p>Recommendations for choosing and using request/response types in your CQRS application.</p>"},{"location":"request_response_types/best_practices/#choosing-the-right-type","title":"Choosing the Right Type","text":""},{"location":"request_response_types/best_practices/#decision-tree","title":"Decision Tree","text":"<pre><code>graph TD\n    Start[Choose Request/Response Type] --&gt; Q1{Need Validation?}\n\n    Q1 --&gt;|Yes| Q1A{Need High Performance?}\n    Q1A --&gt;|Yes| Msgspec[Msgspec]\n    Q1A --&gt;|No| Pydantic[Pydantic]\n\n    Q1 --&gt;|No| Q2{Need Performance?}\n    Q2 --&gt;|Yes| Q2A{Need Lightweight?}\n    Q2A --&gt;|Yes| Dataclasses1[Dataclasses]\n    Q2A --&gt;|No| Msgspec2[Msgspec]\n\n    Q2 --&gt;|No| Q3{Need Lightweight?}\n    Q3 --&gt;|Yes| Q3A{Need Immutability?}\n    Q3A --&gt;|Yes| NamedTuple[NamedTuple]\n    Q3A --&gt;|No| Dataclasses2[Dataclasses]\n\n    Q3 --&gt;|No| Q4{Need Flexibility?}\n    Q4 --&gt;|Yes| Q4A{Need Advanced Features?}\n    Q4A --&gt;|Yes| Attrs[Attrs]\n    Q4A --&gt;|No| StandardClasses[Standard Classes]\n\n    Q4 --&gt;|No| Dataclasses3[Dataclasses]\n\n    style Start fill:#e1f5ff,stroke:#01579b,stroke-width:4px\n    style Pydantic fill:#c8e6c9,stroke:#2e7d32,stroke-width:3px\n    style Msgspec fill:#fff3e0,stroke:#e65100,stroke-width:3px\n    style Msgspec2 fill:#fff3e0,stroke:#e65100,stroke-width:3px\n    style Dataclasses1 fill:#c8e6c9,stroke:#2e7d32,stroke-width:3px\n    style Dataclasses2 fill:#c8e6c9,stroke:#2e7d32,stroke-width:3px\n    style Dataclasses3 fill:#c8e6c9,stroke:#2e7d32,stroke-width:3px\n    style NamedTuple fill:#e1f5ff,stroke:#01579b,stroke-width:3px\n    style Attrs fill:#fff3e0,stroke:#e65100,stroke-width:3px\n    style StandardClasses fill:#ffcdd2,stroke:#c62828,stroke-width:3px</code></pre> <p>Type Descriptions:</p> <ul> <li>Pydantic \u2014 Rich validation &amp; features, best for web APIs</li> <li>Msgspec \u2014 High-performance with validation, up to 10x faster than Pydantic</li> <li>Dataclasses \u2014 Fast &amp; lightweight, no dependencies, default choice</li> <li>NamedTuple \u2014 Immutable &amp; memory-efficient</li> <li>Attrs \u2014 Advanced features beyond standard dataclasses</li> <li>Standard Classes \u2014 Full control over implementation</li> </ul> <p>Step-by-step guide:</p> <ol> <li>Need Validation?</li> <li>\u2705 Yes \u2192 Choose between Pydantic (rich features) or Msgspec (high performance)</li> <li> <p>\u274c No \u2192 Continue to step 2</p> </li> <li> <p>Need Performance?</p> </li> <li>\u2705 Yes \u2192 Choose Msgspec (fastest) or Dataclasses (fast &amp; lightweight)</li> <li> <p>\u274c No \u2192 Continue to step 3</p> </li> <li> <p>Need Lightweight?</p> </li> <li>\u2705 Yes \u2192 Choose Dataclasses (simple) or NamedTuple (immutable)</li> <li> <p>\u274c No \u2192 Continue to step 4</p> </li> <li> <p>Need Flexibility?</p> </li> <li>\u2705 Yes \u2192 Choose Standard Classes (full control) or Attrs (advanced features)</li> <li>\u274c No \u2192 Use Dataclasses (default choice)</li> </ol>"},{"location":"request_response_types/best_practices/#quick-reference","title":"Quick Reference","text":"Requirement Recommended Type Web APIs with validation Pydantic High-performance microservices Msgspec Internal systems, lightweight Dataclasses Immutable, memory-efficient NamedTuple Advanced features Attrs Static type checking only TypedDict Full control Standard Classes"},{"location":"request_response_types/best_practices/#consistency-guidelines","title":"Consistency Guidelines","text":""},{"location":"request_response_types/best_practices/#within-a-domain","title":"Within a Domain","text":"<p>Use the same type for related requests and responses:</p> <pre><code># \u2705 Good: Consistent types\nclass CreateUserCommand(cqrs.PydanticRequest):\n    pass\n\nclass UserResponse(cqrs.PydanticResponse):\n    pass\n\n# \u274c Avoid: Mixed types without reason\nclass CreateUserCommand(cqrs.PydanticRequest):\n    pass\n\nclass UserResponse(cqrs.DCResponse):  # Why different?\n    pass\n</code></pre>"},{"location":"request_response_types/best_practices/#across-domains","title":"Across Domains","text":"<p>Different domains can use different types based on their needs:</p> <pre><code># User domain - needs validation\nclass CreateUserCommand(cqrs.PydanticRequest):\n    pass\n\n# Analytics domain - performance critical\nclass ProcessEventRequest(cqrs.IRequest, msgspec.Struct):\n    pass\n</code></pre>"},{"location":"request_response_types/best_practices/#validation-strategy","title":"Validation Strategy","text":""},{"location":"request_response_types/best_practices/#external-input","title":"External Input","text":"<p>Always validate external input:</p> <pre><code># \u2705 Good: Validate external input\nclass CreateUserCommand(cqrs.PydanticRequest):\n    email: str = pydantic.Field(pattern=r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n    age: int = pydantic.Field(gt=0, le=120)\n</code></pre>"},{"location":"request_response_types/best_practices/#internal-communication","title":"Internal Communication","text":"<p>Internal communication can use lighter types:</p> <pre><code># \u2705 Good: Lightweight for internal use\n@dataclasses.dataclass\nclass InternalQuery(cqrs.DCRequest):\n    user_id: str\n</code></pre>"},{"location":"request_response_types/best_practices/#performance-considerations","title":"Performance Considerations","text":""},{"location":"request_response_types/best_practices/#high-throughput-scenarios","title":"High-Throughput Scenarios","text":"<p>For high-throughput scenarios, consider Msgspec:</p> <pre><code># High-performance request\nclass ProcessRequest(cqrs.IRequest, msgspec.Struct):\n    data: str\n</code></pre>"},{"location":"request_response_types/best_practices/#simple-data-structures","title":"Simple Data Structures","text":"<p>For simple data, Dataclasses are fast enough:</p> <pre><code>@dataclasses.dataclass\nclass SimpleRequest(cqrs.DCRequest):\n    id: str\n    value: int\n</code></pre>"},{"location":"request_response_types/best_practices/#migration-strategy","title":"Migration Strategy","text":""},{"location":"request_response_types/best_practices/#gradual-migration","title":"Gradual Migration","text":"<p>All types implement the same interface, so migration is straightforward:</p> <pre><code># Step 1: Start with Pydantic\nclass MyCommand(cqrs.PydanticRequest):\n    pass\n\n# Step 2: Migrate to Dataclass\n@dataclasses.dataclass\nclass MyCommand(cqrs.DCRequest):\n    pass\n</code></pre>"},{"location":"request_response_types/best_practices/#testing-migration","title":"Testing Migration","text":"<p>Test thoroughly when migrating:</p> <pre><code># Test that serialization works\ndef test_migration():\n    command = MyCommand(id=\"123\")\n    data = command.to_dict()\n    restored = MyCommand.from_dict(**data)\n    assert restored.id == \"123\"\n</code></pre>"},{"location":"request_response_types/best_practices/#common-patterns","title":"Common Patterns","text":""},{"location":"request_response_types/best_practices/#pattern-1-validate-input-optimize-output","title":"Pattern 1: Validate Input, Optimize Output","text":"<pre><code># Validate external input\nclass CreateOrderCommand(cqrs.PydanticRequest):\n    user_id: str\n    items: list[str]\n\n# Lightweight response\n@dataclasses.dataclass\nclass OrderResponse(cqrs.DCResponse):\n    order_id: str\n</code></pre>"},{"location":"request_response_types/best_practices/#pattern-2-performance-critical","title":"Pattern 2: Performance-Critical","text":"<pre><code># High-performance request\nclass ProcessRequest(cqrs.IRequest, msgspec.Struct):\n    data: str\n\n# Simple response\n@dataclasses.dataclass\nclass ProcessResponse(cqrs.DCResponse):\n    result: str\n</code></pre>"},{"location":"request_response_types/best_practices/#pattern-3-full-control","title":"Pattern 3: Full Control","text":"<pre><code># Custom validation and serialization\nclass CustomRequest(cqrs.IRequest):\n    def __init__(self, data: str):\n        if not data:\n            raise ValueError(\"Data cannot be empty\")\n        self.data = data\n\n    def to_dict(self) -&gt; dict:\n        return {\"data\": self.data}\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return cls(**kwargs)\n</code></pre>"},{"location":"request_response_types/best_practices/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"request_response_types/best_practices/#over-engineering","title":"\u274c Over-Engineering","text":"<p>Don't use complex types for simple use cases:</p> <pre><code># \u274c Over-engineered\nclass SimpleQuery(cqrs.IRequest, msgspec.Struct):\n    id: str\n\n# \u2705 Simple enough\n@dataclasses.dataclass\nclass SimpleQuery(cqrs.DCRequest):\n    id: str\n</code></pre>"},{"location":"request_response_types/best_practices/#inconsistent-types","title":"\u274c Inconsistent Types","text":"<p>Don't mix types without reason:</p> <pre><code># \u274c Inconsistent\nclass CreateCommand(cqrs.PydanticRequest):\n    pass\n\nclass UpdateCommand(cqrs.DCRequest):  # Why different?\n    pass\n</code></pre>"},{"location":"request_response_types/best_practices/#skipping-validation","title":"\u274c Skipping Validation","text":"<p>Don't skip validation for external input:</p> <pre><code># \u274c No validation for external input\n@dataclasses.dataclass\nclass CreateUserCommand(cqrs.DCRequest):\n    email: str  # No validation!\n\n# \u2705 Validate external input\nclass CreateUserCommand(cqrs.PydanticRequest):\n    email: str = pydantic.Field(pattern=r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n</code></pre>"},{"location":"request_response_types/best_practices/#documentation","title":"Documentation","text":""},{"location":"request_response_types/best_practices/#document-your-choices","title":"Document Your Choices","text":"<p>Document why you chose a specific type:</p> <pre><code># Use Pydantic for external API requests to ensure validation\nclass CreateUserCommand(cqrs.PydanticRequest):\n    \"\"\"Uses Pydantic for runtime validation of external input.\"\"\"\n    email: str\n</code></pre>"},{"location":"request_response_types/best_practices/#team-guidelines","title":"Team Guidelines","text":"<p>Create team guidelines for type selection:</p> <pre><code>## Type Selection Guidelines\n\n- External APIs: Use Pydantic\n- Internal communication: Use Dataclasses\n- High-performance: Use Msgspec\n- Custom logic: Use Standard Classes\n</code></pre>"},{"location":"request_response_types/best_practices/#see-also","title":"See Also","text":"<ul> <li>Comparison Table - Detailed comparison</li> <li>Mixed Usage - Combining different types</li> <li>Request Handlers - Handler implementation</li> </ul>"},{"location":"request_response_types/dataclasses/","title":"Dataclasses Request/Response","text":"<p>Lightweight implementation - Uses Python's standard library <code>dataclasses</code>.</p>"},{"location":"request_response_types/dataclasses/#best-for","title":"Best For","text":"<ul> <li>When you want to avoid Pydantic dependency</li> <li>Internal system communication</li> <li>Performance-critical paths</li> <li>Simple data structures</li> </ul>"},{"location":"request_response_types/dataclasses/#features","title":"Features","text":"<ul> <li>No external dependencies (beyond standard library)</li> <li>Fast and lightweight</li> <li>Simple and straightforward</li> <li>No runtime validation (by default)</li> </ul>"},{"location":"request_response_types/dataclasses/#usage","title":"Usage","text":"<pre><code>import dataclasses\nimport cqrs\n\n@dataclasses.dataclass\nclass CreateProductCommand(cqrs.DCRequest):\n    \"\"\"Dataclass-based command.\"\"\"\n    name: str\n    price: float\n    category: str\n\n@dataclasses.dataclass\nclass ProductResponse(cqrs.DCResponse):\n    \"\"\"Dataclass-based response.\"\"\"\n    product_id: str\n    name: str\n    price: float\n    category: str\n\nclass CreateProductHandler(\n    cqrs.RequestHandler[CreateProductCommand, ProductResponse]\n):\n    @property\n    def events(self) -&gt; list[cqrs.IEvent]:\n        return []\n\n    async def handle(\n        self, request: CreateProductCommand\n    ) -&gt; ProductResponse:\n        product_id = f\"product_{request.name}\"\n        return ProductResponse(\n            product_id=product_id,\n            name=request.name,\n            price=request.price,\n            category=request.category\n        )\n</code></pre>"},{"location":"request_response_types/dataclasses/#frozen-dataclasses","title":"Frozen Dataclasses","text":"<p>You can use frozen dataclasses for immutability:</p> <pre><code>@dataclasses.dataclass(frozen=True)\nclass ImmutableRequest(cqrs.DCRequest):\n    user_id: str\n    action: str\n\n# This will raise FrozenInstanceError\nrequest = ImmutableRequest(user_id=\"123\", action=\"test\")\n# request.user_id = \"456  # \u274c Error: cannot assign to field\n</code></pre>"},{"location":"request_response_types/dataclasses/#default-values","title":"Default Values","text":"<p>Dataclasses support default values and factory functions:</p> <pre><code>@dataclasses.dataclass\nclass CreateOrderCommand(cqrs.DCRequest):\n    user_id: str\n    product_id: str\n    quantity: int = 1\n    tags: list[str] = dataclasses.field(default_factory=list)\n</code></pre>"},{"location":"request_response_types/dataclasses/#serialization","title":"Serialization","text":"<pre><code>command = CreateProductCommand(\n    name=\"Laptop\",\n    price=999.99,\n    category=\"Electronics\"\n)\n\n# Convert to dictionary\ndata = command.to_dict()\n# {\"name\": \"Laptop\", \"price\": 999.99, \"category\": \"Electronics\"}\n\n# Restore from dictionary\nrestored = CreateProductCommand.from_dict(**data)\n</code></pre>"},{"location":"request_response_types/dataclasses/#see-also","title":"See Also","text":"<ul> <li>Request Handlers - Learn about handler implementation</li> <li>Mixed Usage - Combining Dataclasses with other types</li> </ul>"},{"location":"request_response_types/mixed_usage/","title":"Mixed Usage","text":"<p>You can mix different types for requests and responses based on your needs. This flexibility allows you to choose the best type for each use case.</p>"},{"location":"request_response_types/mixed_usage/#examples","title":"Examples","text":""},{"location":"request_response_types/mixed_usage/#pydantic-request-with-dataclass-response","title":"Pydantic Request with Dataclass Response","text":"<p>Use Pydantic for request validation, but lightweight dataclass for response:</p> <pre><code>import dataclasses\nimport cqrs\nimport pydantic\n\n# Pydantic request with validation\nclass CreateOrderCommand(cqrs.PydanticRequest):\n    user_id: str\n    product_id: str\n    quantity: int = pydantic.Field(gt=0)\n\n# Dataclass response - lightweight\n@dataclasses.dataclass\nclass OrderResponse(cqrs.DCResponse):\n    order_id: str\n    total_price: float\n\nclass CreateOrderHandler(\n    cqrs.RequestHandler[CreateOrderCommand, OrderResponse]\n):\n    @property\n    def events(self) -&gt; list[cqrs.IEvent]:\n        return []\n\n    async def handle(self, request: CreateOrderCommand) -&gt; OrderResponse:\n        # Request is validated by Pydantic\n        total_price = 99.99 * request.quantity\n        return OrderResponse(\n            order_id=f\"order_{request.user_id}\",\n            total_price=total_price\n        )\n</code></pre>"},{"location":"request_response_types/mixed_usage/#dataclass-request-with-pydantic-response","title":"Dataclass Request with Pydantic Response","text":"<p>Use lightweight dataclass for request, but Pydantic for response validation:</p> <pre><code>@dataclasses.dataclass\nclass GetUserQuery(cqrs.DCRequest):\n    \"\"\"Dataclass query - simple and lightweight.\"\"\"\n    user_id: str\n\nclass UserDetailsResponse(cqrs.PydanticResponse):\n    \"\"\"Pydantic response with validation.\"\"\"\n    user_id: str\n    username: str\n    email: str\n    total_orders: int = 0\n\nclass GetUserQueryHandler(\n    cqrs.RequestHandler[GetUserQuery, UserDetailsResponse]\n):\n    @property\n    def events(self) -&gt; list[cqrs.IEvent]:\n        return []\n\n    async def handle(self, request: GetUserQuery) -&gt; UserDetailsResponse:\n        # Response is validated by Pydantic\n        return UserDetailsResponse(\n            user_id=request.user_id,\n            username=\"john\",\n            email=\"john@example.com\",\n            total_orders=5\n        )\n</code></pre>"},{"location":"request_response_types/mixed_usage/#msgspec-request-with-dataclass-response","title":"Msgspec Request with Dataclass Response","text":"<p>High-performance request with lightweight response:</p> <pre><code>import msgspec\n\nclass ProcessDataRequest(cqrs.IRequest, msgspec.Struct):\n    data: str\n    options: dict\n\n    def to_dict(self) -&gt; dict:\n        return msgspec.to_builtins(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return msgspec.from_builtins(cls, kwargs)\n\n@dataclasses.dataclass\nclass ProcessDataResponse(cqrs.DCResponse):\n    result: str\n    processed_at: str\n</code></pre>"},{"location":"request_response_types/mixed_usage/#best-practices-for-mixed-usage","title":"Best Practices for Mixed Usage","text":"<ol> <li>Validate Input, Optimize Output</li> <li>Use Pydantic/Msgspec for requests (external input)</li> <li> <p>Use Dataclasses for responses (internal data)</p> </li> <li> <p>Performance-Critical Paths</p> </li> <li>Use Msgspec for high-throughput requests</li> <li> <p>Use Dataclasses for simple responses</p> </li> <li> <p>Consistency Within Domains</p> </li> <li>Keep the same type for related requests/responses</li> <li> <p>Document your choices in team guidelines</p> </li> <li> <p>Migration Strategy</p> </li> <li>Start with one type, migrate gradually</li> <li>All types implement the same interface</li> </ol>"},{"location":"request_response_types/mixed_usage/#see-also","title":"See Also","text":"<ul> <li>Best Practices - Recommendations for choosing types</li> <li>Request Handlers - Learn about handler implementation</li> </ul>"},{"location":"request_response_types/msgspec/","title":"Msgspec Request/Response","text":"<p>High-performance - Uses <code>msgspec</code> for blazing-fast serialization (up to 10x faster than Pydantic).</p>"},{"location":"request_response_types/msgspec/#best-for","title":"Best For","text":"<ul> <li>High-performance microservices</li> <li>When speed is critical (up to 10x faster than Pydantic)</li> <li>JSON and MsgPack serialization</li> <li>WebSocket applications</li> </ul> <p>Installation</p> <pre><code>pip install msgspec\n</code></pre> <p>Performance</p> <p>Msgspec is written in Rust and provides significantly better performance than Pydantic for serialization/deserialization.</p>"},{"location":"request_response_types/msgspec/#usage","title":"Usage","text":"<pre><code>import cqrs\nimport msgspec\nfrom typing import Self\n\nclass MsgspecRequest(cqrs.IRequest, msgspec.Struct):\n    \"\"\"Request using msgspec.Struct.\"\"\"\n    user_id: str\n    action: str\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return msgspec.to_builtins(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return msgspec.from_builtins(cls, kwargs)\n\nclass MsgspecResponse(cqrs.IResponse, msgspec.Struct):\n    \"\"\"Response using msgspec.Struct.\"\"\"\n    result: str\n    status: str\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return msgspec.to_builtins(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return msgspec.from_builtins(cls, kwargs)\n\nclass MsgspecHandler(cqrs.RequestHandler[MsgspecRequest, MsgspecResponse]):\n    @property\n    def events(self) -&gt; list[cqrs.IEvent]:\n        return []\n\n    async def handle(self, request: MsgspecRequest) -&gt; MsgspecResponse:\n        return MsgspecResponse(\n            result=f\"Processed {request.action}\",\n            status=\"success\"\n        )\n</code></pre>"},{"location":"request_response_types/msgspec/#validation","title":"Validation","text":"<p>Msgspec provides runtime validation:</p> <pre><code>import msgspec\n\nclass ValidatedRequest(cqrs.IRequest, msgspec.Struct):\n    email: str = msgspec.field()\n    age: int = msgspec.field(ge=0, le=120)\n\n    def to_dict(self) -&gt; dict:\n        return msgspec.to_builtins(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return msgspec.from_builtins(cls, kwargs)\n</code></pre>"},{"location":"request_response_types/msgspec/#frozen-structs","title":"Frozen Structs","text":"<p>You can create immutable structs:</p> <pre><code>class ImmutableRequest(cqrs.IRequest, msgspec.Struct, frozen=True):\n    user_id: str\n    action: str\n\n    def to_dict(self) -&gt; dict:\n        return msgspec.to_builtins(self)\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return msgspec.from_builtins(cls, kwargs)\n</code></pre>"},{"location":"request_response_types/msgspec/#performance-comparison","title":"Performance Comparison","text":"<p>Msgspec is significantly faster than Pydantic for serialization:</p> Operation Pydantic Msgspec Speedup Serialization 1x ~5-10x 5-10x faster Deserialization 1x ~5-10x 5-10x faster"},{"location":"request_response_types/msgspec/#see-also","title":"See Also","text":"<ul> <li>Pydantic - Alternative with more features</li> <li>Request Handlers - Learn about handler implementation</li> </ul>"},{"location":"request_response_types/namedtuple/","title":"NamedTuple Request/Response","text":"<p>Immutable and memory-efficient - Uses Python's <code>NamedTuple</code> for lightweight data structures.</p>"},{"location":"request_response_types/namedtuple/#best-for","title":"Best For","text":"<ul> <li>Immutable data structures</li> <li>Memory efficiency</li> <li>Simple, fixed configurations</li> <li>When immutability is required</li> </ul> <p>Limitations</p> <p>NamedTuple is immutable and has limited flexibility. Consider using dataclasses with <code>frozen=True</code> for similar benefits with more features. NamedTuple cannot directly inherit from <code>IRequest</code>/<code>IResponse</code>, so a wrapper class is needed.</p>"},{"location":"request_response_types/namedtuple/#usage","title":"Usage","text":"<p>Since <code>NamedTuple</code> cannot directly inherit from <code>IRequest</code>/<code>IResponse</code>, we use a wrapper class:</p> <pre><code>import cqrs\nfrom typing import NamedTuple, Self\n\n# Define the NamedTuple structure\n_NamedTupleRequestBase = NamedTuple(\n    \"NamedTupleRequestBase\",\n    [(\"user_id\", str), (\"action\", str)]\n)\n\nclass NamedTupleRequest(cqrs.IRequest):\n    \"\"\"Request using NamedTuple as internal storage.\"\"\"\n\n    def __init__(self, user_id: str, action: str):\n        self._data = _NamedTupleRequestBase(user_id=user_id, action=action)\n\n    @property\n    def user_id(self) -&gt; str:\n        return self._data.user_id\n\n    @property\n    def action(self) -&gt; str:\n        return self._data.action\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return {\n            \"user_id\": self._data.user_id,\n            \"action\": self._data.action\n        }\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(\n            user_id=kwargs[\"user_id\"],\n            action=kwargs[\"action\"]\n        )\n\n# Define the NamedTuple structure for response\n_NamedTupleResponseBase = NamedTuple(\n    \"NamedTupleResponseBase\",\n    [(\"result\", str), (\"status\", str)]\n)\n\nclass NamedTupleResponse(cqrs.IResponse):\n    \"\"\"Response using NamedTuple as internal storage.\"\"\"\n\n    def __init__(self, result: str, status: str):\n        self._data = _NamedTupleResponseBase(result=result, status=status)\n\n    @property\n    def result(self) -&gt; str:\n        return self._data.result\n\n    @property\n    def status(self) -&gt; str:\n        return self._data.status\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return {\n            \"result\": self._data.result,\n            \"status\": self._data.status\n        }\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(\n            result=kwargs[\"result\"],\n            status=kwargs[\"status\"]\n        )\n</code></pre>"},{"location":"request_response_types/namedtuple/#alternative-using-class-based-namedtuple","title":"Alternative: Using Class-Based NamedTuple","text":"<p>You can also use the class-based syntax:</p> <pre><code>from typing import NamedTuple, Self\n\nclass NamedTupleRequestData(NamedTuple):\n    user_id: str\n    action: str\n\nclass NamedTupleRequest(cqrs.IRequest):\n    def __init__(self, user_id: str, action: str):\n        self._data = NamedTupleRequestData(user_id=user_id, action=action)\n\n    @property\n    def user_id(self) -&gt; str:\n        return self._data.user_id\n\n    @property\n    def action(self) -&gt; str:\n        return self._data.action\n\n    def to_dict(self) -&gt; dict:\n        return self._data._asdict()\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return cls(**kwargs)\n</code></pre>"},{"location":"request_response_types/namedtuple/#when-to-use","title":"When to Use","text":"<p>Consider using NamedTuple when:</p> <ul> <li>You need immutability guarantees</li> <li>Memory usage is critical</li> <li>You have simple, fixed data structures</li> <li>You want tuple-like behavior with named fields</li> </ul>"},{"location":"request_response_types/namedtuple/#see-also","title":"See Also","text":"<ul> <li>Dataclasses - Similar features with more flexibility</li> <li>Request Handlers - Learn about handler implementation</li> </ul>"},{"location":"request_response_types/pydantic/","title":"Pydantic Request/Response","text":"<p>Default implementation - Uses Pydantic v2 for validation and serialization.</p>"},{"location":"request_response_types/pydantic/#best-for","title":"Best For","text":"<ul> <li>Web APIs (especially with FastAPI)</li> <li>When you need runtime validation</li> <li>Complex data transformations</li> <li>JSON Schema generation</li> </ul>"},{"location":"request_response_types/pydantic/#features","title":"Features","text":"<ul> <li>Automatic validation</li> <li>Type coercion</li> <li>Excellent developer experience</li> <li>JSON Schema support</li> </ul>"},{"location":"request_response_types/pydantic/#usage","title":"Usage","text":"<pre><code>import cqrs\nimport pydantic\n\nclass CreateUserCommand(cqrs.PydanticRequest):\n    \"\"\"Pydantic-based command with validation.\"\"\"\n    username: str\n    email: str = pydantic.Field(pattern=r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n    age: int = pydantic.Field(gt=0, le=120)\n\nclass UserResponse(cqrs.PydanticResponse):\n    \"\"\"Pydantic-based response.\"\"\"\n    user_id: str\n    username: str\n    email: str\n    age: int\n\nclass CreateUserHandler(cqrs.RequestHandler[CreateUserCommand, UserResponse]):\n    @property\n    def events(self) -&gt; list[cqrs.IEvent]:\n        return []\n\n    async def handle(self, request: CreateUserCommand) -&gt; UserResponse:\n        # Validation happens automatically\n        user_id = f\"user_{request.username}\"\n        return UserResponse(\n            user_id=user_id,\n            username=request.username,\n            email=request.email,\n            age=request.age\n        )\n</code></pre>"},{"location":"request_response_types/pydantic/#aliases","title":"Aliases","text":"<p>For convenience, <code>PydanticRequest</code> and <code>PydanticResponse</code> are aliased as <code>Request</code> and <code>Response</code>:</p> <pre><code>import cqrs\n\n# These are equivalent:\nclass MyCommand(cqrs.Request):  # Same as cqrs.PydanticRequest\n    pass\n\nclass MyResponse(cqrs.Response):  # Same as cqrs.PydanticResponse\n    pass\n</code></pre>"},{"location":"request_response_types/pydantic/#validation","title":"Validation","text":"<p>Pydantic provides automatic validation based on type hints and field validators:</p> <pre><code>import cqrs\nimport pydantic\n\nclass CreateProductCommand(cqrs.PydanticRequest):\n    name: str = pydantic.Field(min_length=1, max_length=100)\n    price: float = pydantic.Field(gt=0)\n    category: str = pydantic.Field(pattern=r'^[A-Z][a-z]+$')\n\n# This will raise ValidationError\ntry:\n    command = CreateProductCommand(\n        name=\"\",  # Too short\n        price=-10,  # Negative\n        category=\"invalid\"  # Doesn't match pattern\n    )\nexcept pydantic.ValidationError as e:\n    print(e)\n</code></pre>"},{"location":"request_response_types/pydantic/#serialization","title":"Serialization","text":"<p>Pydantic provides built-in serialization methods:</p> <pre><code>command = CreateUserCommand(\n    username=\"john\",\n    email=\"john@example.com\",\n    age=30\n)\n\n# Convert to dictionary\ndata = command.to_dict()\n# {\"username\": \"john\", \"email\": \"john@example.com\", \"age\": 30}\n\n# Restore from dictionary\nrestored = CreateUserCommand.from_dict(**data)\n</code></pre>"},{"location":"request_response_types/pydantic/#see-also","title":"See Also","text":"<ul> <li>Request Handlers - Learn about handler implementation</li> <li>Mixed Usage - Combining Pydantic with other types</li> </ul>"},{"location":"request_response_types/standard_classes/","title":"Standard Python Classes","text":"<p>Full control - Implement <code>IRequest</code>/<code>IResponse</code> directly with standard Python classes.</p>"},{"location":"request_response_types/standard_classes/#best-for","title":"Best For","text":"<ul> <li>Full control over serialization</li> <li>Custom validation logic</li> <li>Integration with existing codebases</li> <li>Minimal dependencies</li> </ul>"},{"location":"request_response_types/standard_classes/#usage","title":"Usage","text":"<pre><code>import cqrs\nfrom typing import Self\n\nclass CustomRequest(cqrs.IRequest):\n    \"\"\"Custom request using standard Python class.\"\"\"\n\n    def __init__(self, user_id: str, action: str):\n        self.user_id = user_id\n        self.action = action\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return {\n            \"user_id\": self.user_id,\n            \"action\": self.action\n        }\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(\n            user_id=kwargs[\"user_id\"],\n            action=kwargs[\"action\"]\n        )\n\nclass CustomResponse(cqrs.IResponse):\n    \"\"\"Custom response using standard Python class.\"\"\"\n\n    def __init__(self, result: str, status: str):\n        self.result = result\n        self.status = status\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return {\n            \"result\": self.result,\n            \"status\": self.status\n        }\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(\n            result=kwargs[\"result\"],\n            status=kwargs[\"status\"]\n        )\n\nclass CustomHandler(cqrs.RequestHandler[CustomRequest, CustomResponse]):\n    @property\n    def events(self) -&gt; list[cqrs.IEvent]:\n        return []\n\n    async def handle(self, request: CustomRequest) -&gt; CustomResponse:\n        return CustomResponse(\n            result=f\"Processed {request.action} for {request.user_id}\",\n            status=\"success\"\n        )\n</code></pre>"},{"location":"request_response_types/standard_classes/#custom-validation","title":"Custom Validation","text":"<p>You can add custom validation logic in <code>from_dict</code>:</p> <pre><code>class ValidatedRequest(cqrs.IRequest):\n    def __init__(self, user_id: str, age: int):\n        if age &lt; 0 or age &gt; 150:\n            raise ValueError(\"Age must be between 0 and 150\")\n        self.user_id = user_id\n        self.age = age\n\n    def to_dict(self) -&gt; dict:\n        return {\n            \"user_id\": self.user_id,\n            \"age\": self.age\n        }\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return cls(**kwargs)\n</code></pre>"},{"location":"request_response_types/standard_classes/#complex-serialization","title":"Complex Serialization","text":"<p>You can implement complex serialization logic:</p> <pre><code>import json\nfrom datetime import datetime\nfrom typing import Self\n\nclass TimestampedRequest(cqrs.IRequest):\n    def __init__(self, data: str, timestamp: datetime | None = None):\n        self.data = data\n        self.timestamp = timestamp or datetime.now()\n\n    def to_dict(self) -&gt; dict:\n        return {\n            \"data\": self.data,\n            \"timestamp\": self.timestamp.isoformat()\n        }\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        timestamp = kwargs.get(\"timestamp\")\n        if isinstance(timestamp, str):\n            timestamp = datetime.fromisoformat(timestamp)\n        return cls(\n            data=kwargs[\"data\"],\n            timestamp=timestamp\n        )\n</code></pre>"},{"location":"request_response_types/standard_classes/#see-also","title":"See Also","text":"<ul> <li>Request Handlers - Learn about handler implementation</li> <li>Best Practices - Recommendations for custom implementations</li> </ul>"},{"location":"request_response_types/typeddict/","title":"TypedDict Request/Response","text":"<p>Type hints only - Uses <code>TypedDict</code> for static type checking with zero runtime overhead.</p>"},{"location":"request_response_types/typeddict/#best-for","title":"Best For","text":"<ul> <li>Type hints for dictionaries</li> <li>Static type checking (mypy)</li> <li>When you need zero runtime overhead</li> <li>Integration with existing dict-based code</li> </ul> <p>No Runtime Validation</p> <p>TypedDict is only for static type checking. It doesn't provide runtime validation or instance creation. You'll need to implement <code>to_dict()</code> and <code>from_dict()</code> manually. TypedDict cannot directly implement <code>IRequest</code>/<code>IResponse</code>, so a wrapper class is required.</p>"},{"location":"request_response_types/typeddict/#usage","title":"Usage","text":"<p>Since <code>TypedDict</code> cannot directly implement <code>IRequest</code>/<code>IResponse</code>, we use a wrapper class:</p> <pre><code>import cqrs\nfrom typing import TypedDict, Self\n\n# Define TypedDict for type hints\nclass TypedDictRequestDict(TypedDict):\n    \"\"\"Type definition for request dictionary.\"\"\"\n    user_id: str\n    action: str\n\nclass TypedDictRequest(cqrs.IRequest):\n    \"\"\"Request using TypedDict for type hints.\"\"\"\n\n    def __init__(self, user_id: str, action: str):\n        self.user_id = user_id\n        self.action = action\n\n    def to_dict(self) -&gt; TypedDictRequestDict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return {\n            \"user_id\": self.user_id,\n            \"action\": self.action\n        }\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(\n            user_id=kwargs[\"user_id\"],\n            action=kwargs[\"action\"]\n        )\n\nclass TypedDictResponseDict(TypedDict):\n    \"\"\"Type definition for response dictionary.\"\"\"\n    result: str\n    status: str\n\nclass TypedDictResponse(cqrs.IResponse):\n    \"\"\"Response using TypedDict for type hints.\"\"\"\n\n    def __init__(self, result: str, status: str):\n        self.result = result\n        self.status = status\n\n    def to_dict(self) -&gt; TypedDictResponseDict:\n        \"\"\"Convert to dictionary.\"\"\"\n        return {\n            \"result\": self.result,\n            \"status\": self.status\n        }\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(\n            result=kwargs[\"result\"],\n            status=kwargs[\"status\"]\n        )\n</code></pre>"},{"location":"request_response_types/typeddict/#optional-fields","title":"Optional Fields","text":"<p>You can use <code>NotRequired</code> for optional fields:</p> <pre><code>from typing import TypedDict, NotRequired\n\nclass OptionalFieldsDict(TypedDict):\n    user_id: str\n    action: str\n    metadata: NotRequired[dict]\n\nclass OptionalFieldsRequest(cqrs.IRequest):\n    def __init__(self, user_id: str, action: str, metadata: dict | None = None):\n        self.user_id = user_id\n        self.action = action\n        self.metadata = metadata or {}\n\n    def to_dict(self) -&gt; OptionalFieldsDict:\n        result: OptionalFieldsDict = {\n            \"user_id\": self.user_id,\n            \"action\": self.action\n        }\n        if self.metadata:\n            result[\"metadata\"] = self.metadata\n        return result\n\n    @classmethod\n    def from_dict(cls, **kwargs) -&gt; Self:\n        return cls(\n            user_id=kwargs[\"user_id\"],\n            action=kwargs[\"action\"],\n            metadata=kwargs.get(\"metadata\")\n        )\n</code></pre>"},{"location":"request_response_types/typeddict/#total-vs-non-total","title":"Total vs Non-Total","text":"<p>You can control whether all fields are required:</p> <pre><code># Total=True (default) - all fields required\nclass TotalDict(TypedDict, total=True):\n    user_id: str\n    action: str\n\n# Total=False - all fields optional\nclass NonTotalDict(TypedDict, total=False):\n    user_id: str\n    action: str\n</code></pre>"},{"location":"request_response_types/typeddict/#when-to-use","title":"When to Use","text":"<p>Consider using TypedDict when:</p> <ul> <li>You need static type checking only</li> <li>Runtime overhead must be zero</li> <li>You're working with existing dict-based code</li> <li>You want type hints without runtime validation</li> </ul>"},{"location":"request_response_types/typeddict/#see-also","title":"See Also","text":"<ul> <li>Standard Classes - Similar approach with more flexibility</li> <li>Request Handlers - Learn about handler implementation</li> </ul>"},{"location":"saga/","title":"Saga Pattern","text":"<p>The Saga pattern enables distributed transactions across multiple services by executing a series of steps where each step can be compensated if a subsequent step fails. This allows for eventual consistency across distributed systems without requiring two-phase commit.</p>"},{"location":"saga/#overview","title":"Overview","text":"<ul> <li> <p> Flow Diagrams</p> <p>Visual representation of execution and compensation flows.</p> <p> Read More</p> </li> <li> <p> Storage</p> <p>Memory and SQLAlchemy storage implementations for saga state persistence.</p> <p> Read More</p> </li> <li> <p> Recovery</p> <p>How recovery ensures eventual consistency for interrupted sagas.</p> <p> Read More</p> </li> <li> <p> Compensation</p> <p>Compensation mechanism and best practices for rollback operations.</p> <p> Read More</p> </li> <li> <p> Fallback Pattern</p> <p>Fallback steps with Circuit Breaker protection for resilient sagas.</p> <p> Read More</p> </li> <li> <p> Examples</p> <p>Complete examples including FastAPI SSE integration.</p> <p> Read More</p> </li> </ul> <p>The <code>python-cqrs</code> package implements the Orchestrated Saga pattern. <code>SagaTransaction</code> manages step execution sequentially and handles automatic compensation on failure.</p> <p>Orchestrated Saga</p> <p><code>SagaTransaction</code> coordinates step execution, but each step handler is responsible for its own logic. The transaction manages flow, state persistence, and automatic compensation.</p>"},{"location":"saga/#key-concepts","title":"Key Concepts","text":"Concept Description SagaTransaction Context manager that executes steps sequentially and handles compensation Saga Class that defines steps and creates <code>SagaTransaction</code> instances Step Handler Operation with <code>act()</code> and <code>compensate()</code> methods Context Shared state object passed between all steps Storage Persists saga state and execution history for recovery Compensation Automatic rollback of completed steps in reverse order on failure Recovery Mechanism to resume interrupted sagas from persistent storage <p>Prerequisites</p> <p>Understanding of Request Handlers and Dependency Injection is recommended.</p> <p>When to Use</p> <p>Use Saga pattern when coordinating multiple operations across different services, where each operation can be compensated if the overall transaction fails.</p>"},{"location":"saga/#how-it-works","title":"How It Works","text":"<p><code>SagaTransaction</code> executes steps sequentially and automatically compensates completed steps in reverse order if any step fails:</p> <pre><code>graph TD\n    A[Create SagaTransaction] --&gt; B[Execute Step 1]\n    B --&gt;|Success| C[Execute Step 2]\n    C --&gt;|Success| D[Execute Step 3]\n    D --&gt;|Success| E[Saga Completed]\n\n    B --&gt;|Failure| F[Compensate Step 1]\n    C --&gt;|Failure| G[Compensate Step 2]\n    G --&gt; F\n    D --&gt;|Failure| H[Compensate Step 3]\n    H --&gt; G\n\n    F --&gt; I[Saga Failed]\n    G --&gt; I\n    H --&gt; I\n\n    style E fill:#c8e6c9\n    style I fill:#ffcdd2</code></pre>"},{"location":"saga/#basic-example","title":"Basic Example","text":"<pre><code>import dataclasses\nimport uuid\nimport di\n\nimport cqrs\nfrom cqrs.saga import bootstrap\nfrom cqrs.saga.saga import Saga\nfrom cqrs.saga.step import SagaStepHandler, SagaStepResult\nfrom cqrs.saga.storage.memory import MemorySagaStorage\nfrom cqrs.saga.models import SagaContext\nfrom cqrs.response import Response\n\n# Context\n@dataclasses.dataclass\nclass OrderContext(SagaContext):\n    order_id: str\n    items: list[str]\n    total_amount: float\n    inventory_reservation_id: str | None = None\n    payment_id: str | None = None\n\n# Step handler\nclass ReserveInventoryStep(SagaStepHandler[OrderContext, Response]):\n    def __init__(self, inventory_service):\n        self._inventory_service = inventory_service\n\n    async def act(self, context: OrderContext) -&gt; SagaStepResult:\n        reservation_id = await self._inventory_service.reserve_items(\n            context.order_id, context.items\n        )\n        context.inventory_reservation_id = reservation_id\n        return self._generate_step_result(Response())\n\n    async def compensate(self, context: OrderContext) -&gt; None:\n        if context.inventory_reservation_id:\n            await self._inventory_service.release_items(\n                context.inventory_reservation_id\n            )\n\n# Define saga class with steps\nclass OrderSaga(Saga[OrderContext]):\n    steps = [ReserveInventoryStep]\n\n# Setup DI container\ndi_container = di.Container()\n# ... register your services ...\n\n# Create saga storage\nstorage = MemorySagaStorage()\n\n# Register saga in SagaMap\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\n# Create saga mediator using bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n\n# Execute saga\ncontext = OrderContext(order_id=\"123\", items=[\"item_1\"], total_amount=100.0)\nsaga_id = uuid.uuid4()\n\nasync for step_result in mediator.stream(context, saga_id=saga_id):\n    print(f\"Step completed: {step_result.step_type.__name__}\")\n</code></pre> <p>Stream API</p> <p><code>mediator.stream(context, saga_id=...)</code> is called without <code>await</code> and returns an <code>AsyncIterator[SagaStepResult]</code>. Consume it with <code>async for</code> as shown above.</p>"},{"location":"saga/#key-features","title":"Key Features","text":"<ul> <li>Automatic Compensation \u2014 Failed steps trigger compensation of completed steps in reverse order</li> <li>State Persistence \u2014 Saga state and execution history saved (when storage supports checkpoint commits, persistence happens at key points: after create+RUNNING, after each step, after each compensation step, at completion/failure)</li> <li>Checkpoint Commits \u2014 Storages that implement <code>create_run()</code> (Memory, SQLAlchemy) use one session per saga run and commit only at checkpoints, reducing commits and deadlock risk</li> <li>Recovery \u2014 Interrupted sagas can be resumed from persistent storage; Strict Backward Recovery ensures that once in COMPENSATING/FAILED, only compensation proceeds</li> <li>Fallback Pattern \u2014 Define alternative steps that execute when primary steps fail, with optional Circuit Breaker protection</li> <li>Eventual Consistency \u2014 All sagas eventually reach terminal state (COMPLETED or FAILED)</li> </ul>"},{"location":"saga/compensation/","title":"Compensation Strategy","text":"<ul> <li> <p> Back to Saga Overview</p> <p>Return to the Saga Pattern overview page with all topics.</p> <p> Back to Overview</p> </li> </ul> <p>Compensation undoes the effects of completed steps when a saga fails, ensuring resources are properly released and the system returns to a consistent state.</p> <p>When the storage supports <code>create_run()</code>, the saga runs compensation within a single storage run and persists each successfully compensated step at a checkpoint (by committing the run after each step). This keeps the number of commits low and aligns with the checkpoint model used for forward execution.</p>"},{"location":"saga/compensation/#overview","title":"Overview","text":"<p>When any step fails, all previously completed steps are automatically compensated in reverse order:</p> <ul> <li>Resources are properly released</li> <li>Partial operations are rolled back</li> <li>System returns to a consistent state</li> </ul>"},{"location":"saga/compensation/#how-compensation-works","title":"How Compensation Works","text":"<p>Compensation is triggered automatically when a step's <code>act()</code> method raises an exception:</p> <pre><code>sequenceDiagram\n    participant Transaction as SagaTransaction\n    participant Step1 as Step 1\n    participant Step2 as Step 2\n    participant Step3 as Step 3\n\n    Transaction-&gt;&gt;Step1: act(context)\n    Step1--&gt;&gt;Transaction: Success \u2713\n    Transaction-&gt;&gt;Step2: act(context)\n    Step2--&gt;&gt;Transaction: Success \u2713\n    Transaction-&gt;&gt;Step3: act(context)\n    Step3--&gt;&gt;Transaction: Exception \u2717\n\n    Note over Transaction: Compensation triggered\n\n    Transaction-&gt;&gt;Step2: compensate(context)\n    Transaction-&gt;&gt;Step1: compensate(context)\n    Transaction--&gt;&gt;Transaction: Mark saga as FAILED</code></pre> <p>Compensation happens in reverse order: <pre><code>Execution:    Step 1 \u2192 Step 2 \u2192 Step 3\nCompensation: Step 3 \u2190 Step 2 \u2190 Step 1\n</code></pre></p>"},{"location":"saga/compensation/#implementing-compensation","title":"Implementing Compensation","text":"<p>Each step handler must implement the <code>compensate()</code> method:</p> <pre><code>class ReserveInventoryStep(SagaStepHandler[OrderContext, Response]):\n    async def act(self, context: OrderContext) -&gt; SagaStepResult:\n        reservation_id = await self._inventory_service.reserve_items(\n            context.order_id, context.items\n        )\n        context.inventory_reservation_id = reservation_id\n        return self._generate_step_result(Response())\n\n    async def compensate(self, context: OrderContext) -&gt; None:\n        if context.inventory_reservation_id:\n            await self._inventory_service.release_items(\n                context.inventory_reservation_id\n            )\n</code></pre>"},{"location":"saga/compensation/#best-practices","title":"Best Practices","text":"<ol> <li>Idempotent \u2014 Safe to call multiple times</li> <li>Check Context \u2014 Verify compensation is needed before executing</li> <li>Handle Errors \u2014 Gracefully handle missing resources</li> </ol>"},{"location":"saga/compensation/#idempotent-example","title":"Idempotent Example","text":"<pre><code>async def compensate(self, context: OrderContext) -&gt; None:\n    if not context.inventory_reservation_id:\n        return  # Already compensated\n\n    try:\n        await self._inventory_service.release_items(\n            context.inventory_reservation_id\n        )\n        context.inventory_reservation_id = None\n    except ValueError:\n        pass  # Already released - idempotent\n</code></pre>"},{"location":"saga/compensation/#compensation-retry","title":"Compensation Retry","text":"<p>Automatic retry for compensation failures is configured on <code>saga.transaction(...)</code>:</p> <pre><code>saga = OrderSaga()  # steps defined on class\n\nasync with saga.transaction(\n    context=context,\n    container=container,\n    storage=storage,\n    compensation_retry_count=3,      # Number of retry attempts\n    compensation_retry_delay=1.0,   # Initial delay in seconds\n    compensation_retry_backoff=2.0, # Exponential backoff multiplier\n) as transaction:\n    async for step_result in transaction:\n        ...\n</code></pre> <p>Retry schedule:</p> <ul> <li>Attempt 1: fails, wait 1.0s</li> <li>Attempt 2: fails, wait 2.0s (1.0 \u00d7 2.0)</li> <li>Attempt 3: fails, wait 4.0s (2.0 \u00d7 2.0)</li> <li>Attempt 4: final attempt</li> </ul>"},{"location":"saga/compensation/#compensation-patterns","title":"Compensation Patterns","text":""},{"location":"saga/compensation/#direct-reversal","title":"Direct Reversal","text":"<pre><code>async def act(self, context: OrderContext) -&gt; SagaStepResult:\n    resource_id = await service.create_resource(data)\n    context.resource_id = resource_id\n    return self._generate_step_result(Response())\n\nasync def compensate(self, context: OrderContext) -&gt; None:\n    if context.resource_id:\n        await service.delete_resource(context.resource_id)\n</code></pre>"},{"location":"saga/compensation/#compensating-transaction","title":"Compensating Transaction","text":"<pre><code>async def act(self, context: OrderContext) -&gt; SagaStepResult:\n    payment_id = await payment_service.charge(amount)\n    context.payment_id = payment_id\n    return self._generate_step_result(Response())\n\nasync def compensate(self, context: OrderContext) -&gt; None:\n    if context.payment_id:\n        await payment_service.refund(context.payment_id)\n</code></pre>"},{"location":"saga/compensation/#no-op-compensation","title":"No-Op Compensation","text":"<pre><code>async def act(self, context: OrderContext) -&gt; SagaStepResult:\n    await notification_service.send(context.user_id, message)\n    return self._generate_step_result(Response())\n\nasync def compensate(self, context: OrderContext) -&gt; None:\n    pass  # Notifications can't be \"unsent\"\n</code></pre>"},{"location":"saga/compensation/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"saga/compensation/#non-idempotent-compensation","title":"Non-Idempotent Compensation","text":"<pre><code># \u274c Bad: Not idempotent\nasync def compensate(self, context: OrderContext) -&gt; None:\n    await service.delete_resource(context.resource_id)\n\n# \u2705 Good: Idempotent\nasync def compensate(self, context: OrderContext) -&gt; None:\n    if context.resource_id:\n        try:\n            await service.delete_resource(context.resource_id)\n        except NotFoundError:\n            pass\n        context.resource_id = None\n</code></pre>"},{"location":"saga/compensation/#missing-context-check","title":"Missing Context Check","text":"<pre><code># \u274c Bad: May fail if resource doesn't exist\nasync def compensate(self, context: OrderContext) -&gt; None:\n    await service.release_items(context.inventory_reservation_id)\n\n# \u2705 Good: Checks before compensating\nasync def compensate(self, context: OrderContext) -&gt; None:\n    if context.inventory_reservation_id:\n        await service.release_items(context.inventory_reservation_id)\n</code></pre>"},{"location":"saga/compensation/#best-practices_1","title":"Best Practices","text":"<ol> <li>Idempotent \u2014 Safe to call multiple times</li> <li>Check Context \u2014 Verify compensation is needed</li> <li>Handle Failures \u2014 Log errors appropriately</li> <li>Test Logic \u2014 Ensure compensation works correctly</li> </ol>"},{"location":"saga/examples/","title":"Saga Examples","text":"<ul> <li> <p> Back to Saga Overview</p> <p>Return to the Saga Pattern overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"saga/examples/#basic-saga-example","title":"Basic Saga Example","text":"<pre><code>import dataclasses\nimport uuid\nimport di\n\nimport cqrs\nfrom cqrs.saga import bootstrap\nfrom cqrs.saga.saga import Saga\nfrom cqrs.saga.step import SagaStepHandler, SagaStepResult\nfrom cqrs.saga.storage.memory import MemorySagaStorage\nfrom cqrs.saga.models import SagaContext\nfrom cqrs.response import Response\n\n@dataclasses.dataclass\nclass OrderContext(SagaContext):\n    order_id: str\n    items: list[str]\n    total_amount: float\n    inventory_reservation_id: str | None = None\n    payment_id: str | None = None\n\nclass ReserveInventoryStep(SagaStepHandler[OrderContext, Response]):\n    def __init__(self, inventory_service):\n        self._inventory_service = inventory_service\n\n    async def act(self, context: OrderContext) -&gt; SagaStepResult:\n        reservation_id = await self._inventory_service.reserve_items(\n            context.order_id, context.items\n        )\n        context.inventory_reservation_id = reservation_id\n        return self._generate_step_result(Response())\n\n    async def compensate(self, context: OrderContext) -&gt; None:\n        if context.inventory_reservation_id:\n            await self._inventory_service.release_items(\n                context.inventory_reservation_id\n            )\n\n# Define saga class with steps\nclass OrderSaga(Saga[OrderContext]):\n    steps = [ReserveInventoryStep, ProcessPaymentStep]\n\n# Setup DI container\ndi_container = di.Container()\n# ... register services ...\n\n# Create saga storage\nstorage = MemorySagaStorage()\n\n# Register saga in SagaMap\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\n# Create saga mediator using bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n\n# Execute saga\ncontext = OrderContext(order_id=\"123\", items=[\"item_1\"], total_amount=100.0)\nsaga_id = uuid.uuid4()\n\nasync for step_result in mediator.stream(context, saga_id=saga_id):\n    print(f\"Step completed: {step_result.step_type.__name__}\")\n</code></pre> <p>Complete example: <code>examples/saga.py</code></p>"},{"location":"saga/examples/#recovery-example","title":"Recovery Example","text":"<pre><code>from cqrs.saga.recovery import recover_saga\n\n# Get saga instance (or keep reference to saga class)\nsaga = OrderSaga()\n\n# Recover interrupted saga\nsaga_id = uuid.UUID(\"550e8400-e29b-41d4-a716-446655440000\")\n\ntry:\n    await recover_saga(\n        saga=saga,\n        saga_id=saga_id,\n        context_builder=OrderContext,\n        container=di_container,  # Same container used in bootstrap\n        storage=storage,\n    )\n    print(\"Saga recovered successfully!\")\nexcept RuntimeError:\n    # Expected if saga was in COMPENSATING/FAILED state\n    print(\"Compensation completed\")\n</code></pre> <p>Complete example: <code>examples/saga_recovery.py</code></p>"},{"location":"saga/examples/#fastapi-sse-integration","title":"FastAPI SSE Integration","text":"<pre><code>import fastapi\nimport json\nimport uuid\nfrom cqrs.saga import bootstrap\n\ndef mediator_factory() -&gt; cqrs.SagaMediator:\n    \"\"\"Create saga mediator using bootstrap.\"\"\"\n    return bootstrap.bootstrap(\n        di_container=di_container,\n        sagas_mapper=saga_mapper,\n        saga_storage=storage,\n    )\n\n@app.post(\"/process-order\")\nasync def process_order(\n    request: ProcessOrderRequest,\n    mediator: cqrs.SagaMediator = fastapi.Depends(mediator_factory),\n):\n    async def generate_sse():\n        saga_id = uuid.uuid4()\n        context = OrderContext(...)\n\n        yield f\"data: {json.dumps({'type': 'start', 'saga_id': str(saga_id)})}\\n\\n\"\n\n        async for step_result in mediator.stream(context, saga_id=saga_id):\n            yield f\"data: {json.dumps({'type': 'step_progress', 'step': step_result.step_type.__name__})}\\n\\n\"\n\n        yield f\"data: {json.dumps({'type': 'complete'})}\\n\\n\"\n\n    return fastapi.responses.StreamingResponse(\n        generate_sse(), media_type=\"text/event-stream\"\n    )\n</code></pre> <p>Complete example: <code>examples/saga_fastapi_sse.py</code></p>"},{"location":"saga/examples/#sqlalchemy-storage-example","title":"SQLAlchemy Storage Example","text":"<pre><code>from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker\nfrom cqrs.saga.storage.sqlalchemy import SqlAlchemySagaStorage, Base\nfrom cqrs.saga import bootstrap\n\n# Setup\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@localhost/db\")\nSessionLocal = async_sessionmaker(engine, expire_on_commit=False)\n\nasync def create_storage() -&gt; SqlAlchemySagaStorage:\n    return SqlAlchemySagaStorage(SessionLocal())\n\n# Usage\nstorage = await create_storage()\n\n# Register saga in SagaMap\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\n# Create saga mediator using bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n\n# Execute saga\ncontext = OrderContext(...)\nsaga_id = uuid.uuid4()\n\nasync for step_result in mediator.stream(context, saga_id=saga_id):\n    print(f\"Step: {step_result.step_type.__name__}\")\n\nawait storage.session.commit()\n</code></pre>"},{"location":"saga/examples/#compensation-retry-configuration","title":"Compensation Retry Configuration","text":"<p>Compensation retry configuration is handled at the transaction level. When using <code>SagaMediator</code>, retry settings can be configured when creating the saga transaction. However, the recommended approach is to configure retry settings in your saga class or use the default settings.</p> <p>For advanced retry configuration, you can access the transaction directly:</p> <pre><code># Note: Compensation retry is configured at the SagaTransaction level\n# When using mediator.stream(), default retry settings are used\n# For custom retry configuration, you may need to access the transaction directly\n</code></pre>"},{"location":"saga/examples/#background-recovery-job","title":"Background Recovery Job","text":"<pre><code>import asyncio\nfrom cqrs.saga.recovery import recover_saga\n\nasync def recovery_job():\n    saga = OrderSaga()  # Get saga instance\n    while True:\n        incomplete_sagas = await find_incomplete_sagas()\n        for saga_id in incomplete_sagas:\n            try:\n                await recover_saga(\n                    saga=saga,\n                    saga_id=saga_id,\n                    context_builder=OrderContext,\n                    container=di_container,\n                    storage=storage,\n                )\n            except RuntimeError:\n                pass  # Compensation completed\n        await asyncio.sleep(60)  # Scan every minute\n</code></pre>"},{"location":"saga/examples/#fallback-pattern-example","title":"Fallback Pattern Example","text":"<pre><code>import dataclasses\nimport uuid\nimport di\nfrom di import dependent\n\nimport cqrs\nfrom cqrs.saga import bootstrap\nfrom cqrs.saga.fallback import Fallback\nfrom cqrs.adapters.circuit_breaker import AioBreakerAdapter\nfrom cqrs.saga.saga import Saga\nfrom cqrs.saga.step import SagaStepHandler, SagaStepResult\nfrom cqrs.saga.storage.memory import MemorySagaStorage\nfrom cqrs.saga.models import SagaContext\nfrom cqrs.response import Response\n\n@dataclasses.dataclass\nclass OrderContext(SagaContext):\n    order_id: str\n    reservation_id: str | None = None\n\nclass ReserveInventoryResponse(Response):\n    reservation_id: str\n    source: str\n\nclass PrimaryStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    async def act(self, context: OrderContext) -&gt; SagaStepResult[OrderContext, ReserveInventoryResponse]:\n        # Primary step that may fail\n        raise RuntimeError(\"Service unavailable\")\n\nclass FallbackStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    async def act(self, context: OrderContext) -&gt; SagaStepResult[OrderContext, ReserveInventoryResponse]:\n        # Fallback step executes when primary fails\n        reservation_id = f\"fallback_reservation_{context.order_id}\"\n        context.reservation_id = reservation_id\n        return self._generate_step_result(\n            ReserveInventoryResponse(reservation_id=reservation_id, source=\"fallback\")\n        )\n\nclass OrderSaga(Saga[OrderContext]):\n    steps = [\n        Fallback(\n            step=PrimaryStep,\n            fallback=FallbackStep,\n            circuit_breaker=AioBreakerAdapter(\n                fail_max=2,\n                timeout_duration=60,\n            ),\n        ),\n    ]\n\n# Setup\ndi_container = di.Container()\nstorage = MemorySagaStorage()\n\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n\n# Execute\ncontext = OrderContext(order_id=\"123\")\nsaga_id = uuid.uuid4()\n\nasync for step_result in mediator.stream(context, saga_id=saga_id):\n    print(f\"Step: {step_result.step_type.__name__}\")\n</code></pre> <p>Complete example: <code>examples/saga_fallback.py</code></p>"},{"location":"saga/examples/#more-examples","title":"More Examples","text":"<ul> <li>Basic Saga</li> <li>Recovery</li> <li>FastAPI SSE</li> <li>Fallback Pattern</li> </ul>"},{"location":"saga/flow/","title":"Saga Flow Diagrams","text":"<ul> <li> <p> Back to Saga Overview</p> <p>Return to the Saga Pattern overview page with all topics.</p> <p> Back to Overview</p> </li> </ul> <p>Visual representations of saga execution, compensation, and recovery flows.</p>"},{"location":"saga/flow/#execution-flow","title":"Execution Flow","text":""},{"location":"saga/flow/#successful-saga-execution","title":"Successful Saga Execution","text":"<p>When the storage supports <code>create_run()</code>, the saga runs inside one session and commits only at checkpoints (after create + RUNNING, after each step, at COMPLETED). Otherwise, each storage call may commit immediately (legacy behaviour).</p> <pre><code>sequenceDiagram\n    participant Client\n    participant Transaction as SagaTransaction\n    participant Run as SagaStorageRun\n    participant Steps as Steps\n\n    Client-&gt;&gt;Transaction: Execute saga(context, saga_id)\n    Transaction-&gt;&gt;Run: create_saga() + update_status(RUNNING)\n    Note over Transaction,Run: checkpoint: commit()\n\n    loop For each step\n        Transaction-&gt;&gt;Steps: act(context)\n        Steps--&gt;&gt;Transaction: Success\n        Transaction-&gt;&gt;Run: log_step(COMPLETED) + update_context()\n        Note over Transaction,Run: checkpoint: commit()\n    end\n\n    Transaction-&gt;&gt;Run: update_status(COMPLETED)\n    Note over Transaction,Run: checkpoint: commit()\n    Transaction--&gt;&gt;Client: Success</code></pre>"},{"location":"saga/flow/#failed-saga-with-compensation","title":"Failed Saga with Compensation","text":"<p>When using a run (checkpoint path), a commit occurs after each completed step and after each compensated step; then once at the end when status is set to FAILED.</p> <pre><code>sequenceDiagram\n    participant Client\n    participant Transaction as SagaTransaction\n    participant Run as SagaStorageRun\n    participant Step1 as Step 1\n    participant Step2 as Step 2\n    participant Step3 as Step 3\n\n    Client-&gt;&gt;Transaction: Execute saga(context, saga_id)\n    Transaction-&gt;&gt;Run: create_saga() + update_status(RUNNING)\n    Note over Transaction,Run: checkpoint: commit()\n\n    Transaction-&gt;&gt;Step1: act(context)\n    Step1--&gt;&gt;Transaction: Success\n    Transaction-&gt;&gt;Run: log_step(Step1.act, COMPLETED)\n    Note over Transaction,Run: checkpoint: commit()\n\n    Transaction-&gt;&gt;Step2: act(context)\n    Step2--&gt;&gt;Transaction: Success\n    Transaction-&gt;&gt;Run: log_step(Step2.act, COMPLETED)\n    Note over Transaction,Run: checkpoint: commit()\n\n    Transaction-&gt;&gt;Step3: act(context)\n    Step3--&gt;&gt;Transaction: Exception\n    Transaction-&gt;&gt;Run: log_step(Step3.act, FAILED) + update_status(COMPENSATING)\n    Note over Transaction,Run: checkpoint: commit()\n\n    Note over Transaction,Step2: Compensation in reverse order\n\n    Transaction-&gt;&gt;Step2: compensate(context)\n    Step2--&gt;&gt;Transaction: Done\n    Transaction-&gt;&gt;Run: log_step(Step2.compensate, COMPLETED)\n    Note over Transaction,Run: checkpoint: commit()\n\n    Transaction-&gt;&gt;Step1: compensate(context)\n    Step1--&gt;&gt;Transaction: Done\n    Transaction-&gt;&gt;Run: log_step(Step1.compensate, COMPLETED)\n    Note over Transaction,Run: checkpoint: commit()\n\n    Transaction-&gt;&gt;Run: update_status(FAILED)\n    Note over Transaction,Run: checkpoint: commit()\n    Transaction--&gt;&gt;Client: Exception raised</code></pre>"},{"location":"saga/flow/#state-transitions","title":"State Transitions","text":""},{"location":"saga/flow/#saga-status-flow","title":"Saga Status Flow","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; PENDING: Create saga\n    PENDING --&gt; RUNNING: Start execution\n    RUNNING --&gt; COMPLETED: All steps succeed \u2713\n    RUNNING --&gt; COMPENSATING: Step fails \u2717\n    COMPENSATING --&gt; FAILED: Compensation done\n    COMPLETED --&gt; [*]\n    FAILED --&gt; [*]\n\n    note right of COMPENSATING\n        Point of No Return:\n        Forward execution disabled\n    end note</code></pre>"},{"location":"saga/flow/#recovery-flow","title":"Recovery Flow","text":""},{"location":"saga/flow/#recovery-process","title":"Recovery Process","text":"<pre><code>sequenceDiagram\n    participant Recovery as Recovery Process\n    participant Storage as SagaStorage\n    participant Transaction as SagaTransaction\n    participant Steps as Remaining Steps\n\n    Note over Recovery: Saga was interrupted\n    Recovery-&gt;&gt;Storage: load_saga_state(saga_id)\n    Storage--&gt;&gt;Recovery: Status + Context + History\n\n    Recovery-&gt;&gt;Transaction: recover_saga(saga, saga_id)\n\n    alt Status: RUNNING\n        Note over Transaction: Resume forward execution\n        Transaction-&gt;&gt;Steps: Continue from last completed step\n    else Status: COMPENSATING\n        Note over Transaction: Resume compensation\n        Transaction-&gt;&gt;Steps: Continue compensation in reverse\n    end\n\n    Transaction-&gt;&gt;Storage: Update status (COMPLETED/FAILED)</code></pre>"},{"location":"saga/flow/#storage-structure","title":"Storage Structure","text":""},{"location":"saga/flow/#tables","title":"Tables","text":"<p>saga_executions:</p> <ul> <li><code>id</code> (UUID) - Primary key</li> <li><code>status</code> (Enum) - PENDING, RUNNING, COMPENSATING, COMPLETED, FAILED</li> <li><code>context</code> (JSON) - Serialized context data</li> <li><code>created_at</code>, <code>updated_at</code> (DateTime)</li> </ul> <p>saga_logs:</p> <ul> <li><code>id</code> (BigInteger) - Primary key</li> <li><code>saga_id</code> (UUID) - Foreign key</li> <li><code>step_name</code> (String)</li> <li><code>action</code> (String) - \"act\" or \"compensate\"</li> <li><code>status</code> (Enum) - STARTED, COMPLETED, FAILED</li> <li><code>details</code> (Text) - Error message if failed</li> <li><code>created_at</code> (DateTime)</li> </ul>"},{"location":"saga/recovery/","title":"Saga Recovery &amp; Eventual Consistency","text":"<ul> <li> <p> Back to Saga Overview</p> <p>Return to the Saga Pattern overview page with all topics.</p> <p> Back to Overview</p> </li> </ul> <p>Recovery ensures eventual consistency by resuming interrupted sagas from persistent storage, guaranteeing all sagas eventually reach a terminal state (COMPLETED or FAILED). Recovery attempts are tracked per saga so you can limit retries and exclude persistently failing sagas.</p>"},{"location":"saga/recovery/#overview","title":"Overview","text":"<p>Sagas can be interrupted due to server crashes, network timeouts, or system overload. Recovery solves this by:</p> <ol> <li>Persisting saga state after each step</li> <li>Periodically scanning for incomplete sagas (via <code>get_sagas_for_recovery</code>)</li> <li>Resuming execution from the last completed step</li> <li>Completing compensation if saga was in compensating state</li> <li>Tracking recovery attempts \u2014 on recovery failure, the storage increments <code>recovery_attempts</code> automatically so sagas can be retried or excluded when the limit is reached</li> </ol>"},{"location":"saga/recovery/#eventual-consistency","title":"Eventual Consistency","text":"<p>The saga pattern ensures eventual consistency through:</p> <ul> <li>Persistent State \u2014 Saved after each step</li> <li>Recovery Mechanism \u2014 Interrupted sagas can be resumed</li> <li>Recovery Attempts \u2014 Each saga has a <code>recovery_attempts</code> counter; it is incremented automatically when recovery fails, so you can limit retries and exclude sagas that exceed <code>max_recovery_attempts</code></li> <li>Compensation Guarantee \u2014 Failed sagas are always compensated</li> <li>Terminal States \u2014 All sagas eventually reach COMPLETED or FAILED</li> </ul>"},{"location":"saga/recovery/#recovery-process","title":"Recovery Process","text":"<pre><code>from cqrs.saga.recovery import recover_saga\n\n# Recover interrupted saga\nawait recover_saga(\n    saga=saga,\n    saga_id=saga_id,\n    context_builder=OrderContext,  # or lambda d: OrderContext(**d)\n)\n</code></pre> <p>Recovery steps:</p> <ol> <li>Load saga status and context from storage</li> <li>Reconstruct context object from persisted data</li> <li>Resume execution from last completed step or complete compensation</li> </ol>"},{"location":"saga/recovery/#concurrency-safety-row-locking","title":"Concurrency Safety (Row Locking)","text":"<p>In a distributed environment with multiple replicas, multiple recovery workers might attempt to recover the same incomplete saga simultaneously.</p> <p>To prevent race conditions, <code>recover_saga</code> uses Row Locking:</p> <ol> <li>It calls <code>storage.load_saga_state(saga_id, read_for_update=True)</code>.</li> <li>For SQL databases, this executes <code>SELECT ... FOR UPDATE</code>.</li> <li>This acquires a database-level lock on the saga row.</li> <li>If another worker tries to recover the same saga, it will block until the first worker completes or releases the lock.</li> </ol> <p>This ensures that only one worker can actively recover and execute a specific saga at any given time.</p>"},{"location":"saga/recovery/#recovery-scenarios","title":"Recovery Scenarios","text":""},{"location":"saga/recovery/#interrupted-forward-execution","title":"Interrupted Forward Execution","text":"<p>Status: <code>RUNNING</code> Recovery: Skips completed steps, resumes from last completed step</p> <pre><code>status, _, _ = await storage.load_saga_state(saga_id)  # RUNNING\nawait recover_saga(saga, saga_id, OrderContext)\n# Skips completed steps, continues execution\n</code></pre>"},{"location":"saga/recovery/#interrupted-compensation","title":"Interrupted Compensation","text":"<p>Status: <code>COMPENSATING</code> Recovery: Completes compensation in reverse order</p> <pre><code>status, _, _ = await storage.load_saga_state(saga_id)  # COMPENSATING\ntry:\n    await recover_saga(saga, saga_id, OrderContext)\nexcept RuntimeError:\n    pass  # Expected - compensation completed\n</code></pre>"},{"location":"saga/recovery/#already-completed","title":"Already Completed","text":"<p>Status: <code>COMPLETED</code> Recovery: No action needed</p>"},{"location":"saga/recovery/#recovery-attempts","title":"Recovery Attempts","text":"<p>Each saga in storage has a recovery_attempts counter. It is used to:</p> <ul> <li>Limit retries \u2014 Sagas that fail recovery repeatedly can be excluded from future recovery runs</li> <li>Avoid infinite loops \u2014 Persistently failing sagas (e.g. due to bad data) stop being picked after <code>max_recovery_attempts</code></li> </ul> <p>Automatic increment: When <code>recover_saga()</code> fails (exception during resume), the storage's <code>increment_recovery_attempts(saga_id, new_status=SagaStatus.FAILED)</code> is called automatically. Callers do not need to call <code>increment_recovery_attempts</code> themselves.</p> <p>Explicit set: Use <code>storage.set_recovery_attempts(saga_id, attempts)</code> to set the counter to a specific value: e.g. <code>0</code> after successfully recovering one of the steps, or the maximum value so the saga is excluded from further recovery without changing its status.</p> <p>Getting sagas for recovery: Use <code>storage.get_sagas_for_recovery()</code> instead of a custom query:</p> <pre><code># All saga types (default)\nids = await storage.get_sagas_for_recovery(\n    limit=50,\n    max_recovery_attempts=5,   # Only sagas with recovery_attempts &lt; 5\n    stale_after_seconds=120,   # Only sagas not updated in last 2 minutes (avoids picking active sagas)\n)\n\n# Only sagas of a specific type (e.g. one recovery job per saga name)\nids = await storage.get_sagas_for_recovery(\n    limit=50,\n    max_recovery_attempts=5,\n    saga_name=\"OrderSaga\",\n)\n</code></pre> Parameter Description <code>limit</code> Maximum number of saga IDs to return <code>max_recovery_attempts</code> Only include sagas with <code>recovery_attempts</code> strictly less than this value (default: 5) <code>stale_after_seconds</code> If set, only include sagas whose <code>updated_at</code> is older than (now \u2212 this value). Use to avoid picking sagas currently being executed. <code>None</code> = no filter <code>saga_name</code> If set, only include sagas with this name (e.g. handler/type name). <code>None</code> (default) = return all saga types <p>Returns saga IDs in status RUNNING or COMPENSATING, ordered by <code>updated_at</code> ascending (oldest first).</p>"},{"location":"saga/recovery/#strict-backward-recovery","title":"Strict Backward Recovery","text":"<p>Once a saga enters <code>COMPENSATING</code> or <code>FAILED</code> status, forward execution is permanently disabled. Only compensation can proceed.</p> <p>This prevents \"zombie states\" where compensation actions conflict with new execution attempts.</p>"},{"location":"saga/recovery/#implementing-recovery","title":"Implementing Recovery","text":""},{"location":"saga/recovery/#background-recovery-job","title":"Background Recovery Job","text":"<p>Use <code>storage.get_sagas_for_recovery()</code> to get saga IDs that need recovery. On recovery failure, <code>recover_saga()</code> calls <code>increment_recovery_attempts</code> internally \u2014 no extra code needed. You can pass <code>saga_name</code> to run separate recovery jobs per saga type.</p> <pre><code>import asyncio\nfrom cqrs.saga.recovery import recover_saga\n\nasync def recovery_job(storage, saga, context_builder, container, saga_name=None):\n    while True:\n        ids = await storage.get_sagas_for_recovery(\n            limit=50,\n            max_recovery_attempts=5,\n            stale_after_seconds=120,  # Avoid sagas currently being executed\n            saga_name=saga_name,     # None = all types; or e.g. \"OrderSaga\" for one type\n        )\n        for saga_id in ids:\n            try:\n                await recover_saga(\n                    saga=saga,\n                    saga_id=saga_id,\n                    context_builder=context_builder,\n                    container=container,\n                    storage=storage,\n                )\n            except RuntimeError:\n                pass  # Expected when compensation completed (forward execution not allowed)\n            except Exception as e:\n                logger.error(f\"Recovery failed for {saga_id}: {e}\")\n                # recovery_attempts already incremented by recover_saga\n        await asyncio.sleep(60)  # Scan every minute\n</code></pre>"},{"location":"saga/recovery/#using-with-scheduler","title":"Using with Scheduler","text":"<pre><code># APScheduler\nfrom apscheduler.schedulers.asyncio import AsyncIOScheduler\n\nscheduler = AsyncIOScheduler()\nscheduler.add_job(\n    lambda: recovery_job(storage, OrderSaga(), OrderContext, container),\n    'interval',\n    minutes=5,\n)\nscheduler.start()\n</code></pre>"},{"location":"saga/recovery/#best-practices","title":"Best Practices","text":"<ol> <li>Run recovery periodically \u2014 Background job using <code>get_sagas_for_recovery()</code> to scan for incomplete sagas</li> <li>Use <code>max_recovery_attempts</code> \u2014 Exclude sagas that fail recovery too many times (e.g. 5) to avoid infinite retries</li> <li>Use <code>stale_after_seconds</code> \u2014 Avoid picking sagas that are currently being executed by another worker</li> <li>Use <code>saga_name</code> for per-type recovery \u2014 When running separate recovery jobs per saga type, pass <code>saga_name</code> so each job only processes its own sagas</li> <li>Handle failures \u2014 Log errors and send alerts; <code>increment_recovery_attempts</code> is called automatically by <code>recover_saga</code></li> <li>Monitor metrics \u2014 Track recovery rate, duration, failures, and sagas exceeding max attempts</li> <li>Use persistent storage \u2014 Memory storage loses data on restart</li> </ol>"},{"location":"saga/storage/","title":"Saga Storage","text":"<ul> <li> <p> Back to Saga Overview</p> <p>Return to the Saga Pattern overview page with all topics.</p> <p> Back to Overview</p> </li> </ul> <p>Storage persists saga state and execution history, enabling recovery of interrupted sagas and ensuring eventual consistency.</p>"},{"location":"saga/storage/#overview","title":"Overview","text":"<p>Two storage implementations:</p> Storage Type Use Case Persistence MemorySagaStorage Testing, development In-memory (not persistent) SqlAlchemySagaStorage Production Database (persistent)"},{"location":"saga/storage/#storage-interface","title":"Storage Interface","text":"<pre><code>class ISagaStorage(abc.ABC):\n    async def create_saga(saga_id, name, context) -&gt; None\n    async def update_context(saga_id, context, current_version: int | None = None) -&gt; None\n    async def update_status(saga_id, status) -&gt; None\n    async def log_step(saga_id, step_name, action, status, details=None) -&gt; None\n    async def load_saga_state(saga_id, *, read_for_update: bool = False) -&gt; tuple[SagaStatus, dict, int]\n    async def get_step_history(saga_id) -&gt; list[SagaLogEntry]\n    async def get_sagas_for_recovery(limit, max_recovery_attempts=5, stale_after_seconds=None, saga_name=None) -&gt; list[uuid.UUID]\n    async def increment_recovery_attempts(saga_id, new_status: SagaStatus | None = None) -&gt; None\n    async def set_recovery_attempts(saga_id, attempts: int) -&gt; None\n\n    # Optional: checkpoint commits (reduces storage load and deadlock risk)\n    def create_run(self) -&gt; contextlib.AbstractAsyncContextManager[SagaStorageRun]:\n        \"\"\"Yield a SagaStorageRun for one saga execution; raises NotImplementedError if not supported.\"\"\"\n        raise NotImplementedError(\"This storage does not support create_run()\")\n</code></pre> <ul> <li>get_sagas_for_recovery \u2014 Returns saga IDs that need recovery (RUNNING, COMPENSATING) with <code>recovery_attempts</code> &lt; <code>max_recovery_attempts</code>, optionally filtered by staleness and by saga name. When <code>saga_name</code> is <code>None</code> (default), returns all saga types; when set, only sagas with that name. Used by recovery jobs.</li> <li>increment_recovery_attempts \u2014 Called automatically by <code>recover_saga()</code> on recovery failure; increments <code>recovery_attempts</code> and optionally updates status (e.g. to FAILED).</li> <li>set_recovery_attempts \u2014 Sets the recovery attempt counter to an explicit value. Use to reset after successfully recovering a step (e.g. set to <code>0</code>) or to set to the maximum so the saga is excluded from further recovery (e.g. mark as permanently failed without changing status).</li> </ul>"},{"location":"saga/storage/#checkpoint-commits-and-sagastoragerun","title":"Checkpoint commits and <code>SagaStorageRun</code>","text":"<p>When a storage implements <code>create_run()</code>, the saga can run in a single session with checkpoint commits: one commit only at key points (after creating the saga and setting RUNNING, after each completed step, after each compensated step, at completion or failure) instead of committing after every storage call. This reduces the number of commits, shortens lock hold time, and lowers deadlock risk (e.g. with SQLAlchemy).</p> <ul> <li><code>SagaStorageRun</code> \u2014 Protocol for a scoped \u201csession\u201d for a single saga. It exposes the same mutation/read methods as the storage (<code>create_saga</code>, <code>update_context</code>, <code>update_status</code>, <code>log_step</code>, <code>load_saga_state</code>, <code>get_step_history</code>) but does not commit automatically; the caller must call <code>commit()</code> at the desired checkpoints. <code>rollback()</code> aborts the run without persisting changes.</li> <li><code>create_run()</code> \u2014 Returns an async context manager that yields a <code>SagaStorageRun</code>. If a storage does not support it (e.g. a custom implementation), it may raise <code>NotImplementedError</code>; in that case <code>SagaTransaction</code> falls back to the previous behaviour (no single session, no checkpoint commits; each call may commit immediately depending on the implementation).</li> <li><code>load_saga_state(..., read_for_update=True)</code> \u2014 When loading state for recovery or exclusive update, the implementation can lock the row (e.g. <code>SELECT ... FOR UPDATE</code> in SQLAlchemy). Together with checkpoint commits, this shortens lock duration and reduces deadlock risk.</li> </ul>"},{"location":"saga/storage/#memory-storage","title":"Memory Storage","text":"<p>In-memory implementation for testing and development.</p> <pre><code>import cqrs\nfrom cqrs.saga import bootstrap\nfrom cqrs.saga.storage.memory import MemorySagaStorage\n\nstorage = MemorySagaStorage()\n\n# Register saga in SagaMap\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\n# Create saga mediator using bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n\n# Access storage data\nstatus, context_data, version = await storage.load_saga_state(saga_id)\nhistory = await storage.get_step_history(saga_id)\n</code></pre> <p>Features:</p> <ul> <li>\u2705 Fast and lightweight</li> <li>\u2705 No database setup required</li> <li>\u2705 Implements <code>create_run()</code> \u2014 yields <code>_MemorySagaStorageRun</code>; <code>commit()</code> and <code>rollback()</code> are no-ops, but the protocol is aligned with SQLAlchemy for tests.</li> <li>\u274c Not persistent (data lost on restart)</li> </ul>"},{"location":"saga/storage/#sqlalchemy-storage","title":"SQLAlchemy Storage","text":"<p>Database-backed implementation for production. It uses a session factory. When the saga uses <code>create_run()</code>, all operations for one saga run go through a single <code>AsyncSession</code> and are committed only at checkpoints (after create + RUNNING, after each step, after each compensation step, at completion/failure), which reduces commits and deadlock risk.</p>"},{"location":"saga/storage/#database-schema","title":"Database Schema","text":"<p>saga_executions:</p> <ul> <li><code>id</code> (UUID) - Primary key</li> <li><code>status</code> (VARCHAR) - PENDING, RUNNING, COMPENSATING, COMPLETED, FAILED</li> <li><code>context</code> (JSON)</li> <li><code>version</code> (INTEGER) - Optimistic locking version (default: 1)</li> <li><code>recovery_attempts</code> (INTEGER) - Number of failed recovery attempts (default: 0); used by <code>get_sagas_for_recovery</code>, <code>increment_recovery_attempts</code>, and <code>set_recovery_attempts</code></li> <li><code>created_at</code>, <code>updated_at</code> (TIMESTAMP)</li> </ul> <p>saga_logs:</p> <ul> <li><code>id</code> (BIGSERIAL) - Primary key</li> <li><code>saga_id</code> (UUID) - Foreign key</li> <li><code>step_name</code> (VARCHAR)</li> <li><code>action</code> (VARCHAR) - \"act\" or \"compensate\"</li> <li><code>status</code> (VARCHAR) - STARTED, COMPLETED, FAILED</li> <li><code>details</code> (TEXT)</li> <li><code>created_at</code> (TIMESTAMP)</li> </ul> <p>Indexes: <code>saga_id</code>, <code>created_at</code></p>"},{"location":"saga/storage/#usage","title":"Usage","text":"<p>The storage requires an <code>async_sessionmaker</code> to create short-lived sessions for each operation.</p> <pre><code>import uuid\nimport cqrs\nfrom cqrs.saga import bootstrap\nfrom sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker\nfrom cqrs.saga.storage.sqlalchemy import SqlAlchemySagaStorage, Base\n\n# Setup Engine with connection pool\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:pass@localhost/db\",\n    pool_size=20,\n    max_overflow=10,\n)\n\n# Create session factory (factory, NOT session instance)\nsession_factory = async_sessionmaker(engine, expire_on_commit=False)\n\n# Initialize tables (run once)\nasync with engine.begin() as conn:\n    await conn.run_sync(Base.metadata.create_all)\n\n# Initialize storage with session FACTORY\nstorage = SqlAlchemySagaStorage(session_factory)\n\n# Register saga in SagaMap\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\n# Create saga mediator using bootstrap\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n\n# Execute saga\ncontext = OrderContext(...)\nsaga_id = uuid.uuid4()\n\n# With SqlAlchemySagaStorage, commits occur at checkpoints (after each step, etc.)\nasync for step_result in mediator.stream(context, saga_id=saga_id):\n    print(f\"Step: {step_result.step_type.__name__}\")\n</code></pre>"},{"location":"saga/storage/#transaction-management","title":"Transaction Management","text":"<p>SqlAlchemySagaStorage implements <code>create_run()</code>: it yields a <code>_SqlAlchemySagaStorageRun</code> backed by a single <code>AsyncSession</code> per saga run. All mutations go through that session and are committed only when the saga calls <code>run.commit()</code> at checkpoints (after creating the saga and setting RUNNING, after each completed step, after each compensated step, at completion or failure). On exception within the run context, the run's <code>rollback()</code> is invoked.</p> <p>This design ensures:</p> <ul> <li>Fewer commits \u2014 One commit per checkpoint instead of per storage call.</li> <li>Shorter lock time \u2014 With <code>load_saga_state(..., read_for_update=True)</code>, the row is locked only for the duration of the run; checkpoint commits shorten that duration and reduce deadlock risk.</li> <li>Crash safety \u2014 Completed checkpoints are persisted; recovery can resume from the last checkpoint.</li> <li>Backward compatibility \u2014 Custom storages that do not implement <code>create_run()</code> continue to work; the saga falls back to calling storage methods directly (no single session).</li> </ul>"},{"location":"saga/storage/#concurrency-control","title":"Concurrency Control","text":"<p>The storage implementation provides two mechanisms to handle concurrency in distributed environments:</p>"},{"location":"saga/storage/#1-optimistic-locking-versioning","title":"1. Optimistic Locking (Versioning)","text":"<p>To prevent \"lost updates\" when multiple steps might update the context simultaneously (though sagas typically execute sequentially), the <code>version</code> column is used.</p> <ul> <li><code>update_context</code> accepts an optional <code>current_version</code>.</li> <li>If provided, the storage checks if <code>version == current_version</code>.</li> <li>If matched, it updates the context and increments the version (<code>version + 1</code>).</li> <li>If not matched, it raises <code>SagaConcurrencyError</code>, indicating the state was modified by another process.</li> </ul>"},{"location":"saga/storage/#2-row-locking-recovery-safety-and-deadlock-mitigation","title":"2. Row Locking (Recovery Safety and Deadlock Mitigation)","text":"<p>When recovering or exclusively updating a saga (e.g., after a crash), it is critical that only one worker picks up the saga to avoid duplicate execution.</p> <ul> <li><code>load_saga_state(..., read_for_update=True)</code> uses <code>SELECT ... FOR UPDATE</code> (in SQL databases), acquiring a row-level lock on the saga execution record.</li> <li>Other workers attempting to lock the same saga will wait or fail, ensuring exclusive access.</li> <li>When the storage supports <code>create_run()</code>, the saga holds the session (and thus the lock) only between checkpoints; commits are done at key points, which shortens lock duration and reduces deadlock risk.</li> </ul>"},{"location":"saga/storage/#choosing-storage","title":"Choosing Storage","text":"<p>Memory Storage:</p> <ul> <li>\u2705 Unit tests, development</li> <li>\u274c Not persistent</li> </ul> <p>SQLAlchemy Storage:</p> <ul> <li>\u2705 Production, multi-process</li> <li>\u2705 Recovery after restarts</li> <li>\u2705 Audit trail</li> <li>\u2705 Robust transaction management</li> </ul>"},{"location":"saga/storage/#best-practices","title":"Best Practices","text":"<ol> <li>Use persistent storage in production \u2014 Memory storage loses data on restart</li> <li>Configure Connection Pool \u2014 Set appropriate <code>pool_size</code> and <code>max_overflow</code> for your load.</li> <li>Create indexes \u2014 Index <code>saga_id</code> and <code>created_at</code> for better performance</li> <li>Monitor storage size \u2014 Archive old saga logs periodically</li> </ol>"},{"location":"saga/fallback/","title":"Saga Fallback Pattern","text":"<ul> <li> <p> Back to Saga Overview</p> <p>Return to the Saga Pattern overview page with all topics.</p> <p> Back to Overview</p> </li> </ul> <p>The Fallback pattern allows you to define alternative steps that execute automatically when primary steps fail. This provides resilience and graceful degradation for distributed transactions.</p>"},{"location":"saga/fallback/#overview","title":"Overview","text":"<ul> <li> <p> Mechanics &amp; Internals</p> <p>Learn about execution flow, context snapshots, and compensation logic.</p> <p> Read More</p> </li> <li> <p> Circuit Breaker</p> <p>Understand how circuit breaker integration prevents cascading failures.</p> <p> Read More</p> </li> <li> <p> Examples</p> <p>See complete working examples of the Fallback pattern in action.</p> <p> Read More</p> </li> </ul> <p>The <code>Fallback</code> wrapper enables saga steps to have backup execution paths. When a primary step fails, the fallback step executes automatically with the context restored to its state before the primary step attempted execution.</p>"},{"location":"saga/fallback/#key-concepts","title":"Key Concepts","text":"Concept Description Primary Step The main step handler that executes first Fallback Step Alternative step handler that executes if primary fails Context Snapshot Deep copy of context state before primary step execution Context Restore Restoring context to snapshot state before fallback execution Circuit Breaker Optional protection mechanism to prevent cascading failures <p>When to Use</p> <p>Use Fallback pattern when: - You have alternative execution paths for critical operations - You want graceful degradation instead of immediate failure - You need to protect against transient failures - You want to reduce load on failing services with Circuit Breaker</p>"},{"location":"saga/fallback/#basic-example","title":"Basic Example","text":"<pre><code>import dataclasses\nfrom cqrs.saga.fallback import Fallback\nfrom cqrs.saga.saga import Saga\nfrom cqrs.saga.step import SagaStepHandler, SagaStepResult\nfrom cqrs.saga.models import SagaContext\nfrom cqrs.response import Response\n\n@dataclasses.dataclass\nclass OrderContext(SagaContext):\n    order_id: str\n    reservation_id: str | None = None\n\nclass ReserveInventoryResponse(Response):\n    reservation_id: str\n\nclass PrimaryStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    async def act(self, context: OrderContext) -&gt; SagaStepResult[OrderContext, ReserveInventoryResponse]:\n        # Primary step that may fail\n        reservation_id = await self._inventory_service.reserve_items(context.order_id)\n        context.reservation_id = reservation_id\n        return self._generate_step_result(\n            ReserveInventoryResponse(reservation_id=reservation_id)\n        )\n\nclass FallbackStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    async def act(self, context: OrderContext) -&gt; SagaStepResult[OrderContext, ReserveInventoryResponse]:\n        # Alternative step that executes when primary fails\n        # Context is restored to state before primary execution\n        reservation_id = f\"fallback_reservation_{context.order_id}\"\n        context.reservation_id = reservation_id\n        return self._generate_step_result(\n            ReserveInventoryResponse(reservation_id=reservation_id)\n        )\n\n# Define saga with fallback\nclass OrderSaga(Saga[OrderContext]):\n    steps = [\n        Fallback(\n            step=PrimaryStep,\n            fallback=FallbackStep,\n        ),\n    ]\n</code></pre>"},{"location":"saga/fallback/#best-practices","title":"Best Practices","text":"<ol> <li>Use Fallback for Resilience: Define fallback steps for critical operations that have alternative execution paths</li> <li>Context Isolation: Remember that fallback receives a restored context (no side effects from failed primary)</li> <li>Circuit Breaker for Transient Failures: Use Circuit Breaker when failures are likely transient and you want to reduce load on failing services</li> <li>Exclude Business Exceptions: Use <code>exclude</code> parameter to prevent business logic errors from opening the circuit</li> <li>Idempotent Fallback Steps: Ensure fallback steps are idempotent (safe to retry during recovery)</li> <li>Proper Compensation: Define <code>compensate()</code> methods for both primary and fallback steps</li> <li>Failure Exception Filtering: Use <code>failure_exceptions</code> to control which exceptions trigger fallback</li> </ol>"},{"location":"saga/fallback/circuit_breaker/","title":"Circuit Breaker Integration","text":"<ul> <li> <p> Back to Saga Fallback Overview</p> <p>Return to the Saga Fallback overview page with all topics.</p> <p> Back to Overview</p> </li> </ul> <p>Circuit Breaker prevents cascading failures by \"opening\" the circuit after repeated failures, failing fast instead of attempting execution.</p>"},{"location":"saga/fallback/circuit_breaker/#why-circuit-breaker","title":"Why Circuit Breaker?","text":"<p>When a service is experiencing issues:</p> <ul> <li>Without Circuit Breaker: Every request attempts execution, wasting resources and potentially making the problem worse</li> <li>With Circuit Breaker: After threshold failures, requests fail immediately without attempting execution, reducing load on failing service</li> </ul>"},{"location":"saga/fallback/circuit_breaker/#circuit-breaker-states","title":"Circuit Breaker States","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; CLOSED: Initial state\n    CLOSED --&gt; OPEN: Failures &gt;= fail_max\n    OPEN --&gt; HALF_OPEN: timeout_duration elapsed\n    HALF_OPEN --&gt; CLOSED: Success\n    HALF_OPEN --&gt; OPEN: Failure\n\n    note right of OPEN\n        Fail fast mode:\n        No execution attempted\n        Fallback executes immediately\n    end note\n\n    note right of HALF_OPEN\n        Test mode:\n        Single request allowed\n        Determines if service recovered\n    end note</code></pre>"},{"location":"saga/fallback/circuit_breaker/#circuit-breaker-strategy","title":"Circuit Breaker Strategy","text":"<p>The Circuit Breaker follows a three-state pattern:</p> <ol> <li>CLOSED (Normal Operation)</li> <li>Primary step executes normally</li> <li>Failures are counted</li> <li> <p>After <code>fail_max</code> failures \u2192 transition to OPEN</p> </li> <li> <p>OPEN (Fail Fast)</p> </li> <li>Primary step is NOT executed (fail fast)</li> <li><code>CircuitBreakerError</code> is raised immediately</li> <li>Fallback executes automatically</li> <li> <p>After <code>timeout_duration</code> \u2192 transition to HALF_OPEN</p> </li> <li> <p>HALF_OPEN (Testing Recovery)</p> </li> <li>Single request allowed (test if service recovered)</li> <li>Success \u2192 transition to CLOSED</li> <li>Failure \u2192 transition back to OPEN</li> </ol>"},{"location":"saga/fallback/circuit_breaker/#configuration","title":"Configuration","text":"<pre><code>from cqrs.adapters.circuit_breaker import AioBreakerAdapter\nfrom cqrs.saga.fallback import Fallback\n\nFallback(\n    step=PrimaryStep,\n    fallback=FallbackStep,\n    circuit_breaker=AioBreakerAdapter(\n        fail_max=3,              # Open circuit after 3 failures\n        timeout_duration=60,      # Wait 60 seconds before retry (HALF_OPEN)\n        exclude=[BusinessError],  # Don't count these as failures\n    ),\n)\n</code></pre> <p>Parameters:</p> Parameter Description Default <code>fail_max</code> Number of failures before opening circuit <code>5</code> <code>timeout_duration</code> Seconds to wait before attempting HALF_OPEN <code>60</code> <code>exclude</code> Exception types that don't count as failures <code>[]</code>"},{"location":"saga/fallback/circuit_breaker/#storage-configuration-memory-vs-redis","title":"Storage Configuration (Memory vs Redis)","text":"<p>By default, the circuit breaker uses in-memory storage, which is isolated to each application instance. For distributed applications, you can configure it to use Redis to share circuit state across all instances.</p> <p>In-Memory Storage (Default): <pre><code>circuit_breaker = AioBreakerAdapter(\n    fail_max=3,\n    timeout_duration=60\n)\n</code></pre></p> <p>Redis Storage (Distributed): <pre><code>import redis\nfrom aiobreaker.storage.redis import CircuitRedisStorage\nfrom aiobreaker import CircuitBreakerState\n\ndef redis_storage_factory(name: str):\n    # Important: decode_responses=False for aiobreaker compatibility\n    client = redis.from_url(\n        \"redis://localhost:6379\", \n        encoding=\"utf-8\", \n        decode_responses=False\n    )\n    return CircuitRedisStorage(\n        state=CircuitBreakerState.CLOSED, \n        redis_object=client, \n        namespace=name\n    )\n\ncircuit_breaker = AioBreakerAdapter(\n    fail_max=3,\n    timeout_duration=60,\n    storage_factory=redis_storage_factory\n)\n</code></pre></p>"},{"location":"saga/fallback/circuit_breaker/#failure-exception-filtering","title":"Failure Exception Filtering","text":"<p>You can specify which exceptions should trigger fallback execution:</p> <pre><code>Fallback(\n    step=PrimaryStep,\n    fallback=FallbackStep,\n    failure_exceptions=(ConnectionError, TimeoutError),  # Only these trigger fallback\n)\n</code></pre> <p>Behavior:</p> <ul> <li>If <code>failure_exceptions</code> is empty tuple <code>()</code>: All exceptions trigger fallback (default)</li> <li>If <code>failure_exceptions</code> is specified: Only matching exceptions trigger fallback</li> <li>Non-matching exceptions propagate immediately (saga fails without fallback)</li> </ul>"},{"location":"saga/fallback/circuit_breaker/#business-exception-exclusion","title":"Business Exception Exclusion","text":"<p>Some exceptions shouldn't open the circuit (e.g., business logic errors):</p> <pre><code>class InventoryOutOfStockError(Exception):\n    pass\n\nFallback(\n    step=PrimaryStep,\n    fallback=FallbackStep,\n    circuit_breaker=AioBreakerAdapter(\n        fail_max=3,\n        timeout_duration=60,\n        exclude=[InventoryOutOfStockError],  # Don't count as failure\n    ),\n)\n</code></pre> <p>Behavior:</p> <ul> <li><code>InventoryOutOfStockError</code> \u2192 Fallback executes, but circuit counter is not incremented</li> <li>Other exceptions \u2192 Fallback executes, circuit counter is incremented</li> </ul>"},{"location":"saga/fallback/examples/","title":"Complete Example","text":"<ul> <li> <p> Back to Saga Fallback Overview</p> <p>Return to the Saga Fallback overview page with all topics.</p> <p> Back to Overview</p> </li> </ul> <p>Here is a complete example demonstrating the Fallback pattern with Circuit Breaker and Saga execution.</p> <pre><code>import dataclasses\nimport uuid\nimport di\nfrom di import dependent\n\nimport cqrs\nfrom cqrs.saga import bootstrap\nfrom cqrs.saga.fallback import Fallback\nfrom cqrs.adapters.circuit_breaker import AioBreakerAdapter\nfrom cqrs.saga.saga import Saga\nfrom cqrs.saga.step import SagaStepHandler, SagaStepResult\nfrom cqrs.saga.storage.memory import MemorySagaStorage\nfrom cqrs.saga.models import SagaContext\nfrom cqrs.response import Response\n\n@dataclasses.dataclass\nclass OrderContext(SagaContext):\n    order_id: str\n    user_id: str\n    reservation_id: str | None = None\n\nclass ReserveInventoryResponse(Response):\n    reservation_id: str\n    source: str  # \"primary\" or \"fallback\"\n\nclass PrimaryStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    def __init__(self, inventory_service):\n        self._inventory_service = inventory_service\n\n    async def act(self, context: OrderContext) -&gt; SagaStepResult[OrderContext, ReserveInventoryResponse]:\n        # Primary step - may fail\n        reservation_id = await self._inventory_service.reserve_items(\n            context.order_id\n        )\n        context.reservation_id = reservation_id\n        return self._generate_step_result(\n            ReserveInventoryResponse(reservation_id=reservation_id, source=\"primary\")\n        )\n\n    async def compensate(self, context: OrderContext) -&gt; None:\n        if context.reservation_id:\n            await self._inventory_service.release_items(context.reservation_id)\n\nclass FallbackStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    def __init__(self, fallback_service):\n        self._fallback_service = fallback_service\n\n    async def act(self, context: OrderContext) -&gt; SagaStepResult[OrderContext, ReserveInventoryResponse]:\n        # Fallback step - executes when primary fails\n        # Context is restored to state before primary execution\n        reservation_id = f\"fallback_reservation_{context.order_id}\"\n        context.reservation_id = reservation_id\n        return self._generate_step_result(\n            ReserveInventoryResponse(reservation_id=reservation_id, source=\"fallback\")\n        )\n\n    async def compensate(self, context: OrderContext) -&gt; None:\n        if context.reservation_id:\n            await self._fallback_service.release_fallback_reservation(context.reservation_id)\n\nclass OrderSaga(Saga[OrderContext]):\n    steps = [\n        Fallback(\n            step=PrimaryStep,\n            fallback=FallbackStep,\n            circuit_breaker=AioBreakerAdapter(\n                fail_max=2,\n                timeout_duration=60,\n            ),\n        ),\n    ]\n\n# Setup\ndi_container = di.Container()\n# ... register services ...\n\nstorage = MemorySagaStorage()\n\ndef saga_mapper(mapper: cqrs.SagaMap) -&gt; None:\n    mapper.bind(OrderContext, OrderSaga)\n\nmediator = bootstrap.bootstrap(\n    di_container=di_container,\n    sagas_mapper=saga_mapper,\n    saga_storage=storage,\n)\n\n# Execute\ncontext = OrderContext(order_id=\"123\", user_id=\"user_1\")\nsaga_id = uuid.uuid4()\n\nasync for step_result in mediator.stream(context, saga_id=saga_id):\n    print(f\"Step: {step_result.step_type.__name__}\")\n    if hasattr(step_result.response, \"source\"):\n        print(f\"Source: {step_result.response.source}\")\n</code></pre>"},{"location":"saga/fallback/mechanics/","title":"Mechanics &amp; Internals","text":"<ul> <li> <p> Back to Saga Fallback Overview</p> <p>Return to the Saga Fallback overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"saga/fallback/mechanics/#how-it-works","title":"How It Works","text":""},{"location":"saga/fallback/mechanics/#execution-flow","title":"Execution Flow","text":"<pre><code>sequenceDiagram\n    participant Executor as FallbackStepExecutor\n    participant Primary as PrimaryStep\n    participant Fallback as FallbackStep\n\n    Executor-&gt;&gt;Executor: Create context snapshot\n\n    alt Primary Step Succeeds\n        Executor-&gt;&gt;Primary: act(context)\n        Primary--&gt;&gt;Executor: Success\n        Note over Executor: Return primary result\n    else Primary Step Fails\n        Executor-&gt;&gt;Primary: act(context)\n        Primary--&gt;&gt;Executor: Exception\n\n        Executor-&gt;&gt;Executor: Restore context from snapshot\n        Executor-&gt;&gt;Fallback: act(restored_context)\n\n        alt Fallback Succeeds\n            Fallback--&gt;&gt;Executor: Success\n            Note over Executor: Return fallback result\n        else Fallback Fails\n            Fallback--&gt;&gt;Executor: Exception\n            Note over Executor: Saga fails\n        end\n    end</code></pre>"},{"location":"saga/fallback/mechanics/#context-management","title":"Context Management","text":"<p>The Fallback pattern implements a snapshot and restore mechanism for context management:</p> <ol> <li>Before Primary Execution: A deep copy of the context is created (<code>copy.deepcopy(context.to_dict())</code>)</li> <li>If Primary Fails: The context is restored to the snapshot state before fallback execution</li> <li>If Primary Succeeds: The snapshot is discarded and context updates from primary step are kept</li> </ol> <p>This ensures that:</p> <ul> <li>Fallback steps start with a clean state (no side effects from failed primary)</li> <li>Context mutations from primary step are not visible to fallback</li> <li>Each step execution is isolated</li> </ul> <pre><code># Simplified context snapshot/restore logic\ncontext_snapshot = copy.deepcopy(context.to_dict())  # Before primary\n\ntry:\n    result = await primary_step.act(context)  # May modify context\nexcept Exception:\n    # Restore context to snapshot state\n    restored_context = context.__class__.from_dict(context_snapshot)\n    for field in dataclasses.fields(context):\n        setattr(context, field.name, getattr(restored_context, field.name))\n\n    # Execute fallback with restored context\n    result = await fallback_step.act(context)\n</code></pre>"},{"location":"saga/fallback/mechanics/#step-execution-details","title":"Step Execution Details","text":""},{"location":"saga/fallback/mechanics/#primary-step-execution","title":"Primary Step Execution","text":"<ol> <li>Context Snapshot: Deep copy created before execution</li> <li>Logging: Step start logged to <code>SagaLog</code></li> <li>Execution: </li> <li>If Circuit Breaker present: <code>circuit_breaker.call(step_type, primary_step.act, context)</code></li> <li>Otherwise: <code>primary_step.act(context)</code> directly</li> <li>Success: Context updated, step completion logged</li> <li>Failure: Exception caught, fallback logic triggered</li> </ol>"},{"location":"saga/fallback/mechanics/#fallback-step-execution","title":"Fallback Step Execution","text":"<ol> <li>Context Restore: Context restored to snapshot state (before primary execution)</li> <li>Logging: Fallback step start logged</li> <li>Execution: <code>fallback_step.act(restored_context)</code></li> <li>Success: Context updated, fallback completion logged</li> <li>Failure: Exception propagated (saga fails)</li> </ol>"},{"location":"saga/fallback/mechanics/#idempotency","title":"Idempotency","text":"<p>Fallback steps respect idempotency checks:</p> <ul> <li>If primary step name is in <code>completed_step_names</code> \u2192 Skip execution</li> <li>If fallback step name is in <code>completed_step_names</code> \u2192 Skip execution</li> <li>This ensures recovery doesn't re-execute already completed steps</li> </ul>"},{"location":"saga/fallback/mechanics/#compensation","title":"Compensation","text":"<p>Both primary and fallback steps can define <code>compensate()</code> methods:</p> <pre><code>class PrimaryStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    async def act(self, context: OrderContext) -&gt; SagaStepResult:\n        # ... primary logic ...\n\n    async def compensate(self, context: OrderContext) -&gt; None:\n        # Compensate primary step\n        if context.reservation_id:\n            await self._inventory_service.release_items(context.reservation_id)\n\nclass FallbackStep(SagaStepHandler[OrderContext, ReserveInventoryResponse]):\n    async def act(self, context: OrderContext) -&gt; SagaStepResult:\n        # ... fallback logic ...\n\n    async def compensate(self, context: OrderContext) -&gt; None:\n        # Compensate fallback step\n        if context.reservation_id:\n            await self._inventory_service.release_fallback_reservation(context.reservation_id)\n</code></pre> <p>Compensation Rules:</p> <ul> <li>Only the actually executed step (primary or fallback) is compensated</li> <li>If primary succeeded \u2192 only primary's <code>compensate()</code> is called</li> <li>If fallback executed \u2192 only fallback's <code>compensate()</code> is called</li> </ul>"},{"location":"saga/fallback/mechanics/#storage-and-logging","title":"Storage and Logging","text":"<p>Fallback execution is fully logged in <code>SagaLog</code>:</p> <p>Successful Primary: <pre><code>- primary_step.act STARTED\n- primary_step.act COMPLETED\n</code></pre></p> <p>Failed Primary \u2192 Successful Fallback: <pre><code>- primary_step.act STARTED\n- fallback_step.act STARTED\n- fallback_step.act COMPLETED\n</code></pre></p> <p>Failed Primary \u2192 Failed Fallback: <pre><code>- primary_step.act STARTED\n- fallback_step.act STARTED\n- fallback_step.act FAILED (error details)\n</code></pre></p> <p>Circuit Breaker OPEN: <pre><code>- fallback_step.act STARTED (primary not executed)\n- fallback_step.act COMPLETED\n</code></pre></p>"},{"location":"stream_handling/","title":"Stream Handling","text":"<p>Stream handling allows you to process requests incrementally and yield results as they become available. This is particularly useful for processing large batches of items, file uploads, or any operation that benefits from real-time progress updates.</p>"},{"location":"stream_handling/#overview","title":"Overview","text":"<ul> <li> <p> Configuration</p> <p>Bootstrap setup and mediator usage for streaming requests.</p> <p> Read More</p> </li> <li> <p> FastAPI Integration</p> <p>SSE integration examples for real-time progress updates.</p> <p> Read More</p> </li> <li> <p> Reference</p> <p>Key features, use cases, and best practices for stream handling.</p> <p> Read More</p> </li> <li> <p> Fallback</p> <p>Fallback streaming handler when primary stream fails.</p> <p> Read More</p> </li> </ul> <p><code>StreamingRequestHandler</code> works with <code>StreamingRequestMediator</code> to process requests incrementally. The handler yields results as they become available, and events are processed after each yield. This enables:</p> <ul> <li>Real-time progress updates \u2014 Clients receive results as they're processed</li> <li>Better user experience \u2014 No need to wait for entire batch to complete</li> <li>Parallel event processing \u2014 Events can be processed concurrently while streaming</li> <li>SSE integration \u2014 Perfect for Server-Sent Events in web applications</li> </ul> <p>Prerequisites</p> <p>Understanding of Request Handlers and Bootstrap is recommended.</p> <p>Use Cases</p> <p>Streaming is ideal for large batch operations, file processing, or any scenario where you want to provide real-time feedback. See FastAPI Integration for SSE examples.</p>"},{"location":"stream_handling/#basic-example","title":"Basic Example","text":"<p>Here's a simple example of a streaming handler:</p> <pre><code>import typing\nfrom datetime import datetime\nimport cqrs\nfrom cqrs.requests.request_handler import StreamingRequestHandler\nfrom cqrs.events.event import Event\n\nclass ProcessFilesCommand(cqrs.Request):\n    file_ids: list[str]\n\nclass FileProcessedResult(cqrs.Response):\n    file_id: str\n    status: str\n    processed_at: datetime\n\nclass ProcessFilesCommandHandler(\n    StreamingRequestHandler[ProcessFilesCommand, FileProcessedResult]\n):\n    def __init__(self):\n        self._events: list[Event] = []\n\n    @property\n    def events(self) -&gt; list[Event]:\n        return self._events.copy()\n\n    def clear_events(self) -&gt; None:\n        self._events.clear()\n\n    async def handle(\n        self, request: ProcessFilesCommand\n    ) -&gt; typing.AsyncIterator[FileProcessedResult]:\n        for file_id in request.file_ids:\n            # Process file\n            result = FileProcessedResult(\n                file_id=file_id,\n                status=\"completed\",\n                processed_at=datetime.now()\n            )\n\n            # Emit events\n            self._events.append(\n                FileProcessedEvent(file_id=file_id, ...)\n            )\n\n            # Yield result - events will be processed after this yield\n            yield result\n</code></pre> <p>Typing</p> <p>The base <code>StreamingRequestHandler</code> declares <code>def handle(...) -&gt; AsyncIterator[ResT]</code>. Your subclass implements it as an async generator (<code>async def handle(...): yield ...</code>). This is type-safe; no <code># type: ignore</code> is needed. Call <code>mediator.stream(request)</code> without <code>await</code> and consume the result with <code>async for</code>.</p>"},{"location":"stream_handling/configuration/","title":"Configuration","text":"<ul> <li> <p> Back to Stream Handling Overview</p> <p>Return to the Stream Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"stream_handling/configuration/#overview","title":"Overview","text":"<p>To use streaming handlers, you need to bootstrap a <code>StreamingRequestMediator</code>:</p> <pre><code>import functools\nfrom cqrs.requests import bootstrap\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(ProcessFilesCommand, ProcessFilesCommandHandler)\n\ndef domain_events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(FileProcessedEvent, FileProcessedEventHandler)\n\n@functools.cache\ndef streaming_mediator_factory() -&gt; cqrs.StreamingRequestMediator:\n    return bootstrap.bootstrap_streaming(\n        di_container=container,\n        commands_mapper=commands_mapper,\n        domain_events_mapper=domain_events_mapper,\n        message_broker=broker,\n        max_concurrent_event_handlers=3,  # Process up to 3 events in parallel\n        concurrent_event_handle_enable=True,  # Enable parallel processing\n    )\n</code></pre> <p>Once you have a streaming mediator, you can stream results:</p> <pre><code>mediator = streaming_mediator_factory()\n\ncommand = ProcessFilesCommand(file_ids=[\"file1\", \"file2\", \"file3\"])\n\n# Stream results as they become available\nasync for result in mediator.stream(command):\n    if result is not None:\n        print(f\"Processed: {result.file_id} - {result.status}\")\n</code></pre> <p>Streaming handlers support parallel event processing. After each yield, events are collected and can be processed concurrently:</p> <pre><code>class ProcessOrdersCommandHandler(\n    cqrs.StreamingRequestHandler[ProcessOrdersCommand, OrderProcessedResult]\n):\n    def __init__(self):\n        self._events: list[Event] = []\n\n    @property\n    def events(self) -&gt; list[Event]:\n        return self._events.copy()\n\n    def clear_events(self) -&gt; None:\n        self._events.clear()\n\n    async def handle(\n        self, request: ProcessOrdersCommand\n    ) -&gt; typing.AsyncIterator[OrderProcessedResult]:\n        for order_id in request.order_ids:\n            # Process order\n            result = OrderProcessedResult(order_id=order_id, ...)\n\n            # Emit multiple events that will be processed in parallel\n            self._events.append(OrderProcessedEvent(order_id=order_id, ...))\n            self._events.append(OrderAnalyticsEvent(order_id=order_id, ...))\n            self._events.append(InventoryUpdateEvent(order_id=order_id, ...))\n            self._events.append(AuditLogEvent(order_id=order_id, ...))\n\n            yield result\n            # Events are processed in parallel after each yield\n</code></pre>"},{"location":"stream_handling/configuration/#configuration_1","title":"Configuration","text":"<p>Control parallel event processing with these parameters:</p> <ul> <li><code>max_concurrent_event_handlers</code> \u2014 Maximum number of event handlers that can run simultaneously (default: <code>10</code> for streaming mediator)</li> <li><code>concurrent_event_handle_enable</code> \u2014 Enable/disable parallel processing (default: <code>True</code> for streaming mediator)</li> </ul> <pre><code>mediator = bootstrap.bootstrap_streaming(\n    di_container=container,\n    commands_mapper=commands_mapper,\n    domain_events_mapper=domain_events_mapper,\n    max_concurrent_event_handlers=5,  # Process up to 5 events in parallel\n    concurrent_event_handle_enable=True,  # Enable parallel processing\n)\n</code></pre> <p>Configuration Tips</p> <ul> <li>Set <code>max_concurrent_event_handlers</code> to limit resource consumption</li> <li>Set <code>concurrent_event_handle_enable=False</code> to process events sequentially</li> <li>Higher concurrency improves performance but uses more resources</li> </ul>"},{"location":"stream_handling/fallback/","title":"Stream Handling Fallback","text":"<ul> <li> <p> Back to Stream Handling Overview</p> <p>Return to the Stream Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"stream_handling/fallback/#overview","title":"Overview","text":"<p>The Stream Handling Fallback uses the same <code>RequestHandlerFallback</code> wrapper as ordinary request handlers, but with streaming handlers as primary and fallback. When the primary streaming handler fails (e.g. raises after yielding some items), the dispatcher switches to the fallback streaming handler and consumes its stream. This is useful when the primary stream source (e.g. live API) can fail mid-way and you want to continue with a fallback stream (e.g. cached or degraded results).</p> Concept Description Primary <code>StreamingRequestHandler</code> that yields first; may raise during iteration Fallback <code>StreamingRequestHandler</code> used when primary raises Flow <code>mediator.stream(request)</code> yields from primary until it raises, then yields from fallback <p>When to Use</p> <p>Use streaming fallback when you stream results from a primary source that can fail partway through (e.g. connection lost). The fallback can yield from cache or a degraded path so the client still receives a complete stream.</p>"},{"location":"stream_handling/fallback/#registration","title":"Registration","text":"<p>Bind the streaming command to <code>RequestHandlerFallback</code> with both handlers as <code>StreamingRequestHandler</code>:</p> <pre><code>import cqrs\n\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(\n        StreamItemsCommand,\n        cqrs.RequestHandlerFallback(\n            primary=PrimaryStreamItemsHandler,\n            fallback=FallbackStreamItemsHandler,\n            failure_exceptions=(ConnectionError, TimeoutError),  # optional\n            circuit_breaker=stream_cb,  # optional\n        ),\n    )\n</code></pre> <p>Use <code>bootstrap_streaming</code> to obtain a <code>StreamingRequestMediator</code>; when you call <code>mediator.stream(request)</code>, the dispatcher runs the primary handler's async generator. If the primary raises, the fallback handler's stream is used.</p>"},{"location":"stream_handling/fallback/#basic-example","title":"Basic Example","text":"<pre><code>from typing import AsyncIterator\nimport cqrs\nfrom cqrs.requests.request_handler import StreamingRequestHandler\n\nclass StreamItemsCommand(cqrs.Request):\n    item_ids: list[str]\n\nclass StreamItemResult(cqrs.Response):\n    item_id: str\n    status: str\n    source: str  # \"primary\" or \"fallback\"\n\nclass PrimaryStreamItemsHandler(\n    cqrs.StreamingRequestHandler[StreamItemsCommand, StreamItemResult],\n):\n    def __init__(self) -&gt; None:\n        self._events: list[cqrs.Event] = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events.copy()\n\n    def clear_events(self) -&gt; None:\n        self._events.clear()\n\n    async def handle(\n        self, request: StreamItemsCommand\n    ) -&gt; AsyncIterator[StreamItemResult]:\n        for i, item_id in enumerate(request.item_ids):\n            if i &gt;= 2:\n                raise ConnectionError(\"Stream connection lost\")\n            yield StreamItemResult(\n                item_id=item_id, status=\"processed\", source=\"primary\"\n            )\n\nclass FallbackStreamItemsHandler(\n    cqrs.StreamingRequestHandler[StreamItemsCommand, StreamItemResult],\n):\n    # ... same events protocol ...\n\n    async def handle(\n        self, request: StreamItemsCommand\n    ) -&gt; AsyncIterator[StreamItemResult]:\n        for item_id in request.item_ids:\n            yield StreamItemResult(\n                item_id=item_id, status=\"from_fallback\", source=\"fallback\"\n            )\n\n# Mapper\nmapper.bind(\n    StreamItemsCommand,\n    cqrs.RequestHandlerFallback(\n        primary=PrimaryStreamItemsHandler,\n        fallback=FallbackStreamItemsHandler,\n        failure_exceptions=(ConnectionError, TimeoutError),\n    ),\n)\n\n# Usage: bootstrap_streaming(...), then:\nasync for response in mediator.stream(StreamItemsCommand(item_ids=[\"a\", \"b\", \"c\", \"d\"])):\n    if response is not None:\n        print(response.item_id, response.source)  # primary, primary, fallback, fallback...\n</code></pre> <p>The client receives items from the primary stream until it raises, then items from the fallback stream. Optional <code>failure_exceptions</code> and <code>circuit_breaker</code> behave as for non-streaming Request Handler Fallback.</p>"},{"location":"stream_handling/fallback/#circuit-breaker-configuration","title":"Circuit Breaker configuration","text":"<p>Streaming fallback uses the same <code>RequestHandlerFallback</code> wrapper, so Circuit Breaker is configured the same way as for Request Handler Fallback.</p> <ul> <li>Adapter: <code>AioBreakerAdapter</code> from <code>cqrs.adapters.circuit_breaker</code>.</li> <li>Parameters: <code>fail_max</code> (default <code>5</code>), <code>timeout_duration</code> (seconds, default <code>60</code>), <code>exclude</code> (exceptions that do not count as failures), optional <code>storage_factory</code> for Redis/distributed state.</li> <li>One instance per domain \u2014 e.g. one adapter for all streaming fallbacks that share the same policy; the adapter creates an isolated circuit per handler type.</li> </ul> <p>Example:</p> <pre><code>from cqrs.adapters.circuit_breaker import AioBreakerAdapter\n\nstream_cb = AioBreakerAdapter(fail_max=3, timeout_duration=30)\nmapper.bind(\n    StreamItemsCommand,\n    cqrs.RequestHandlerFallback(\n        primary=PrimaryStreamItemsHandler,\n        fallback=FallbackStreamItemsHandler,\n        failure_exceptions=(ConnectionError, TimeoutError),\n        circuit_breaker=stream_cb,\n    ),\n)\n</code></pre> <p>Full configuration options (exclude, storage_factory, failure_exceptions) are described in Request Handler Fallback \u2014 Circuit Breaker configuration and Saga Fallback \u2014 Circuit Breaker.</p>"},{"location":"stream_handling/fallback/#related","title":"Related","text":"<ul> <li>Request Handler Fallback \u2014 Same wrapper for non-streaming handlers</li> <li>Stream Handling Configuration \u2014 Bootstrap and mediator setup</li> <li>Saga Fallback Pattern \u2014 Fallback for saga steps</li> </ul>"},{"location":"stream_handling/fastapi_integration/","title":"FastAPI Integration","text":"<ul> <li> <p> Back to Stream Handling Overview</p> <p>Return to the Stream Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"stream_handling/fastapi_integration/#overview","title":"Overview","text":"<p><code>StreamingRequestMediator</code> is designed for use with Server-Sent Events (SSE) in FastAPI applications:</p> <pre><code>import fastapi\nimport json\nfrom cqrs.requests import bootstrap\n\ndef streaming_mediator_factory() -&gt; cqrs.StreamingRequestMediator:\n    return bootstrap.bootstrap_streaming(\n        di_container=container,\n        commands_mapper=commands_mapper,\n        domain_events_mapper=domain_events_mapper,\n        message_broker=broker,\n        max_concurrent_event_handlers=3,\n        concurrent_event_handle_enable=True,\n    )\n\n@app.post(\"/process-files\")\nasync def process_files_stream(\n    command: ProcessFilesCommand,\n    mediator: cqrs.StreamingRequestMediator = fastapi.Depends(\n        streaming_mediator_factory\n    ),\n) -&gt; fastapi.responses.StreamingResponse:\n    async def generate_sse():\n        yield f\"data: {json.dumps({'type': 'start', 'message': 'Processing...'})}\\n\\n\"\n\n        async for result in mediator.stream(command):\n            if result is None:\n                continue\n\n            sse_data = {\n                \"type\": \"progress\",\n                \"data\": result.model_dump(),\n            }\n            yield f\"data: {json.dumps(sse_data)}\\n\\n\"\n\n        yield f\"data: {json.dumps({'type': 'complete'})}\\n\\n\"\n\n    return fastapi.responses.StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n    )\n</code></pre> <p>Here's a complete example demonstrating streaming handlers with parallel event processing:</p> <pre><code>import asyncio\nimport typing\nfrom datetime import datetime\nimport di\nimport cqrs\nfrom cqrs.requests import bootstrap\nfrom cqrs.message_brokers import devnull\n\n# Domain models\nclass ProcessOrdersCommand(cqrs.Request):\n    order_ids: list[str]\n\nclass OrderProcessedResult(cqrs.Response):\n    order_id: str\n    status: str\n    processed_at: datetime\n    items_count: int\n\n# Domain events\nclass OrderProcessedEvent(cqrs.DomainEvent, frozen=True):\n    order_id: str\n    customer_id: str\n    total_amount: float\n\nclass OrderAnalyticsEvent(cqrs.DomainEvent, frozen=True):\n    order_id: str\n    category: str\n\n# Streaming handler\nclass ProcessOrdersCommandHandler(\n    cqrs.StreamingRequestHandler[ProcessOrdersCommand, OrderProcessedResult]\n):\n    def __init__(self):\n        self._events: list[cqrs.Event] = []\n\n    @property\n    def events(self) -&gt; list[cqrs.Event]:\n        return self._events.copy()\n\n    def clear_events(self) -&gt; None:\n        self._events.clear()\n\n    async def handle(\n        self, request: ProcessOrdersCommand\n    ) -&gt; typing.AsyncIterator[OrderProcessedResult]:\n        for order_id in request.order_ids:\n            # Simulate processing\n            await asyncio.sleep(0.1)\n\n            # Create result\n            result = OrderProcessedResult(\n                order_id=order_id,\n                status=\"processed\",\n                processed_at=datetime.now(),\n                items_count=3,\n            )\n\n            # Emit multiple events\n            self._events.append(\n                OrderProcessedEvent(\n                    order_id=order_id,\n                    customer_id=f\"customer_{order_id}\",\n                    total_amount=100.0,\n                )\n            )\n            self._events.append(\n                OrderAnalyticsEvent(\n                    order_id=order_id,\n                    category=\"electronics\",\n                )\n            )\n\n            yield result\n\n# Event handlers\nclass OrderProcessedEventHandler(cqrs.EventHandler[OrderProcessedEvent]):\n    async def handle(self, event: OrderProcessedEvent) -&gt; None:\n        print(f\"Order {event.order_id} processed for customer {event.customer_id}\")\n\nclass OrderAnalyticsEventHandler(cqrs.EventHandler[OrderAnalyticsEvent]):\n    async def handle(self, event: OrderAnalyticsEvent) -&gt; None:\n        print(f\"Analytics updated for order {event.order_id} in category {event.category}\")\n\n# Mappers\ndef commands_mapper(mapper: cqrs.RequestMap) -&gt; None:\n    mapper.bind(ProcessOrdersCommand, ProcessOrdersCommandHandler)\n\ndef domain_events_mapper(mapper: cqrs.EventMap) -&gt; None:\n    mapper.bind(OrderProcessedEvent, OrderProcessedEventHandler)\n    mapper.bind(OrderAnalyticsEvent, OrderAnalyticsEventHandler)\n\n# Bootstrap\nasync def main():\n    mediator = bootstrap.bootstrap_streaming(\n        di_container=di.Container(),\n        commands_mapper=commands_mapper,\n        domain_events_mapper=domain_events_mapper,\n        message_broker=devnull.DevnullMessageBroker(),\n        max_concurrent_event_handlers=3,\n        concurrent_event_handle_enable=True,\n    )\n\n    command = ProcessOrdersCommand(order_ids=[\"order1\", \"order2\", \"order3\"])\n\n    async for result in mediator.stream(command):\n        print(f\"Processed: {result.order_id}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"stream_handling/reference/","title":"Reference","text":"<ul> <li> <p> Back to Stream Handling Overview</p> <p>Return to the Stream Handling overview page with all topics.</p> <p> Back to Overview</p> </li> </ul>"},{"location":"stream_handling/reference/#incremental-processing","title":"Incremental Processing","text":"<p>Streaming handlers process items one at a time, yielding results as they become available. This allows clients to receive progress updates in real-time.</p>"},{"location":"stream_handling/reference/#event-emission","title":"Event Emission","text":"<p>After each yield, events are collected and can be emitted. Events are processed after each yield, allowing for parallel processing of side effects.</p>"},{"location":"stream_handling/reference/#parallel-event-processing","title":"Parallel Event Processing","text":"<p>Events can be processed concurrently with configurable concurrency limits. This improves performance when multiple event handlers need to process events independently.</p>"},{"location":"stream_handling/reference/#sse-integration","title":"SSE Integration","text":"<p>Streaming handlers work seamlessly with Server-Sent Events (SSE) in FastAPI, enabling real-time progress updates in web applications.</p> <p>Streaming handlers are ideal for:</p> <ul> <li>Batch processing \u2014 Processing large batches of items with progress updates</li> <li>File uploads \u2014 Processing uploaded files one by one</li> <li>Data import \u2014 Importing data with real-time progress</li> <li>Long-running operations \u2014 Operations that take time and benefit from progress updates</li> <li> <p>Real-time updates \u2014 Applications that need to show progress to users</p> </li> <li> <p>Clear events after processing \u2014 Implement <code>clear_events()</code> to prevent event accumulation</p> </li> <li>Use appropriate concurrency limits \u2014 Set <code>max_concurrent_event_handlers</code> based on your resource constraints</li> <li>Handle errors gracefully \u2014 Wrap streaming logic in try-except blocks</li> <li>Yield meaningful results \u2014 Include progress information in response objects</li> <li>Use SSE for web applications \u2014 Stream results via SSE for better user experience</li> </ul> Feature Regular Handler Streaming Handler Response Single response Multiple responses (yielded) Processing All at once Incremental Progress Updates Not available Real-time Event Processing After completion After each yield Use Case Simple operations Batch/long-running operations"},{"location":"stream_handling/reference/#api-contract-and-typing","title":"API Contract and Typing","text":"<p>StreamingRequestHandler</p> <p>The base class declares <code>handle</code> as a sync method returning an iterator: <code>def handle(self, request: ReqT) -&gt; AsyncIterator[ResT]</code>. Subclasses implement it as an async generator (<code>async def handle(...): ... yield ...</code>). This keeps types compatible with Pyright and mypy \u2014 no type ignores are needed on your handler's <code>handle</code> method.</p> <p>Stream and consumption</p> <ul> <li><code>mediator.stream(request)</code> is called without <code>await</code>.</li> <li>It returns an <code>AsyncIterator</code>; consume it with <code>async for</code>:</li> </ul> <pre><code># Correct: no await, iterate with async for\nasync for result in mediator.stream(command):\n    print(result)\n</code></pre>"}]}